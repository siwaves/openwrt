From a351777c73eecacf9233dc3440c416442f5091b0 Mon Sep 17 00:00:00 2001
From: Richard Dai <richard@siliconwaves.com>
Date: Tue, 25 Jul 2023 18:14:48 +0800
Subject: [PATCH] siliconwaves w3k sdhci driver

---
 drivers/mmc/host/Kconfig                    |   10 +
 drivers/mmc/host/Makefile                   |    4 +
 drivers/mmc/host/sdhci-w3k.c                | 6202 +++++++++++++++++++
 drivers/mmc/host/sdhci_w3k.h                |  760 +++
 include/linux/platform_data/mmc-sdhci-w3k.h |   32 +
 5 files changed, 7008 insertions(+)
 create mode 100644 drivers/mmc/host/sdhci-w3k.c
 create mode 100644 drivers/mmc/host/sdhci_w3k.h
 create mode 100644 include/linux/platform_data/mmc-sdhci-w3k.h

diff --git a/drivers/mmc/host/Kconfig b/drivers/mmc/host/Kconfig
index 82e1fbd6b..84816d732 100644
--- a/drivers/mmc/host/Kconfig
+++ b/drivers/mmc/host/Kconfig
@@ -480,6 +480,16 @@ config MMC_SDHCI_ST
 	  If you have a controller with this interface, say Y or M here.
 	  If unsure, say N.
 
+config MMC_SDHCI_W3K
+	tristate "SDHCI support on Siliconwaves w3k platform"
+	help
+	  This selects the Secure Digital Host Controller Interface (SDHCI)
+	  often referrered to as the HSMMC block in some of the w3k
+	  range of SoC
+
+	  If you have a controller with this interface, say Y or M here.
+	  If unsure, say N.
+
 config MMC_OMAP
 	tristate "TI OMAP Multimedia Card Interface support"
 	depends on ARCH_OMAP
diff --git a/drivers/mmc/host/Makefile b/drivers/mmc/host/Makefile
index 451c25fc2..36b70738f 100644
--- a/drivers/mmc/host/Makefile
+++ b/drivers/mmc/host/Makefile
@@ -99,6 +99,10 @@ obj-$(CONFIG_MMC_SDHCI_BCM_KONA)	+= sdhci-bcm-kona.o
 obj-$(CONFIG_MMC_SDHCI_IPROC)		+= sdhci-iproc.o
 obj-$(CONFIG_MMC_SDHCI_MSM)		+= sdhci-msm.o
 obj-$(CONFIG_MMC_SDHCI_ST)		+= sdhci-st.o
+obj-$(CONFIG_MMC_SDHCI_W3K)		+= sdhci-w3k.o
+ifeq ($(CONFIG_MMC_SDHCI_W3K),y)
+	KBUILD_CFLAGS	+=	-DW3K_MMC_HOST
+endif
 obj-$(CONFIG_MMC_SDHCI_MICROCHIP_PIC32)	+= sdhci-pic32.o
 obj-$(CONFIG_MMC_SDHCI_BRCMSTB)		+= sdhci-brcmstb.o
 obj-$(CONFIG_MMC_SDHCI_OMAP)		+= sdhci-omap.o
diff --git a/drivers/mmc/host/sdhci-w3k.c b/drivers/mmc/host/sdhci-w3k.c
new file mode 100644
index 000000000..35e755d73
--- /dev/null
+++ b/drivers/mmc/host/sdhci-w3k.c
@@ -0,0 +1,6202 @@
+#include <linux/delay.h>
+#include <linux/highmem.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/scatterlist.h>
+#include <linux/regulator/consumer.h>
+#include <linux/pm_runtime.h>
+
+#include <linux/platform_device.h>
+
+#include <linux/mmc/mmc.h>
+#include <linux/mmc/host.h>
+#include <linux/mmc/card.h>
+#include <linux/mmc/sdio.h>
+#include <linux/mmc/slot-gpio.h>
+
+#include <linux/platform_data/mmc-sdhci-w3k.h>
+#include <linux/of.h>
+#include <linux/of_gpio.h>
+
+//#include <plat/gpio.h>
+//#include <mach/gpio.h>
+//#include <mach/magic.h>
+
+#include "sdhci_w3k.h"
+
+#define DRIVER_NAME "sdhci"
+
+#define DBG(f, x...) \
+	pr_debug(DRIVER_NAME " [%s()]: " f, __func__,## x)
+
+#define MAX_TUNING_LOOP 40
+
+//#define USE_ADMA
+#undef DISPLAY_SHMOO
+
+#define SDHCI_CK_REG		0x00
+#define SDHCI_LAT_REG		0x04
+#define SDHCI_PIN_REG		0x08
+#define SDHCI_INT_REG		0x0C
+#define SDHCI_IEN_REG		0x10
+#define SDHCI_CFG_REG		0x14
+#define SDHCI_CMD_REG		0x18
+#define SDHCI_ARG_REG		0x1C
+#define SDHCI_STA_REG		0x20
+#define SDHCI_RSP0_REG		0x24
+#define SDHCI_RSP1_REG		0x28
+#define SDHCI_RSP2_REG		0x2C
+#define SDHCI_RSP3_REG		0x30
+#define SDHCI_BLK_REG		0x34
+#define SDHCI_DC16_REG		0x38
+
+#define SDHCI_M_CFG0_REG	0x3C
+#define SDHCI_M_CFG1_REG	0x40
+#define SDHCI_M_STA_REG		0x44
+#define SDHCI_M_IO_REG		0x48
+
+#define SDHCI_ACMD1_RSP_REG	0x4C
+#define SDHCI_A19_ST0_REG	0x50
+#define SDHCI_A19_ST1_REG	0x54
+#define SDHCI_PCH0_REG		0x58
+#define SDHCI_PCH1_REG		0x5C
+#define SDHCI_DBG_REG		0x60
+#define SDHCI_CST_REG		0x64
+#define SDHCI_CST_INT_REG	0x68
+#define SDHCI_ACMD_REG		0x6C
+#define SDHCI_ATRG_REG		0x70
+#define SDHCI_KDL_REG		0x74
+#define SDHCI_MEM_REG		0x78
+#define SDHCI_C16P_10_REG	0x7C
+#define SDHCI_C16P_73_REG	0x80
+#define SDHCI_C16N_73_REG	0x84
+#define SDHCI_DLL_REG		0x88
+#define SDHCI_ODL_REG		0x8C
+#define SDHCI_WCS_REG		0x90
+#define SDHCI_BSIZ_REG		0x94
+#define SDHCI_DS_REG		0x98
+#define SDHCI_VDDP_REG		0xA0
+#define SDHCI_D03IDL_REG	0xB0
+#define SDHCI_D74IDL_REG	0xB4
+#define SDHCI_RSPIDL_REG	0xB8
+#define SDHCI_APB_REG		0xC0
+#define SDHCI_POP_REG		0xC4
+#define SDHCI_PDA_REG		0xC8
+#define SDHCI_PER_REG		0xD0
+#define SDHCI_PCNT_REG		0xD4
+#define SDHCI_RBIT_REG		0xE0
+#define SDHCI_HINT_REG		0xE4
+
+#define SDHCI_SDMA_SADDR_REG	0x100
+#define SDHCI_SDMA_LEN_REG	0x104
+#define SDHCI_DMA_CTL_REG	0x108
+#define SDHCI_ADMA_SADDR_REG	0x10C
+#define SDHCI_DMA_STA_REG	0x110
+
+
+/* SDHCI_CK_REG bit fields */
+#define SDCK_SOFT_RESET		0x04
+#define SDCK_SD_OFF		0x10
+
+/* SDHCI_COMMAND bit fields */
+#define SDHCI_W3K_RESP_NO	0x0	/* no response */
+#define SDHCI_W3K_RESP_R1	0x1	/* R1/R5/R6/R7,R48-count */
+#define SDHCI_W3K_RESP_R2	0x2	/* R2, R136-count */
+#define SDHCI_W3K_RESP_R3	0x3	/* R3, R48 */
+#define SDHCI_W3K_RESP_R4	0x4	/* R4, R48 */
+#define SDHCI_W3K_RESP_R1B	0x7	/* R1b */
+
+
+/* SDMMC_INT bit fields */
+#define MMC_IRQ         0x00000001      /* MMC interrupt event */
+
+#define ACMD_DONE       0x00000008      /* auto command done */
+#define ACMD_TIMEOUT    0x00000010      /* auto command timeout */
+#define ACMD_CRC_ERROR  0x00000020      /* auto command crc error */
+
+#define SDIO_IRQ        0x00000080      /* SDIO irq */
+#define CMD_DONE        0x00000100      /* command done */
+#define CMD_TIMEOUT     0x00000200      /* command timeout */
+#define CMD_CRC_ERROR   0x00000400      /* command crc error */
+#define CST_INT         0x00000800
+#define DAT_DONE        0x00001000      /* data transfer done */
+
+#define DAT_TIMEOUT     0x00004000      /* data timeout */
+#define DAT_CRC_ERROR   0x00008000      /* data crc error */
+#define A19_DONE        0x00010000
+
+#define CMD_INT         0x00000700
+#define DAT_INT         0x0000D000
+#define INS_INT         0x00000002
+
+#define SDIO_INT	(1 << 7)
+#define SDIO_INT_FLG	(1 << 7)
+
+#define IFM_SD_POWER_OFF		0
+#define IFM_SD_POWER_ON			1
+
+#define SLOT_EMMC	0
+#define SLOT_SDIO_WIFI	1
+#define SLOT_SDIO	2
+#define SLOT_SD		3
+
+#ifdef USE_SRAM
+#define W3K_SRAM_TO_MEM_FLAG
+#define W3C_SDHCI_SDMA_ENABLE
+static void sdhci_w3k_enable_irq(struct sdhci_host *host)
+{
+	sdhci_writel(host, (CMD_INT | DAT_INT|INS_INT |SDIO_INT), SDHCI_IEN_REG);
+}
+
+static void sdhci_w3k_disable_irq(struct sdhci_host *host)
+{
+	sdhci_writel(host, 0x0, SDHCI_IEN_REG);
+}
+
+struct w3k_mmc_data {
+	union {
+		char *dest;
+		char *src; /* src buffers don't get written to */
+	};
+	uint flags;
+	uint blocks;
+	uint blocksize;
+	int last_data;
+};
+
+struct mmc_cmd {
+	ushort cmdidx;
+	uint resp_type;
+	uint cmdarg;
+	uint response[4];
+};
+struct mmc_last_tran {
+	int flag;
+	char *dest;
+	int len;
+};
+struct mmc_last_tran mmc_last_tran = {
+	.flag = 0,
+};
+static int w3k_sdhci_send_command(struct sdhci_host *host, struct mmc_cmd *cmd,
+		       struct w3k_mmc_data *data);
+static int w3k_sdhci_cmd(struct sdhci_host *host, struct mmc_command *cmd)
+{
+	struct w3k_mmc_data w3k_mmc_data;
+	struct mmc_cmd mmc_cmd;
+	mmc_cmd.cmdidx = cmd->opcode;
+	mmc_cmd.resp_type = cmd->flags;
+	mmc_cmd.cmdarg = cmd->arg;
+
+	w3k_mmc_data.flags = cmd->data->flags;
+	if(w3k_mmc_data.flags & MMC_DATA_READ){
+		w3k_mmc_data.dest = sg_virt(cmd->data->sg);
+	}else
+		w3k_mmc_data.src = sg_virt(cmd->data->sg);
+	
+	w3k_mmc_data.blocks = cmd->data->blocks;
+	w3k_mmc_data.blocksize = cmd->data->blksz;
+	return w3k_sdhci_send_command(host, &mmc_cmd, &w3k_mmc_data);
+}
+
+static int w3k_sdhci_cmd_top(struct sdhci_host *host)
+{
+	struct mmc_cmd stop_tran_cmd = {
+		.cmdidx = 0xc, 
+		.resp_type = 0x1d,
+		.cmdarg = 0,
+	};
+	return w3k_sdhci_send_command(host, &stop_tran_cmd, NULL);
+}
+
+#if 1
+#define W3K_ONCE_TRAN_BYTES_LEN (1024*32)
+static int __w3k_sdhci_send_command(struct sdhci_host *host, struct mmc_cmd *cmd,
+		       struct w3k_mmc_data *data);
+static int w3k_sdhci_send_command(struct sdhci_host *host, struct mmc_cmd *cmd,
+		       struct w3k_mmc_data *data)
+{
+
+	struct w3k_mmc_data data_tmp;
+	struct w3k_mmc_data *ptr_data;
+	struct mmc_cmd *ptr_cmd;
+	uint size;
+	int ret = -1;
+	uint blocksize, blocks, count_blocks, last_size;
+	uint tran_blocks;
+	//cmd16 设置块大小的命令
+	struct mmc_cmd set_blocksize_cmd = {
+		.cmdidx = 0x10, 
+		.resp_type = 0x15,
+		.cmdarg = 0, //块大小
+	};
+	//cmd18 设置块数量的命令
+	struct mmc_cmd set_blockcount_cmd = {
+		.cmdidx = 0x12, 
+		.resp_type = 0x15,
+		.cmdarg = 0, //块数量
+	};
+	//读多个块的命令
+	struct mmc_cmd read_multiblock_cmd = {
+		.cmdidx = 0x12, 
+		.resp_type = 0x15,
+		.cmdarg = 0, //块位置
+	};
+	//写多个块的命令
+	struct mmc_cmd write_multiblock_cmd = {
+		.cmdidx = 0x19, 
+		.resp_type = 0x15,
+		.cmdarg = 0, //块位置
+	};
+	//停止传输命令
+	struct mmc_cmd stop_tran_cmd = {
+		.cmdidx = 0xc, 
+		.resp_type = 0x1d,
+		.cmdarg = 0,
+	};
+	//send状态传输命令
+	struct mmc_cmd send_status_cmd = {
+		.cmdidx = 0xd, 
+		.resp_type = 0x15,
+		.cmdarg = 0x10000,
+	};
+
+	if(data){
+		size =data->blocksize *data->blocks;
+		count_blocks = data->blocks;
+		tran_blocks = W3K_ONCE_TRAN_BYTES_LEN/data->blocksize;
+	}
+
+	pr_info("\ncmdidx = 0x%x, resp_type = 0x%x, cmdarg= 0x%x\n", cmd->cmdidx, cmd->resp_type, cmd->cmdarg);
+	if(data && count_blocks >=  tran_blocks){
+		pr_info("count_blocks = %d, tran_blocks = %d\n", count_blocks, tran_blocks);
+		if(count_blocks >= tran_blocks && count_blocks <= (tran_blocks*2)){
+			pr_info("%s %d: data->blocks = %d\n", __func__, __LINE__, data->blocks);
+			goto out;
+		}
+		set_blockcount_cmd.cmdarg = tran_blocks;
+		
+		memcpy(&data_tmp, data, sizeof(struct w3k_mmc_data));
+		if (data->flags & MMC_DATA_READ)
+			ptr_cmd = &read_multiblock_cmd;
+		else
+			ptr_cmd = &write_multiblock_cmd;
+		ptr_cmd->cmdarg = cmd->cmdarg;
+		ptr_data = &data_tmp;
+		ptr_data->blocks = tran_blocks;
+		ret = __w3k_sdhci_send_command(host, &set_blockcount_cmd, NULL);
+		while(1){
+			if((size - ptr_data->blocks *data->blocksize) == 0 ){
+				ptr_data->last_data = 1;
+			}
+			else 
+				ptr_data->last_data = 0;
+			if(ptr_data->last_data == 1 && (data->flags & MMC_DATA_READ))
+			{
+				mmc_last_tran.dest = ptr_data->dest;
+				mmc_last_tran.flag = 1;
+				mmc_last_tran.len = (ptr_data->blocks *data->blocksize);
+			}
+			ret = __w3k_sdhci_send_command(host, ptr_cmd, (struct w3k_mmc_data *)ptr_data);
+			if(ret < 0)
+				break;
+			if(ptr_data->last_data == 1)
+				return ret;
+			/*重启一次传输*/
+			count_blocks -= tran_blocks;
+			size -= (ptr_data->blocks *data->blocksize);
+			if(size == 0){
+				memcpy(cmd->response, ptr_cmd->response, sizeof(ptr_cmd->response));
+				break;
+			}
+			//停止传输
+			ret = __w3k_sdhci_send_command(host, &stop_tran_cmd, NULL);
+			if(ret < 0)
+				break;
+			//send状态传输命令
+			if(data->flags & MMC_DATA_WRITE){
+				ret = __w3k_sdhci_send_command(host, &send_status_cmd, NULL);
+				if(ret < 0)
+					break;
+			}
+		
+			if(count_blocks >= tran_blocks && count_blocks <= (tran_blocks*2)){
+				//一次性传输剩余数据
+				ptr_data->blocks = count_blocks;
+				set_blockcount_cmd.cmdarg = count_blocks;
+			}
+			ptr_cmd->cmdarg += tran_blocks;
+
+			if (data->flags & MMC_DATA_READ){
+				ptr_data->dest += W3K_ONCE_TRAN_BYTES_LEN;
+			}
+			else{
+				ptr_data->src += W3K_ONCE_TRAN_BYTES_LEN;
+			}
+			//设置块大小
+			ret = __w3k_sdhci_send_command(host, &set_blockcount_cmd, NULL);
+			if(ret < 0)
+				break;
+		}	
+	}else {
+out:
+		ret = __w3k_sdhci_send_command(host, cmd, data);
+	}
+	return ret;
+}
+#endif
+static void sdhci_disable_dma(struct sdhci_host *host)
+{
+	pr_info("%s()\n", __func__);
+#define W3K_SDHCI_DMA_CTL		0x108
+	sdhci_writel(host, 0x00020000, W3K_SDHCI_DMA_CTL);
+	pr_info("write W3K_SDHCI_DMA_CTL(0x%x): 0x%x\n", W3K_SDHCI_DMA_CTL, 0x00020000);
+
+	while (sdhci_readl(host, W3K_SDHCI_DMA_CTL) & 0x00020000);
+}
+static int sdhci_transfer_data(struct sdhci_host *host, struct w3k_mmc_data *data,
+				unsigned int start_addr)
+{
+	unsigned int int_stat, dma_stat, timeout, sync_flag = 0;
+
+	pr_info("%s()\n", __func__);
+
+	timeout = 1000000;
+#define W3K_SDHCI_DMA_STATUS	0x110
+#define W3K_SDHCI_INT_STATUS	0x00C
+	do {
+		int_stat = sdhci_readl(host, W3K_SDHCI_INT_STATUS);
+		dma_stat = sdhci_readl(host, W3K_SDHCI_DMA_STATUS);
+
+		if ((dma_stat & 0xF) != 0x0) {
+			if ((dma_stat & 0x2) || (dma_stat & 0x8)) {
+				sync_flag |= 0x4;
+				pr_info("%s: DMA done\n", __func__);
+			}
+			if (dma_stat & 0x4) {
+				pr_info("%s: Error detected in status(0x%X)!\n",
+				       __func__, dma_stat);
+			}
+
+			/* clear dma interrupt */
+			sdhci_writel(host, dma_stat, W3K_SDHCI_DMA_STATUS);
+			pr_info("write W3K_SDHCI_DMA_STATUS(0x%x): 0x%x\n", W3K_SDHCI_DMA_STATUS, dma_stat);
+		}
+#define  W3K_DAT_DONE	0x00001000	/* data transfer done */
+		if (int_stat != 0x0) {
+			/* handle data requests */
+			if (int_stat & W3K_DAT_DONE) {
+				sync_flag |= 0x2;
+				pr_info("%s: data done\n", __func__);
+			}
+#define  W3K_DAT_TIMEOUT	0x00004000	/* data timeout */
+#define  W3K_DAT_CRC_ERROR	0x00008000	/* data crc error */
+			if ((int_stat & W3K_DAT_TIMEOUT) ||
+			    (int_stat & W3K_DAT_CRC_ERROR)) {
+				sdhci_disable_dma(host);
+
+				pr_info("%s: Error detected in status(0x%X)!\n",
+				       __func__, int_stat);
+				return -1;
+			}
+
+			/* clear controller interrupt */
+			sdhci_writel(host, int_stat, W3K_SDHCI_INT_STATUS);
+			pr_info("write W3K_SDHCI_INT_STATUS(0x%x): 0x%x\n", W3K_SDHCI_INT_STATUS, int_stat);
+		}
+
+		if (sync_flag == 0x6) {
+			return 0;
+		}
+
+		if (timeout-- > 0) {
+			udelay(10);
+		} else {
+			pr_info("%s: Transfer data timeout\n", __func__);
+			return -1;
+		}
+	} while (1);
+
+	return 0;
+}
+static void sdhci_cmd_done(struct sdhci_host *host, struct mmc_cmd *cmd)
+{
+	int i;
+
+	pr_info("%s()\n", __func__);
+#define W3K_SDHCI_RESPONSE		0x24
+	if (cmd->resp_type & MMC_RSP_136) {
+		/* CRC is stripped so we need to do some shifting. */
+		for (i = 0; i < 4; i++) {
+			cmd->response[i] = sdhci_readl(host,
+					W3K_SDHCI_RESPONSE + (3 - i) * 4);
+		}
+	} else {
+		cmd->response[0] = sdhci_readl(host, W3K_SDHCI_RESPONSE);
+	}
+}
+
+static void w3k_sdhci_dma_flush(struct sdhci_host *host)
+{
+#define W3K_SDHCI_DMA_CTL_REG 	0x110
+	u32 val = sdhci_readl(host, W3K_SDHCI_DMA_CTL_REG);	
+	val &= ~(1<<17);
+	val |= (1&1)<<17;
+	sdhci_writel(host, val, W3K_SDHCI_DMA_CTL_REG);
+	while((sdhci_readl(host, W3K_SDHCI_DMA_CTL_REG) & (1<<17))!=0)
+		asm volatile("nop"); 
+}
+static int __w3k_sdhci_send_command(struct sdhci_host *host, struct mmc_cmd *cmd,
+		       struct w3k_mmc_data *data)
+{
+	unsigned int stat = 0;
+	unsigned int command = 0, autocmd;
+	int ret = 0;
+	int trans_bytes = 0, is_aligned = 1;
+	u32 flags = 0;
+	unsigned int start_addr = 0;
+#ifdef  W3K_SRAM_TO_MEM_FLAG 
+	char* sram_addr = (char*)SRAM_ADDR;
+	char* sram_addr_write = (char*)SRAM_ADDR;
+#endif
+	unsigned int retry = 10000;
+#ifndef W3C_SDHCI_SDMA_ENABLE
+	struct w3k_sdhci_adma_desc *adma_table = NULL;
+#endif
+	pr_info("%s(%d)\n", __func__, cmd->cmdidx);
+#define W3K_SDHCI_STA_REG		0x020
+	while (sdhci_readl(host, W3K_SDHCI_STA_REG) & 0x3);
+#define W3K_SDHCI_ARGUMENT		0x01C
+	sdhci_writel(host, cmd->cmdarg, W3K_SDHCI_ARGUMENT);
+	pr_info("write W3K_SDHCI_ARGUMENT(0x%x): 0x%x\n", W3K_SDHCI_ARGUMENT, cmd->cmdarg);
+
+	/* Set Transfer mode regarding to data flag */
+	if (data != 0) {
+		w3k_sdhci_dma_flush(host);
+		/* set controller data length */
+		command = ((data->blocksize & 0xFFF) << 16);
+
+		/* set controller block count */
+		if (data->blocks == 1) {
+			command |= 0x00000800;
+		} else if (data->blocks > 1) {
+			command |= 0x00001000;
+		}
+
+		if (data->flags & MMC_DATA_WRITE) {
+			command |= 0x00002000;
+		}
+#define W3K_SDHCI_BLOCK_COUNT	0x034
+		sdhci_writel(host, data->blocks, W3K_SDHCI_BLOCK_COUNT);
+		pr_info("write W3K_SDHCI_BLOCK_COUNT(0x%x): 0x%x\n", W3K_SDHCI_BLOCK_COUNT, data->blocks);
+#define W3K_SDHCI_DMA_STATUS	0x110
+		stat = sdhci_readl(host, W3K_SDHCI_DMA_STATUS);
+		sdhci_writel(host, stat, W3K_SDHCI_DMA_STATUS);
+		pr_info("write W3K_SDHCI_DMA_STATUS(0x%x): 0x%x\n", W3K_SDHCI_DMA_STATUS, stat);
+#ifdef W3C_SDHCI_SDMA_ENABLE
+#define W3K_SDHCI_DMA_CTL		0x108
+		if (data->flags & MMC_DATA_WRITE) {
+			sdhci_writel(host, 0x000000000, W3K_SDHCI_DMA_CTL);
+			pr_info("write W3K_SDHCI_DMA_CTL(0x%x): 0x%x\n", W3K_SDHCI_DMA_CTL, 0x00000300);
+		} else {
+			sdhci_writel(host, 0x80000000, W3K_SDHCI_DMA_CTL);
+			pr_info("write W3K_SDHCI_DMA_CTL(0x%x): 0x%x\n", W3K_SDHCI_DMA_CTL, 0x80000300);
+		}
+		trans_bytes = data->blocks *data->blocksize;
+		if (data->flags & MMC_DATA_READ){
+#ifdef W3K_SRAM_TO_MEM_FLAG
+			start_addr = (unsigned int)sram_addr;
+#else
+			start_addr = (unsigned int)data->dest;
+			//ccache2_flush(start_addr, trans_bytes);
+#endif
+		}
+		else{
+#ifdef W3K_SRAM_TO_MEM_FLAG
+			pr_info("write copy 0x%lx from 0x%x len:%d\n", (unsigned long)sram_addr_write,  (unsigned int )data->src, trans_bytes);
+			char *io_addr = (char *)ioremap((phys_addr_t)sram_addr_write, W3K_ONCE_TRAN_BYTES_LEN);
+			memcpy(io_addr, data->src, trans_bytes);
+			iounmap(io_addr);
+			start_addr = (unsigned int)sram_addr_write;
+#else
+			start_addr = (unsigned int)data->src;
+#endif
+		}	
+		pr_info("%s %d blksz = %d, blocks = %d\n", __func__, __LINE__,data->blocksize, data->blocks);
+#define ARCH_DMA_MINALIGN	128
+		//flush_cache(start_addr, trans_bytes+ARCH_DMA_MINALIGN);
+		//invalidate_dcache_range(start_addr, start_addr+trans_bytes+ARCH_DMA_MINALIGN);
+		
+#define W3K_SDHCI_SDMA_SADDR	0x0100
+#define W3K_SDHCI_SDMA_LEN		0x0104
+		if(data->last_data == 1)
+			sdhci_w3k_enable_irq(host);
+		sdhci_writel(host, start_addr, W3K_SDHCI_SDMA_SADDR);
+		pr_info("write W3K_SDHCI_SDMA_SADDR(0x%x): 0x%x\n", W3K_SDHCI_SDMA_SADDR, start_addr);
+		sdhci_writel(host, trans_bytes & 0XFFFFF, W3K_SDHCI_SDMA_LEN);
+		pr_info("write W3K_SDHCI_SDMA_LEN(0x%x): 0x%x\n", W3K_SDHCI_SDMA_LEN, trans_bytes);
+#else
+		adma_table = w3k_sdhci_adma_init(data->blocks *data->blocksize);
+		if(!adma_table){
+			pr_info("%s %d: w3k_sdhci_adma_init error\n", __func__, __LINE__);
+		}
+		w3k_sdhci_prepare_adma_table(adma_table, data);
+		pr_info("amda descriptor:0x%x\n", (unsigned int)adma_table);
+		w3k_sdhci_adma_start(host, (void*)adma_table, data->flags);
+#endif
+	}
+/* SDMMC_CMD bit fields */
+#define  SD_RESP_NO	 0x0	/* no response */
+#define  SD_RESP_R1	 0x1	/* R1/R5/R6/R7,R48-count */
+#define  SD_RESP_R2	 0x2	/* R2, R136-count */
+#define  SD_RESP_R3	 0x3	/* R3, R48 */
+#define  SD_RESP_R4	 0x4	/* R4, R48 */
+#define  SD_RESP_R1B 0x7	/* R1b */
+
+	/* Translate mmc_resp_type(cmd) to known form of anarion sd/mmc controller */
+	switch (cmd->resp_type) {
+	case MMC_RSP_NONE:
+		flags = SD_RESP_NO;
+		break;
+	case MMC_RSP_R1:
+	case (MMC_RSP_PRESENT|MMC_RSP_OPCODE):
+		flags = SD_RESP_R1;
+		break;
+#define MMC_RSP_R1b	(MMC_RSP_PRESENT|MMC_RSP_CRC|MMC_RSP_OPCODE| \
+			MMC_RSP_BUSY)
+	case MMC_RSP_R1b:
+		flags = SD_RESP_R1B;
+		break;
+	case MMC_RSP_R2:
+		flags = SD_RESP_R2;
+		break;
+	case MMC_RSP_R3:	/* MMC_RSP_R4 */
+		flags = SD_RESP_R3;
+		break;
+	default :
+		pr_info("Unknown response type!!!\n");
+		flags = SD_RESP_NO;
+		break;
+	}
+#define W3K_SDHCI_MAKE_CMD(c, f) ((c & 0x3f) | ((f & 0x7) << 7))
+	if (cmd->resp_type & MMC_RSP_CRC)
+		command |= 0x40000000;
+	if(0){
+	//if (W3K_SDHCI_MAKE_CMD(cmd->cmdidx, flags) == MMC_CMD_SET_BLOCK_COUNT) {
+		command |= (2 << 28);
+		autocmd = W3K_SDHCI_MAKE_CMD(cmd->cmdidx, flags);
+		autocmd |= (SD_RESP_R1 << 7);
+		autocmd |= (1 << 10);
+		autocmd |= (0 << 11);	/* no data */
+		autocmd |= (0 << 14);
+		autocmd |= (1 << 30);
+#define W3K_SDHCI_ACMD_REG		0x6C
+		sdhci_writel(host, autocmd, W3K_SDHCI_ACMD_REG);
+	}
+#define W3K_SDHCI_INT_STATUS	0x00C
+	stat = sdhci_readl(host, W3K_SDHCI_INT_STATUS);
+	sdhci_writel(host, stat, W3K_SDHCI_INT_STATUS);
+	pr_info("write W3K_SDHCI_INT_STATUS(0x%x): 0x%x\n", W3K_SDHCI_INT_STATUS, stat);
+
+	pr_info("command : 0x%x\n", W3K_SDHCI_MAKE_CMD(cmd->cmdidx, flags) | command);
+#define W3K_SDHCI_COMMAND		0x18
+	sdhci_writel(host, W3K_SDHCI_MAKE_CMD(cmd->cmdidx, flags) | command, W3K_SDHCI_COMMAND);
+	pr_info("write W3K_SDHCI_COMMAND(0x%x): 0x%x\n", W3K_SDHCI_COMMAND, W3K_SDHCI_MAKE_CMD(cmd->cmdidx, flags) | command);
+	if(data && data->last_data == 1){
+		return 0;
+	}
+	do {
+		stat = sdhci_readl(host, W3K_SDHCI_INT_STATUS);
+		if (stat & 0x00000100) {
+			pr_info("%s: command done 0x%x\n", __func__, stat);
+			break;
+		}
+		if (stat & 0x00000200) {
+			pr_info("%s(0x%x): command timeout 0x%x\n",
+					__func__, sdhci_readl(host, W3K_SDHCI_COMMAND), stat);
+			break;
+		}
+		if (stat & 0x00000400) {
+			pr_info("%s(0x%x): command crc error 0x%x\n",
+					__func__, sdhci_readl(host, W3K_SDHCI_COMMAND), stat);
+			break;
+		}
+	} while (--retry != 0);
+
+	if (retry == 0) {
+		pr_info("%s: Timeout for status update!\n", __func__);
+		return -ETIMEDOUT;
+	}
+
+	if (stat & 0x00000100) {
+		sdhci_cmd_done(host, cmd);
+	} else
+		ret = -1;
+	
+	if (!ret && data)
+		ret = sdhci_transfer_data(host, data, start_addr);
+	
+#ifndef  W3C_SDHCI_SDMA_ENABLE
+	if(adma_table)
+		free(adma_table);
+#endif	
+	stat = sdhci_readl(host, W3K_SDHCI_INT_STATUS);
+	sdhci_writel(host, stat, W3K_SDHCI_INT_STATUS);
+	pr_info("write W3K_SDHCI_INT_STATUS(0x%x): 0x%x\n", W3K_SDHCI_INT_STATUS, stat);
+
+#ifdef W3K_SRAM_TO_MEM_FLAG	
+	if (!ret && data && data->flags & MMC_DATA_READ){
+		pr_info("read copy 0x%lx to 0x%x len:%d\n", (unsigned long )sram_addr,  (unsigned int )data->dest, trans_bytes);
+		char *io_addr = (char *)ioremap((phys_addr_t)sram_addr, W3K_ONCE_TRAN_BYTES_LEN);
+		memcpy(data->dest, io_addr, trans_bytes);
+		iounmap(io_addr);
+	}
+	if(!ret && data)
+		return 0;
+#endif	
+
+#define  W3K_SDHCI_INT_TIMEOUT	0x00000200
+#define  W3K_SDHCI_INT_DATA_TIMEOUT	0x00004000
+	//w3k_sdhci_reset(host, W3K_SDHCI_RESET_ALL);
+
+	//clear dma interrupt flag
+	u32 reg_value = sdhci_readl(host, W3K_SDHCI_DMA_STATUS);
+	sdhci_writel(host, reg_value, W3K_SDHCI_DMA_STATUS);
+
+	if (stat & (W3K_SDHCI_INT_TIMEOUT | W3K_SDHCI_INT_DATA_TIMEOUT))
+		return -ETIMEDOUT;
+	else
+		return 0;
+}
+
+
+#endif
+
+/******************************************************************************/
+/* WIFI sdio interrupt issue */
+////#define RTL_SDIO_GPIO_TEST
+
+#ifdef RTL_SDIO_GPIO_TEST
+#define SDIO_INTERRUPT_GPIO	4
+static u8 wifi_eirq_enable = 0;
+#endif
+
+struct sdhci_host *wifi_sdio_host = NULL;
+
+void detect_wifi_card(unsigned long msecs)
+{
+	BUG_ON(wifi_sdio_host == NULL);
+	mmc_detect_change(wifi_sdio_host->mmc, msecs_to_jiffies(msecs));
+}
+EXPORT_SYMBOL(detect_wifi_card);
+
+struct sdhci_host* get_wifi_sdio_host(void)
+{
+	BUG_ON(wifi_sdio_host == NULL);
+	return wifi_sdio_host;
+}
+EXPORT_SYMBOL(get_wifi_sdio_host);
+
+#ifdef RTL_SDIO_GPIO_TEST
+static void wifi_irq_trg(int gpio, bool triger)
+{
+	if (triger == GPIO_INT_GEN)
+		gpio_line_set_interrupt_enable_disable(gpio, GPIO_INT_GEN);
+	else
+		gpio_line_set_interrupt_enable_disable(gpio, GPIO_NO_INT_GEN);
+}
+#endif
+
+#ifdef RTL_SDIO_GPIO_TEST
+static void wifi_host_sdio_triger(bool enable)
+{
+	wifi_irq_trg(SDIO_INTERRUPT_GPIO, enable);
+}
+#endif
+
+void Wifi_SDIO_irq_set(bool enable)
+{
+#ifdef RTL_SDIO_GPIO_TEST
+	wifi_host_sdio_triger(enable);
+#else
+////	unsigned long flags;
+////	struct sdhci_host *host = get_wifi_sdio_host();
+
+	if (enable)
+		printk("nothing...");
+	else
+		printk("disable ....\n");
+#endif
+}
+
+void export_wifi_eirq_enable(void)
+{
+	printk(KERN_INFO "%s %d", __func__, __LINE__);
+	//enable or disable gpio interrupt
+	Wifi_SDIO_irq_set(1);
+	//for sdio sub-sys
+#ifdef RTL_SDIO_GPIO_TEST
+	wifi_eirq_enable = 1;
+#endif
+}
+EXPORT_SYMBOL_GPL(export_wifi_eirq_enable);
+
+void export_wifi_eirq_disable(void)
+{
+	printk(KERN_INFO "%s %d", __func__, __LINE__);
+	Wifi_SDIO_irq_set(0);
+
+#ifdef RTL_SDIO_GPIO_TEST	
+	//for sdio sub-sys
+	wifi_eirq_enable = 0;
+#endif
+}
+EXPORT_SYMBOL_GPL(export_wifi_eirq_disable);
+
+#ifdef RTL_SDIO_GPIO_TEST
+static irqreturn_t gpio_sdio_irq_handle(int irq, void *devid)
+{
+	struct sdhci_host *host = (struct sdhci_host *)devid;
+
+	if (!(w3k_readl(GPIO_EINT_REG) & (1 << SDIO_INTERRUPT_GPIO)) ||
+	    (!external_int_line_detect(SDIO_INTERRUPT_GPIO))) {
+		external_int_line_clear_set(SDIO_INTERRUPT_GPIO, EXTERNAL_INT_CLEAR);
+		return IRQ_NONE;
+	}
+
+	if (host->mmc)
+		mmc_signal_sdio_irq(host->mmc);
+	else
+		printk(KERN_INFO "%s %d host->mmc is null!!!!!", __func__, __LINE__);
+
+	external_int_line_clear_set(SDIO_INTERRUPT_GPIO, EXTERNAL_INT_CLEAR);
+
+	return IRQ_HANDLED;
+}
+static void sdio_gpio_init(int gpio)
+{
+	int ret = gpio_request(gpio, "sdio_irq_qpio");
+	if (ret)
+		printk("request_irq failed\n");
+
+	ret = gpio_direction_input(gpio);	//data1 2.8v
+	if (ret)
+		printk("gpio_direction_input failed\n");
+
+	// triger method
+	gpio_line_set_edgr_tri(gpio, LOW_LEVEL_TRIGGER);	//sdio interrupt method
+
+	// disable gpio interrupt at first.
+	gpio_line_set_interrupt_enable_disable(gpio, GPIO_NO_INT_GEN);
+#if defined CONFIG_SDIO_GPIO_WAKEUP
+	printk("%s %d %s", __func__, __LINE__, __FILE__);
+//	w3k_pm_trigger_source_setup(true, A9_MSK_WKUPTR_REG__DISABLE_GPIO4_TRIGGER, GPIO_POLARITY_LOW);
+#endif
+	printk(KERN_INFO "%s %d disable gpio interrupt", __func__, __LINE__);
+}
+static void sdio_gpio_dinit(int gpio)
+{
+	gpio_line_set_interrupt_enable_disable(gpio, GPIO_INT_GEN);
+	gpio_free(gpio);
+}
+
+static int sdio_irq_gpio_set(int gpio,struct sdhci_host *host)
+{
+	int ret;
+
+	/* init gpio first. */
+	sdio_gpio_init(gpio);
+
+	ret = request_irq(gpio_to_irq(gpio), gpio_sdio_irq_handle,
+					IRQF_SHARED, DRIVER_NAME, host);
+	if (ret)
+		printk(KERN_INFO "wifi irq  failed to request irq\n");
+	else
+		printk(KERN_INFO "wifi irq request successfully\n");
+
+	return ret;
+}
+
+static void sdio_irq_gpio_unset(int gpio,struct sdhci_host *host)
+{
+	free_irq(gpio_to_irq(gpio), (void *)host);
+	sdio_gpio_dinit(gpio);
+}
+#endif
+
+/******************************************************************************/
+
+static unsigned int debug_quirks = 0;
+static unsigned int debug_quirks2;
+
+static void sdhci_finish_data(struct sdhci_host *);
+
+static void sdhci_finish_command(struct sdhci_host *);
+static int sdhci_execute_tuning(struct mmc_host *mmc, u32 opcode);
+static void sdhci_tuning_timer(struct timer_list *timer);
+static void sdhci_enable_preset_value(struct sdhci_host *host, bool enable);
+static int sdhci_pre_dma_transfer(struct sdhci_host *host,
+					struct mmc_data *data,
+					struct sdhci_host_next *next);
+static int sdhci_do_get_cd(struct sdhci_host *host);
+
+#ifdef CONFIG_PM
+static int sdhci_runtime_pm_get(struct sdhci_host *host);
+static int sdhci_runtime_pm_put(struct sdhci_host *host);
+static void sdhci_runtime_pm_bus_on(struct sdhci_host *host);
+static void sdhci_runtime_pm_bus_off(struct sdhci_host *host);
+#else
+static inline int sdhci_runtime_pm_get(struct sdhci_host *host)
+{
+	return 0;
+}
+static inline int sdhci_runtime_pm_put(struct sdhci_host *host)
+{
+	return 0;
+}
+static void sdhci_runtime_pm_bus_on(struct sdhci_host *host)
+{
+}
+static void sdhci_runtime_pm_bus_off(struct sdhci_host *host)
+{
+}
+#endif
+
+/******************************************************************************/
+
+static void sdhci_w3k_flush_dma(struct sdhci_host *host);
+static int sdhci_w3k_enable_dma(struct sdhci_host *host);
+static unsigned int sdhci_w3k_get_max_clock(struct sdhci_host *host);
+static unsigned int sdhci_w3k_get_min_clock(struct sdhci_host *host);
+static unsigned int sdhci_w3k_get_timeout_clock(struct sdhci_host *host);
+static unsigned int sdhci_w3k_get_max_timeout_count(struct sdhci_host *host);
+static void sdhci_w3k_platform_send_init_74_clocks(struct sdhci_host *host,
+						      u8 power_mode);
+static unsigned int sdhci_w3k_get_ro(struct sdhci_host *host);
+static int sdhci_w3k_platform_execute_tuning(struct sdhci_host *host, u32 opcode);
+static void sdhci_w3k_hw_reset(struct sdhci_host *host);
+static void sdhci_w3k_adma_workaround(struct sdhci_host *host, u32 intmask);
+static void sdhci_w3k_card_event(struct sdhci_host *host);
+static void sdhci_w3k_voltage_switch(struct sdhci_host *host);
+
+/******************************************************************************/
+
+static void sdhci_dumpregs(struct sdhci_host *host)
+{
+	pr_debug(DRIVER_NAME ": =========== REGISTER DUMP (%s)===========\n",
+		mmc_hostname(host->mmc));
+
+	pr_debug(DRIVER_NAME "SDHCI_CK_REG 0x%x\n",  sdhci_readl(host, SDHCI_CK_REG));
+	pr_debug(DRIVER_NAME "SDHCI_LAT_REG 0x%x\n", sdhci_readl(host, SDHCI_LAT_REG));
+	pr_debug(DRIVER_NAME "SDHCI_PIN_REG 0x%x\n", sdhci_readl(host, SDHCI_PIN_REG));
+	pr_debug(DRIVER_NAME "SDHCI_INT_REG 0x%x\n", sdhci_readl(host, SDHCI_INT_REG));
+	pr_debug(DRIVER_NAME "SDHCI_IEN_REG 0x%x\n", sdhci_readl(host, SDHCI_IEN_REG));
+	pr_debug(DRIVER_NAME "SDHCI_CFG_REG 0x%x\n", sdhci_readl(host, SDHCI_CFG_REG));
+	pr_debug(DRIVER_NAME "SDHCI_CMD_REG 0x%x\n", sdhci_readl(host, SDHCI_CMD_REG));
+	pr_debug(DRIVER_NAME "SDHCI_ARG_REG 0x%x\n", sdhci_readl(host, SDHCI_ARG_REG));
+	pr_debug(DRIVER_NAME "SDHCI_STA_REG 0x%x\n", sdhci_readl(host, SDHCI_STA_REG));
+	pr_debug(DRIVER_NAME "SDHCI_RSP0_REG 0x%x\n", sdhci_readl(host, SDHCI_RSP0_REG));
+	pr_debug(DRIVER_NAME "SDHCI_RSP1_REG 0x%x\n", sdhci_readl(host, SDHCI_RSP1_REG));
+	pr_debug(DRIVER_NAME "SDHCI_RSP2_REG 0x%x\n", sdhci_readl(host, SDHCI_RSP2_REG));
+	pr_debug(DRIVER_NAME "SDHCI_RSP3_REG 0x%x\n", sdhci_readl(host, SDHCI_RSP3_REG));
+	pr_debug(DRIVER_NAME "SDHCI_BLK_REG 0x%x\n",  sdhci_readl(host, SDHCI_BLK_REG));
+	pr_debug(DRIVER_NAME "SDHCI_DC16_REG 0x%x\n", sdhci_readl(host, SDHCI_DC16_REG));
+	pr_debug(DRIVER_NAME "SDHCI_M_CFG0_REG 0x%x\n", sdhci_readl(host, SDHCI_M_CFG0_REG));
+	pr_debug(DRIVER_NAME "SDHCI_M_CFG1_REG 0x%x\n", sdhci_readl(host, SDHCI_M_CFG1_REG));
+	pr_debug(DRIVER_NAME "SDHCI_M_STA_REG 0x%x\n", sdhci_readl(host, SDHCI_M_STA_REG));
+	pr_debug(DRIVER_NAME "SDHCI_M_IO_REG 0x%x\n", sdhci_readl(host, SDHCI_M_IO_REG));
+	pr_debug(DRIVER_NAME "SDHCI_ACMD1_RSP_REG 0x%x\n", sdhci_readl(host, SDHCI_ACMD1_RSP_REG));
+	pr_debug(DRIVER_NAME "SDHCI_A19_ST0_REG 0x%x\n", sdhci_readl(host, SDHCI_A19_ST0_REG));
+	pr_debug(DRIVER_NAME "SDHCI_A19_ST1_REG 0x%x\n", sdhci_readl(host, SDHCI_A19_ST1_REG));
+	pr_debug(DRIVER_NAME "SDHCI_PCH0_REG 0x%x\n", sdhci_readl(host, SDHCI_PCH0_REG));
+	pr_debug(DRIVER_NAME "SDHCI_PCH1_REG 0x%x\n", sdhci_readl(host, SDHCI_PCH1_REG));
+	pr_debug(DRIVER_NAME "SDHCI_DBG_REG 0x%x\n", sdhci_readl(host, SDHCI_DBG_REG));
+	pr_debug(DRIVER_NAME "SDHCI_CST_REG 0x%x\n", sdhci_readl(host, SDHCI_CST_REG));
+	pr_debug(DRIVER_NAME "SDHCI_CST_INT_REG 0x%x\n", sdhci_readl(host, SDHCI_CST_INT_REG));
+	pr_debug(DRIVER_NAME "SDHCI_ACMD_REG 0x%x\n", sdhci_readl(host, SDHCI_ACMD_REG));
+	pr_debug(DRIVER_NAME "SDHCI_ATRG_REG 0x%x\n", sdhci_readl(host, SDHCI_ATRG_REG));
+	pr_debug(DRIVER_NAME "SDHCI_KDL_REG 0x%x\n", sdhci_readl(host, SDHCI_KDL_REG));
+	pr_debug(DRIVER_NAME "SDHCI_MEM_REG 0x%x\n", sdhci_readl(host, SDHCI_MEM_REG));
+	pr_debug(DRIVER_NAME "SDHCI_C16P_10_REG 0x%x\n", sdhci_readl(host, SDHCI_C16P_10_REG));
+	pr_debug(DRIVER_NAME "SDHCI_C16P_73_REG 0x%x\n", sdhci_readl(host, SDHCI_C16P_73_REG));
+	pr_debug(DRIVER_NAME "SDHCI_C16N_73_REG 0x%x\n", sdhci_readl(host, SDHCI_C16N_73_REG));
+	pr_debug(DRIVER_NAME "SDHCI_DLL_REG 0x%x\n", sdhci_readl(host, SDHCI_DLL_REG));
+	pr_debug(DRIVER_NAME "SDHCI_ODL_REG 0x%x\n", sdhci_readl(host, SDHCI_ODL_REG));
+	pr_debug(DRIVER_NAME "SDHCI_WCS_REG 0x%x\n", sdhci_readl(host, SDHCI_WCS_REG));
+	pr_debug(DRIVER_NAME "SDHCI_BSIZ_REG 0x%x\n", sdhci_readl(host, SDHCI_BSIZ_REG));
+	pr_debug(DRIVER_NAME "SDHCI_DS_REG 0x%x\n", sdhci_readl(host, SDHCI_DS_REG));
+	pr_debug(DRIVER_NAME "SDHCI_VDDP_REG 0x%x\n", sdhci_readl(host, SDHCI_VDDP_REG));
+	pr_debug(DRIVER_NAME "SDHCI_D03IDL_REG 0x%x\n", sdhci_readl(host, SDHCI_D03IDL_REG));
+	pr_debug(DRIVER_NAME "SDHCI_D74IDL_REG 0x%x\n", sdhci_readl(host, SDHCI_D74IDL_REG));
+	pr_debug(DRIVER_NAME "SDHCI_RSPIDL_REG 0x%x\n", sdhci_readl(host, SDHCI_RSPIDL_REG));
+	pr_debug(DRIVER_NAME "SDHCI_APB_REG 0x%x\n", sdhci_readl(host, SDHCI_APB_REG));
+	pr_debug(DRIVER_NAME "SDHCI_POP_REG 0x%x\n", sdhci_readl(host, SDHCI_POP_REG));
+	pr_debug(DRIVER_NAME "SDHCI_PDA_REG 0x%x\n", sdhci_readl(host, SDHCI_PDA_REG));
+	pr_debug(DRIVER_NAME "SDHCI_PER_REG 0x%x\n", sdhci_readl(host, SDHCI_PER_REG));
+	pr_debug(DRIVER_NAME "SDHCI_PCNT_REG 0x%x\n", sdhci_readl(host, SDHCI_PCNT_REG));
+	pr_debug(DRIVER_NAME "SDHCI_RBIT_REG 0x%x\n", sdhci_readl(host, SDHCI_RBIT_REG));
+	pr_debug(DRIVER_NAME "SDHCI_HINT_REG 0x%x\n", sdhci_readl(host, SDHCI_HINT_REG));
+
+#if 0
+	pr_debug(DRIVER_NAME ": Sys addr: 0x%08x | Version:  0x%08x\n",
+		sdhci_readl(host, SDHCI_DMA_ADDRESS),
+		sdhci_readw(host, SDHCI_HOST_VERSION));
+	pr_debug(DRIVER_NAME ": Blk size: 0x%08x | Blk cnt:  0x%08x\n",
+		sdhci_readw(host, SDHCI_BLOCK_SIZE),
+		sdhci_readw(host, SDHCI_BLOCK_COUNT));
+	pr_debug(DRIVER_NAME ": Argument: 0x%08x | Trn mode: 0x%08x\n",
+		sdhci_readl(host, SDHCI_ARGUMENT),
+		sdhci_readw(host, SDHCI_TRANSFER_MODE));
+	pr_debug(DRIVER_NAME ": Present:  0x%08x | Host ctl: 0x%08x\n",
+		sdhci_readl(host, SDHCI_PRESENT_STATE),
+		sdhci_readb(host, SDHCI_HOST_CONTROL));
+	pr_debug(DRIVER_NAME ": Power:    0x%08x | Blk gap:  0x%08x\n",
+		sdhci_readb(host, SDHCI_POWER_CONTROL),
+		sdhci_readb(host, SDHCI_BLOCK_GAP_CONTROL));
+	pr_debug(DRIVER_NAME ": Wake-up:  0x%08x | Clock:    0x%08x\n",
+		sdhci_readb(host, SDHCI_WAKE_UP_CONTROL),
+		sdhci_readw(host, SDHCI_CLOCK_CONTROL));
+	pr_debug(DRIVER_NAME ": Timeout:  0x%08x | Int stat: 0x%08x\n",
+		sdhci_readb(host, SDHCI_TIMEOUT_CONTROL),
+		sdhci_readl(host, SDHCI_INT_STATUS));
+	pr_debug(DRIVER_NAME ": Int enab: 0x%08x | Sig enab: 0x%08x\n",
+		sdhci_readl(host, SDHCI_INT_ENABLE),
+		sdhci_readl(host, SDHCI_SIGNAL_ENABLE));
+	pr_debug(DRIVER_NAME ": AC12 err: 0x%08x | Slot int: 0x%08x\n",
+		sdhci_readw(host, SDHCI_ACMD12_ERR),
+		sdhci_readw(host, SDHCI_SLOT_INT_STATUS));
+	pr_debug(DRIVER_NAME ": Caps:     0x%08x | Caps_1:   0x%08x\n",
+		sdhci_readl(host, SDHCI_CAPABILITIES),
+		sdhci_readl(host, SDHCI_CAPABILITIES_1));
+	pr_debug(DRIVER_NAME ": Cmd:      0x%08x | Max curr: 0x%08x\n",
+		sdhci_readw(host, SDHCI_COMMAND),
+		sdhci_readl(host, SDHCI_MAX_CURRENT));
+	pr_debug(DRIVER_NAME ": Host ctl2: 0x%08x\n",
+		sdhci_readw(host, SDHCI_HOST_CONTROL2));
+
+	if (host->flags & SDHCI_USE_ADMA) {
+		if (host->flags & SDHCI_USE_64_BIT_DMA)
+			pr_debug(DRIVER_NAME ": ADMA Err: 0x%08x | ADMA Ptr: 0x%08x%08x\n",
+				 readl(host->ioaddr + SDHCI_ADMA_ERROR),
+				 readl(host->ioaddr + SDHCI_ADMA_ADDRESS_HI),
+				 readl(host->ioaddr + SDHCI_ADMA_ADDRESS));
+		else
+			pr_debug(DRIVER_NAME ": ADMA Err: 0x%08x | ADMA Ptr: 0x%08x\n",
+				 readl(host->ioaddr + SDHCI_ADMA_ERROR),
+				 readl(host->ioaddr + SDHCI_ADMA_ADDRESS));
+	}
+#endif
+
+	pr_debug(DRIVER_NAME ": ===========================================\n");
+}
+
+/*****************************************************************************\
+ *                                                                           *
+ * Low level functions                                                       *
+ *                                                                           *
+\*****************************************************************************/
+
+static void sdhci_set_card_detection(struct sdhci_host *host, bool enable)
+{
+	u32 ctrl;
+
+	if ((host->quirks & SDHCI_QUIRK_BROKEN_CARD_DETECTION) ||
+	    (host->mmc->caps & MMC_CAP_NONREMOVABLE))
+		return;
+
+	//pr_info(KERN_INFO "%s : %s(%d)\n", mmc_hostname(host->mmc), __func__, enable);
+
+	/* check busy state */
+	while (sdhci_readl(host, SDHCI_STA_REG) & 0x3);
+
+	ctrl = sdhci_readl(host, SDHCI_PRESENT_STATE);
+	ctrl &= ~0x1;
+	sdhci_writel(host, ctrl, SDHCI_PRESENT_STATE);
+
+	if (enable) {
+		ctrl |= 0x1;
+		sdhci_writel(host, ctrl, SDHCI_PRESENT_STATE);
+		host->ier |= (SDHCI_INT_CARD_REMOVE | SDHCI_INT_CARD_INSERT);
+	} else {
+//		ctrl &= ~0x1;
+		host->ier &= ~(SDHCI_INT_CARD_REMOVE | SDHCI_INT_CARD_INSERT);
+	}
+
+	sdhci_writel(host, host->ier, SDHCI_IEN_REG);
+//	sdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);
+}
+
+static void sdhci_enable_card_detect(struct sdhci_host *host)
+{
+	if (host->card_detect)
+		sdhci_set_card_detection(host, true);
+}
+
+static void sdhci_disable_card_detect(struct sdhci_host *host)
+{
+	if (host->card_detect)
+		sdhci_set_card_detection(host, false);
+}
+
+static void sdhci_enable_card_detection(struct sdhci_host *host)
+{
+	host->card_detect = true;
+	sdhci_set_card_detection(host, true);
+}
+
+static void sdhci_disable_card_detection(struct sdhci_host *host)
+{
+	host->card_detect = false;
+	sdhci_set_card_detection(host, false);
+}
+
+void sdhci_reset(struct sdhci_host *host, u8 mask)
+{
+	unsigned long timeout;
+
+	//pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	sdhci_writel(host, (sdhci_readl(host, SDHCI_CK_REG) | 0x4), SDHCI_CK_REG);
+
+	if (mask & SDHCI_RESET_ALL) {
+		host->clock = 0;
+		/* Reset-all turns off SD Bus Power */
+		if (host->quirks2 & SDHCI_QUIRK2_CARD_ON_NEEDS_BUS_ON)
+			sdhci_runtime_pm_bus_off(host);
+	}
+
+	/* Wait max 100 ms */
+	timeout = 100000;
+
+	/* hw clears the bit when it's done */
+	while (sdhci_readl(host, SDHCI_CK_REG) & 0x80) {
+		if (timeout == 0) {
+			pr_err("%s: Reset 0x%x never completed.\n",
+				mmc_hostname(host->mmc), (int)mask);
+			sdhci_dumpregs(host);
+			return;
+		}
+		timeout--;
+		//mdelay(1);
+	}
+}
+EXPORT_SYMBOL_GPL(sdhci_reset);
+
+static void sdhci_do_reset(struct sdhci_host *host, u8 mask)
+{
+	if (host->quirks & SDHCI_QUIRK_NO_CARD_NO_RESET) {
+		if (!(sdhci_readl(host, SDHCI_PRESENT_STATE) &
+			SDHCI_CARD_PRESENT))
+			return;
+	}
+
+	sdhci_reset(host, mask);
+
+	if (mask & SDHCI_RESET_ALL) {
+		if (host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {
+			sdhci_w3k_enable_dma(host);
+		}
+
+		/* Resetting the controller clears many */
+		host->preset_enabled = false;
+	}
+}
+
+static void sdhci_set_ios(struct mmc_host *mmc, struct mmc_ios *ios);
+
+static void sdhci_init(struct sdhci_host *host, int soft)
+{
+	pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	if (soft)
+		sdhci_do_reset(host, SDHCI_RESET_CMD|SDHCI_RESET_DATA);
+	else
+		sdhci_do_reset(host, SDHCI_RESET_ALL);
+
+#if 0
+	host->ier = SDHCI_INT_DATA_CRC | SDHCI_INT_DATA_TIMEOUT |
+		    SDHCI_INT_CRC |
+		    SDHCI_INT_TIMEOUT | SDHCI_INT_DATA_END |
+		    SDHCI_INT_RESPONSE;
+#else
+	host->ier = (CMD_INT | DAT_INT|INS_INT |SDIO_INT);
+#endif
+
+	sdhci_writel(host, host->ier, SDHCI_IEN_REG);
+//	sdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);
+
+	if (soft) {
+		/* force clock reconfiguration */
+		host->clock = 0;
+		sdhci_set_ios(host->mmc, &host->mmc->ios);
+	}
+}
+
+static void sdhci_reinit(struct sdhci_host *host)
+{
+	//pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	sdhci_init(host, 0);
+	/*
+	 * Retuning stuffs are affected by different cards inserted and only
+	 * applicable to UHS-I cards. So reset these fields to their initial
+	 * value when card is removed.
+	 */
+	if (host->flags & SDHCI_USING_RETUNING_TIMER) {
+		host->flags &= ~SDHCI_USING_RETUNING_TIMER;
+
+		del_timer_sync(&host->tuning_timer);
+		host->flags &= ~SDHCI_NEEDS_RETUNING;
+	}
+	sdhci_enable_card_detection(host);
+}
+
+/*****************************************************************************\
+ *                                                                           *
+ * Core functions                                                            *
+ *                                                                           *
+\*****************************************************************************/
+#if 0
+static void sdhci_read_block_pio(struct sdhci_host *host)
+{
+	unsigned long flags;
+	size_t blksize, len, chunk;
+	u32 uninitialized_var(scratch);
+	u8 *buf;
+
+	DBG("PIO reading\n");
+
+	blksize = host->data->blksz;
+	chunk = 0;
+
+	local_irq_save(flags);
+
+	while (blksize) {
+		if (!sg_miter_next(&host->sg_miter))
+			BUG();
+
+		len = min(host->sg_miter.length, blksize);
+
+		blksize -= len;
+		host->sg_miter.consumed = len;
+
+		buf = host->sg_miter.addr;
+
+		while (len) {
+			if (chunk == 0) {
+				scratch = sdhci_readl(host, SDHCI_BUFFER);
+				chunk = 4;
+			}
+
+			*buf = scratch & 0xFF;
+
+			buf++;
+			scratch >>= 8;
+			chunk--;
+			len--;
+		}
+	}
+
+	sg_miter_stop(&host->sg_miter);
+
+	local_irq_restore(flags);
+}
+
+static void sdhci_write_block_pio(struct sdhci_host *host)
+{
+	unsigned long flags;
+	size_t blksize, len, chunk;
+	u32 scratch;
+	u8 *buf;
+
+	DBG("PIO writing\n");
+
+	blksize = host->data->blksz;
+	chunk = 0;
+	scratch = 0;
+
+	local_irq_save(flags);
+
+	while (blksize) {
+		if (!sg_miter_next(&host->sg_miter))
+			BUG();
+
+		len = min(host->sg_miter.length, blksize);
+
+		blksize -= len;
+		host->sg_miter.consumed = len;
+
+		buf = host->sg_miter.addr;
+
+		while (len) {
+			scratch |= (u32)*buf << (chunk * 8);
+
+			buf++;
+			chunk++;
+			len--;
+
+			if ((chunk == 4) || ((len == 0) && (blksize == 0))) {
+				sdhci_writel(host, scratch, SDHCI_BUFFER);
+				chunk = 0;
+				scratch = 0;
+			}
+		}
+	}
+
+	sg_miter_stop(&host->sg_miter);
+
+	local_irq_restore(flags);
+}
+#endif
+#if 0
+static void sdhci_transfer_pio(struct sdhci_host *host)
+{
+	u32 mask;
+
+	BUG_ON(!host->data);
+
+	if (host->blocks == 0)
+		return;
+
+	if (host->data->flags & MMC_DATA_READ)
+		mask = SDHCI_DATA_AVAILABLE;
+	else
+		mask = SDHCI_SPACE_AVAILABLE;
+
+	/*
+	 * Some controllers (JMicron JMB38x) mess up the buffer bits
+	 * for transfers < 4 bytes. As long as it is just one block,
+	 * we can ignore the bits.
+	 */
+	if ((host->quirks & SDHCI_QUIRK_BROKEN_SMALL_PIO) &&
+		(host->data->blocks == 1))
+		mask = ~0;
+
+	while (sdhci_readl(host, SDHCI_PRESENT_STATE) & mask) {
+		if (host->quirks & SDHCI_QUIRK_PIO_NEEDS_DELAY)
+			udelay(100);
+
+		if (host->data->flags & MMC_DATA_READ)
+			sdhci_read_block_pio(host);
+		else
+			sdhci_write_block_pio(host);
+
+		host->blocks--;
+		if (host->blocks == 0)
+			break;
+	}
+
+	DBG("PIO transfer complete.\n");
+}
+#endif
+
+static char *sdhci_kmap_atomic(struct scatterlist *sg, unsigned long *flags)
+{
+	local_irq_save(*flags);
+	return kmap_atomic(sg_page(sg)) + sg->offset;
+}
+
+static void sdhci_kunmap_atomic(void *buffer, unsigned long *flags)
+{
+	kunmap_atomic(buffer);
+	local_irq_restore(*flags);
+}
+
+static void sdhci_adma_write_desc(struct sdhci_host *host, void *desc,
+				  dma_addr_t addr, int len, unsigned cmd)
+{
+	struct sdhci_adma2_64_desc *dma_desc = desc;
+	//printk(KERN_INFO "write_desc cmd %x len %x\n", cmd, len);
+	/* 32-bit and 64-bit descriptors have these members in same position */
+	dma_desc->cmd = cpu_to_le16(cmd);
+	dma_desc->len = cpu_to_le16(len);
+	dma_desc->addr_lo = cpu_to_le32((u32)addr);
+
+	if (host->flags & SDHCI_USE_64_BIT_DMA)
+		dma_desc->addr_hi = cpu_to_le32((u64)addr >> 32);
+}
+
+static void sdhci_adma_mark_end(void *desc)
+{
+	struct sdhci_adma2_64_desc *dma_desc = desc;
+
+	/* 32-bit and 64-bit descriptors have 'cmd' in same position */
+	dma_desc->cmd |= cpu_to_le16(ADMA2_END);
+}
+
+static int sdhci_adma_table_pre(struct sdhci_host *host,
+	struct mmc_data *data)
+{
+	int direction;
+
+	void *desc;
+	void *align;
+	dma_addr_t addr;
+	dma_addr_t align_addr;
+	int len, offset;
+
+	struct scatterlist *sg;
+	int i;
+	char *buffer;
+	unsigned long flags;
+
+	/*
+	 * The spec does not specify endianness of descriptor table.
+	 * We currently guess that it is LE.
+	 */
+
+	if (data->flags & MMC_DATA_READ)
+		direction = DMA_FROM_DEVICE;
+	else
+		direction = DMA_TO_DEVICE;
+
+	host->align_addr = dma_map_single(mmc_dev(host->mmc),
+		host->align_buffer, host->align_buffer_sz, direction);
+	if (dma_mapping_error(mmc_dev(host->mmc), host->align_addr))
+		goto fail;
+	BUG_ON(host->align_addr & host->align_mask);
+
+	host->sg_count = sdhci_pre_dma_transfer(host, data, NULL);
+	if (host->sg_count < 0)
+		goto unmap_align;
+
+	desc = host->adma_table;
+	align = host->align_buffer;
+
+	align_addr = host->align_addr;
+
+	for_each_sg(data->sg, sg, host->sg_count, i) {
+		addr = sg_dma_address(sg);
+		len = sg_dma_len(sg);
+
+		/*
+		 * The SDHCI specification states that ADMA
+		 * addresses must be 32-bit aligned. If they
+		 * aren't, then we use a bounce buffer for
+		 * the (up to three) bytes that screw up the
+		 * alignment.
+		 */
+		offset = (host->align_sz - (addr & host->align_mask)) &
+			 host->align_mask;
+		if (offset) {
+			if (data->flags & MMC_DATA_WRITE) {
+				buffer = sdhci_kmap_atomic(sg, &flags);
+				memcpy(align, buffer, offset);
+				sdhci_kunmap_atomic(buffer, &flags);
+			}
+
+			/* tran, valid */
+			sdhci_adma_write_desc(host, desc, align_addr, offset,
+					      ADMA2_TRAN_VALID);
+
+			BUG_ON(offset > 65536);
+
+			align += host->align_sz;
+			align_addr += host->align_sz;
+
+			desc += host->desc_sz;
+
+			addr += offset;
+			len -= offset;
+		}
+
+		BUG_ON(len > 65536);
+
+		/* tran, valid */
+		sdhci_adma_write_desc(host, desc, addr, len, ADMA2_TRAN_VALID);
+		desc += host->desc_sz;
+
+		/*
+		 * If this triggers then we have a calculation bug
+		 * somewhere. :/
+		 */
+		WARN_ON((desc - host->adma_table) >= host->adma_table_sz);
+	}
+
+	if (host->quirks & SDHCI_QUIRK_NO_ENDATTR_IN_NOPDESC) {
+		/*
+		* Mark the last descriptor as the terminating descriptor
+		*/
+		if (desc != host->adma_table) {
+			desc -= host->desc_sz;
+			sdhci_adma_mark_end(desc);
+		}
+	} else {
+		/*
+		* Add a terminating entry.
+		*/
+
+		/* nop, end, valid */
+		sdhci_adma_write_desc(host, desc, 0, 0, ADMA2_NOP_END_VALID);
+	}
+
+	/*
+	 * Resync align buffer as we might have changed it.
+	 */
+	if (data->flags & MMC_DATA_WRITE) {
+		dma_sync_single_for_device(mmc_dev(host->mmc),
+			host->align_addr, host->align_buffer_sz, direction);
+	}
+
+	return 0;
+
+unmap_align:
+	dma_unmap_single(mmc_dev(host->mmc), host->align_addr,
+		host->align_buffer_sz, direction);
+fail:
+	return -EINVAL;
+}
+
+static void sdhci_adma_table_post(struct sdhci_host *host,
+	struct mmc_data *data)
+{
+	int direction;
+
+	struct scatterlist *sg;
+	int i, size;
+	void *align;
+	char *buffer;
+	unsigned long flags;
+	bool has_unaligned;
+
+	if (data->flags & MMC_DATA_READ)
+		direction = DMA_FROM_DEVICE;
+	else
+		direction = DMA_TO_DEVICE;
+
+	dma_unmap_single(mmc_dev(host->mmc), host->align_addr,
+		host->align_buffer_sz, direction);
+
+	/* Do a quick scan of the SG list for any unaligned mappings */
+	has_unaligned = false;
+	for_each_sg(data->sg, sg, host->sg_count, i)
+		if (sg_dma_address(sg) & host->align_mask) {
+			has_unaligned = true;
+			break;
+		}
+
+	if (has_unaligned && data->flags & MMC_DATA_READ) {
+		dma_sync_sg_for_cpu(mmc_dev(host->mmc), data->sg,
+			data->sg_len, direction);
+
+		align = host->align_buffer;
+
+		for_each_sg(data->sg, sg, host->sg_count, i) {
+			if (sg_dma_address(sg) & host->align_mask) {
+				size = host->align_sz -
+				       (sg_dma_address(sg) & host->align_mask);
+
+				buffer = sdhci_kmap_atomic(sg, &flags);
+				memcpy(buffer, align, size);
+				sdhci_kunmap_atomic(buffer, &flags);
+
+				align += host->align_sz;
+			}
+		}
+	}
+
+	if (!data->host_cookie)
+		dma_unmap_sg(mmc_dev(host->mmc), data->sg,
+			data->sg_len, direction);
+}
+
+static u8 sdhci_calc_timeout(struct sdhci_host *host, struct mmc_command *cmd)
+{
+	u8 count;
+	struct mmc_data *data = cmd->data;
+	unsigned target_timeout, current_timeout;
+
+	/*
+	 * If the host controller provides us with an incorrect timeout
+	 * value, just skip the check and use 0xE.  The hardware may take
+	 * longer to time out, but that's much better than having a too-short
+	 * timeout value.
+	 */
+	if (host->quirks & SDHCI_QUIRK_BROKEN_TIMEOUT_VAL)
+		return 0xE;
+
+	/* Unspecified timeout, assume max */
+	if (!data && !cmd->busy_timeout)
+		return 0xE;
+
+	/* timeout in us */
+	if (!data)
+		target_timeout = cmd->busy_timeout * 1000;
+	else {
+		target_timeout = data->timeout_ns / 1000;
+		if (host->clock)
+			target_timeout += data->timeout_clks / host->clock;
+	}
+
+	/*
+	 * Figure out needed cycles.
+	 * We do this in steps in order to fit inside a 32 bit int.
+	 * The first step is the minimum timeout, which will have a
+	 * minimum resolution of 6 bits:
+	 * (1) 2^13*1000 > 2^22,
+	 * (2) host->timeout_clk < 2^16
+	 *     =>
+	 *     (1) / (2) > 2^6
+	 */
+	count = 0;
+	current_timeout = (1 << 13) * 1000 / host->timeout_clk;
+	while (current_timeout < target_timeout) {
+		count++;
+		current_timeout <<= 1;
+		if (count >= 0xF)
+			break;
+	}
+
+	if (count >= 0xF) {
+		DBG("%s: Too large timeout 0x%x requested for CMD%d!\n",
+		    mmc_hostname(host->mmc), count, cmd->opcode);
+		count = 0xE;
+	}
+
+	return count;
+}
+
+static void sdhci_set_transfer_irqs(struct sdhci_host *host)
+{
+#if 0
+	u32 pio_irqs = SDHCI_INT_DATA_AVAIL | SDHCI_INT_SPACE_AVAIL;
+	u32 dma_irqs = SDHCI_INT_DMA_END | SDHCI_INT_ADMA_ERROR;
+
+	if (host->flags & SDHCI_REQ_USE_DMA)
+		host->ier = (host->ier & ~pio_irqs) | dma_irqs;
+	else
+		host->ier = (host->ier & ~dma_irqs) | pio_irqs;
+
+	sdhci_writel(host, host->ier, SDHCI_INT_ENABLE);
+	sdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);
+#endif
+}
+
+static void sdhci_set_timeout(struct sdhci_host *host, struct mmc_command *cmd)
+{
+#if 0
+	u8 count;
+
+	if (host->ops->set_timeout) {
+		host->ops->set_timeout(host, cmd);
+	} else {
+		count = sdhci_calc_timeout(host, cmd);
+		sdhci_writeb(host, count, SDHCI_TIMEOUT_CONTROL);
+	}
+#else
+	u8 count;
+	u32 ctrl;
+
+	ctrl = sdhci_readl(host, SDHCI_CFG_REG);
+	ctrl &= ~0xff000000;
+
+	count = sdhci_calc_timeout(host, cmd);
+count = 0x20;
+
+	ctrl |= (count << 24);
+	sdhci_writel(host, ctrl, SDHCI_CFG_REG);
+#endif
+}
+
+static void sdhci_prepare_data(struct sdhci_host *host, struct mmc_command *cmd)
+{
+	u8 ctrl;
+	struct mmc_data *data = cmd->data;
+	int ret;
+
+	WARN_ON(host->data);
+
+	if (data || (cmd->flags & MMC_RSP_BUSY))
+		sdhci_set_timeout(host, cmd);
+	
+	if (!data)
+		return;
+	//printk("data->blksz: %u, data->blocks: %u\n", data->blksz, data->blocks);
+	/* Sanity checks */
+	BUG_ON(data->blksz * data->blocks > 524288);
+	BUG_ON(data->blksz > host->mmc->max_blk_size);
+	BUG_ON(data->blocks > 65535);
+
+	host->data = data;
+	host->data_early = 0;
+	host->data->bytes_xfered = 0;
+
+	if (host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA))
+		host->flags |= SDHCI_REQ_USE_DMA;
+
+	/*
+	 * FIXME: This doesn't account for merging when mapping the
+	 * scatterlist.
+	 */
+	if (host->flags & SDHCI_REQ_USE_DMA) {
+		int broken, i;
+		struct scatterlist *sg;
+
+		broken = 0;
+		if (host->flags & SDHCI_USE_ADMA) {
+			if (host->quirks & SDHCI_QUIRK_32BIT_ADMA_SIZE)
+				broken = 1;
+		} else {
+			if (host->quirks & SDHCI_QUIRK_32BIT_DMA_SIZE)
+				broken = 1;
+		}
+
+		if (unlikely(broken)) {
+			for_each_sg(data->sg, sg, data->sg_len, i) {
+				if (sg->length & 0x3) {
+					DBG("Reverting to PIO because of "
+						"transfer size (%d)\n",
+						sg->length);
+					host->flags &= ~SDHCI_REQ_USE_DMA;
+					break;
+				}
+			}
+		}
+	}
+
+	/*
+	 * The assumption here being that alignment is the same after
+	 * translation to device address space.
+	 */
+	if (host->flags & SDHCI_REQ_USE_DMA) {
+		int broken, i;
+		struct scatterlist *sg;
+
+		broken = 0;
+		if (host->flags & SDHCI_USE_ADMA) {
+			/*
+			 * As we use 3 byte chunks to work around
+			 * alignment problems, we need to check this
+			 * quirk.
+			 */
+			if (host->quirks & SDHCI_QUIRK_32BIT_ADMA_SIZE)
+				broken = 1;
+		} else {
+			if (host->quirks & SDHCI_QUIRK_32BIT_DMA_ADDR)
+				broken = 1;
+		}
+
+		if (unlikely(broken)) {
+			for_each_sg(data->sg, sg, data->sg_len, i) {
+				if (sg->offset & 0x3) {
+					DBG("Reverting to PIO because of "
+						"bad alignment\n");
+					host->flags &= ~SDHCI_REQ_USE_DMA;
+					break;
+				}
+			}
+		}
+	}
+
+	sdhci_writel(host, sdhci_readl(host, SDHCI_DMA_STA_REG), SDHCI_DMA_STA_REG);
+
+	if (host->flags & SDHCI_REQ_USE_DMA) {
+		if (host->flags & SDHCI_USE_ADMA) {
+			if (data->flags & MMC_DATA_WRITE) {
+				sdhci_writel(host, 0x00000C00, SDHCI_DMA_CTL_REG);
+			} else {
+				sdhci_writel(host, 0x80000C00, SDHCI_DMA_CTL_REG);
+			}
+
+			ret = sdhci_adma_table_pre(host, data);
+			if (ret) {
+				/*
+				 * This only happens when someone fed
+				 * us an invalid request.
+				 */
+				WARN_ON(1);
+				host->flags &= ~SDHCI_REQ_USE_DMA;
+			} else {
+//				sdhci_writel(host, host->adma_addr,
+//					SDHCI_ADMA_ADDRESS);
+				sdhci_writel(host, host->adma_addr,
+					SDHCI_ADMA_SADDR_REG);
+				if (host->flags & SDHCI_USE_64_BIT_DMA)
+					sdhci_writel(host,
+						     (u64)host->adma_addr >> 32,
+						     SDHCI_ADMA_ADDRESS_HI);
+			}
+		} else {
+			int sg_cnt;
+
+			if (data->flags & MMC_DATA_WRITE) {
+				sdhci_writel(host, 0x00000200, SDHCI_DMA_CTL_REG);
+			} else {
+				sdhci_writel(host, 0x80000200, SDHCI_DMA_CTL_REG);
+			}
+
+			sg_cnt = sdhci_pre_dma_transfer(host, data, NULL);
+			if (sg_cnt <= 0) {
+				/*
+				 * This only happens when someone fed
+				 * us an invalid request.
+				 */
+				WARN_ON(1);
+				host->flags &= ~SDHCI_REQ_USE_DMA;
+			} else {
+				WARN_ON(sg_cnt != 1);
+//				sdhci_writel(host, sg_dma_address(data->sg),
+//					SDHCI_DMA_ADDRESS);
+				
+#ifdef USE_SRAM
+				if(data->flags & MMC_DATA_READ){
+						//printk("read dma address: 0x%llx replace to sram: 0x%x len: %u\n", 
+						//	sg_dma_address(data->sg), host->sram, sg_dma_len(data->sg));
+				}else {
+					if(sg_dma_len(data->sg) > (SRAM_SIZE))
+						printk("write dma address: 0x%llx replace to sram: 0x%x len: %u\n", 
+							sg_dma_address(data->sg), host->sram, sg_dma_len(data->sg));
+					memcpy(host->sram_addr, sg_virt(host->data->sg), sg_dma_len(data->sg));
+				}
+				sdhci_writel(host,  host->sram, SDHCI_SDMA_SADDR_REG);
+#else
+				printk("dma address: 0x%llx, len: %u\n", sg_dma_address(data->sg), sg_dma_len(data->sg));
+				sdhci_writel(host, sg_dma_address(data->sg),
+					SDHCI_SDMA_SADDR_REG);
+#endif
+	
+				sdhci_writel(host, sg_dma_len(data->sg),
+					SDHCI_SDMA_LEN_REG);
+
+			}
+		}
+	}
+
+	/*
+	 * Always adjust the DMA selection as some controllers
+	 * (e.g. JMicron) can't do PIO properly when the selection
+	 * is ADMA.
+	 */
+	if (host->version >= SDHCI_SPEC_200) {
+//		ctrl = sdhci_readb(host, SDHCI_HOST_CONTROL);
+		ctrl &= ~SDHCI_CTRL_DMA_MASK;
+		if ((host->flags & SDHCI_REQ_USE_DMA) &&
+			(host->flags & SDHCI_USE_ADMA)) {
+			if (host->flags & SDHCI_USE_64_BIT_DMA)
+				ctrl |= SDHCI_CTRL_ADMA64;
+			else
+				ctrl |= SDHCI_CTRL_ADMA32;
+		} else {
+			ctrl |= SDHCI_CTRL_SDMA;
+		}
+//		sdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);
+	}
+
+	if (!(host->flags & SDHCI_REQ_USE_DMA)) {
+		int flags;
+
+		flags = SG_MITER_ATOMIC;
+		if (host->data->flags & MMC_DATA_READ)
+			flags |= SG_MITER_TO_SG;
+		else
+			flags |= SG_MITER_FROM_SG;
+		sg_miter_start(&host->sg_miter, data->sg, data->sg_len, flags);
+		host->blocks = data->blocks;
+	}
+
+	sdhci_set_transfer_irqs(host);
+
+	/* Set the DMA boundary value and block size */
+//	sdhci_writew(host, SDHCI_MAKE_BLKSZ(SDHCI_DEFAULT_BOUNDARY_ARG,
+//		data->blksz), SDHCI_BLOCK_SIZE);
+	sdhci_writel(host, data->blocks, SDHCI_BLOCK_COUNT);
+	//pr_info(KERN_INFO "data blocks %d\n", data->blocks);
+}
+
+static void sdhci_set_transfer_mode(struct sdhci_host *host,
+	struct mmc_command *cmd)
+{
+#if 0
+	u16 mode = 0;
+	struct mmc_data *data = cmd->data;
+
+	if (data == NULL) {
+		if (host->quirks2 &
+			SDHCI_QUIRK2_CLEAR_TRANSFERMODE_REG_BEFORE_CMD) {
+			sdhci_writew(host, 0x0, SDHCI_TRANSFER_MODE);
+		} else {
+		/* clear Auto CMD settings for no data CMDs */
+			mode = sdhci_readw(host, SDHCI_TRANSFER_MODE);
+			sdhci_writew(host, mode & ~(SDHCI_TRNS_AUTO_CMD12 |
+				SDHCI_TRNS_AUTO_CMD23), SDHCI_TRANSFER_MODE);
+		}
+		return;
+	}
+
+	WARN_ON(!host->data);
+
+	if (!(host->quirks2 & SDHCI_QUIRK2_SUPPORT_SINGLE))
+		mode = SDHCI_TRNS_BLK_CNT_EN;
+
+	if (mmc_op_multi(cmd->opcode) || data->blocks > 1) {
+		mode = SDHCI_TRNS_BLK_CNT_EN | SDHCI_TRNS_MULTI;
+		/*
+		 * If we are sending CMD23, CMD12 never gets sent
+		 * on successful completion (so no Auto-CMD12).
+		 */
+		if (!host->mrq->sbc && (host->flags & SDHCI_AUTO_CMD12) &&
+		    (cmd->opcode != SD_IO_RW_EXTENDED))
+			mode |= SDHCI_TRNS_AUTO_CMD12;
+		else if (host->mrq->sbc && (host->flags & SDHCI_AUTO_CMD23)) {
+			mode |= SDHCI_TRNS_AUTO_CMD23;
+			sdhci_writel(host, host->mrq->sbc->arg, SDHCI_ARGUMENT2);
+		}
+	}
+
+	if (data->flags & MMC_DATA_READ)
+		mode |= SDHCI_TRNS_READ;
+	if (host->flags & SDHCI_REQ_USE_DMA)
+		mode |= SDHCI_TRNS_DMA;
+
+	sdhci_writew(host, mode, SDHCI_TRANSFER_MODE);
+#endif
+}
+
+static void sdhci_finish_data(struct sdhci_host *host)
+{
+	struct mmc_data *data;
+	//pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(host->mmc), __func__);
+	
+	BUG_ON(!host->data);
+#ifdef USE_SRAM
+	if(host->data->error == 0 && (host->data->flags & MMC_DATA_READ) ){
+		memcpy(sg_virt(host->data->sg), host->sram_addr, sg_dma_len(host->data->sg));
+	}
+	
+#endif
+	data = host->data;
+	host->data = NULL;
+
+	if (host->flags & SDHCI_REQ_USE_DMA) {
+		
+		if (host->flags & SDHCI_USE_ADMA)
+			sdhci_adma_table_post(host, data);
+		else {
+			if (!data->host_cookie)
+				dma_unmap_sg(mmc_dev(host->mmc),
+					data->sg, data->sg_len,
+					(data->flags & MMC_DATA_READ) ?
+					DMA_FROM_DEVICE : DMA_TO_DEVICE);
+		}
+		
+	}
+
+	/*
+	 * The specification states that the block count register must
+	 * be updated, but it does not specify at what point in the
+	 * data flow. That makes the register entirely useless to read
+	 * back so we have to assume that nothing made it to the card
+	 * in the event of an error.
+	 */
+	if (data->error)
+		data->bytes_xfered = 0;
+	else
+		data->bytes_xfered = data->blksz * data->blocks;
+
+	/*
+	 * Need to send CMD12 if -
+	 * a) open-ended multiblock transfer (no CMD23)
+	 * b) error in multiblock transfer
+	 */
+	if (data->stop &&
+	    (data->error ||
+	     !host->mrq->sbc)) {
+
+		/*
+		 * The controller needs a reset of internal state machines
+		 * upon error conditions.
+		 */
+		
+		if (data->error) {
+			sdhci_w3k_flush_dma(host);
+
+			sdhci_do_reset(host, SDHCI_RESET_CMD);
+//			sdhci_do_reset(host, SDHCI_RESET_DATA);
+		}
+		
+		sdhci_send_command(host, data->stop);
+	} else
+		tasklet_schedule(&host->finish_tasklet);
+	
+}
+
+void sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)
+{
+	int flags;
+	u32 mask;
+	unsigned long timeout;
+	struct mmc_data *data = cmd->data;
+	u32 command, autocmd;
+	//if((cmd->opcode & 0x3F) != 13)
+	//	printk(KERN_INFO "cmd:%d,arg:%d,flags:0x%x,resp[0]:0x%x,resp[1]:0x%x,resp[2]:0x%x,resp[3]:0x%x\n", 
+	//		(cmd->opcode & 0x3F), cmd->arg, cmd->flags,cmd->resp[0], cmd->resp[1],cmd->resp[2],cmd->resp[3]);
+	//pr_info(KERN_INFO "%s : %s(%d)\n", mmc_hostname(host->mmc), __func__,
+	//				(cmd->opcode & 0x3F));
+
+	WARN_ON(host->cmd);
+
+	/* Wait max 10 ms */
+	timeout = 10;
+
+	mask = SDHCI_CMD_INHIBIT;
+	if ((cmd->data != NULL) || (cmd->flags & MMC_RSP_BUSY))
+		mask |= SDHCI_DATA_INHIBIT;
+
+	/* We shouldn't wait for data inihibit for stop commands, even
+	   though they might use busy signaling */
+	if (host->mrq->data && (cmd == host->mrq->data->stop))
+		mask &= ~SDHCI_DATA_INHIBIT;
+
+#if 0
+	while (sdhci_readl(host, SDHCI_PRESENT_STATE) & mask) {
+		if (timeout == 0) {
+			pr_err("%s: Controller never released "
+				"inhibit bit(s).\n", mmc_hostname(host->mmc));
+			sdhci_dumpregs(host);
+			cmd->error = -EIO;
+			tasklet_schedule(&host->finish_tasklet);
+			return;
+		}
+		timeout--;
+		mdelay(1);
+	}
+#endif
+
+	timeout = jiffies;
+	if (!cmd->data && cmd->busy_timeout > 9000)
+		timeout += DIV_ROUND_UP(cmd->busy_timeout, 1000) * HZ + HZ;
+	else
+		timeout += 10 * HZ;
+	mod_timer(&host->timer, timeout);
+
+	host->cmd = cmd;
+	host->busy_handle = 0;
+	host->resp_flag = 0;
+
+	sdhci_disable_card_detect(host);
+
+	sdhci_prepare_data(host, cmd);
+
+	sdhci_writel(host, cmd->arg, SDHCI_ARGUMENT);
+
+	sdhci_set_transfer_mode(host, cmd);
+
+	if ((cmd->flags & MMC_RSP_136) && (cmd->flags & MMC_RSP_BUSY)) {
+		pr_err("%s: Unsupported response type!\n",
+			mmc_hostname(host->mmc));
+		cmd->error = -EINVAL;
+		tasklet_schedule(&host->finish_tasklet);
+		return;
+	}
+
+	if (!(cmd->flags & MMC_RSP_PRESENT))
+		flags = SDHCI_CMD_RESP_NONE;
+	else if (cmd->flags & MMC_RSP_136)
+		flags = SDHCI_CMD_RESP_LONG;
+	else if (cmd->flags & MMC_RSP_BUSY)
+		flags = SDHCI_CMD_RESP_SHORT_BUSY;
+	else
+		flags = SDHCI_CMD_RESP_SHORT;
+
+	if (cmd->flags & MMC_RSP_CRC)
+		flags |= SDHCI_CMD_CRC;
+	if (cmd->flags & MMC_RSP_OPCODE)
+		flags |= SDHCI_CMD_INDEX;
+
+	/* CMD19 is special in that the Data Present Select should be set */
+	if (cmd->data || cmd->opcode == MMC_SEND_TUNING_BLOCK ||
+	    cmd->opcode == MMC_SEND_TUNING_BLOCK_HS200)
+		flags |= SDHCI_CMD_DATA;
+
+	command = (cmd->opcode & 0x3F);
+
+	if (cmd->flags & MMC_RSP_CRC)
+		command |= (1 << 30);
+
+	if (cmd->opcode == MMC_SEND_TUNING_BLOCK) {
+		command |= (3 << 28);
+
+		if (host->mmc->ios.bus_width == MMC_BUS_WIDTH_8)
+			command |= (128 << 16);
+		else if (host->mmc->ios.bus_width == MMC_BUS_WIDTH_4)
+			command |= (64 << 16);
+
+		command |= (1 << 11);
+
+		autocmd = cmd->opcode;
+		autocmd |= (SDHCI_W3K_RESP_R1 << 7);
+		autocmd |= (1 << 10);
+		autocmd |= (1 << 11);	/* single block */
+		autocmd |= (0 << 14);
+		autocmd |= (1 << 30);
+		sdhci_writel(host, autocmd, SDHCI_ACMD_REG);
+	} else if (cmd->opcode == MMC_SEND_TUNING_BLOCK_HS200) {
+		command |= (3 << 28);
+
+		command |= (128 << 16);
+		command |= (1 << 11);
+
+		autocmd = cmd->opcode;
+		autocmd |= (SDHCI_W3K_RESP_R1 << 7);
+		autocmd |= (1 << 10);
+		autocmd |= (1 << 11);	/* single block */
+		autocmd |= (0 << 14);
+		autocmd |= (1 << 30);
+		sdhci_writel(host, autocmd, SDHCI_ACMD_REG);
+	} else if (cmd->opcode == MMC_SET_BLOCK_COUNT) {
+		command |= (2 << 28);
+
+		autocmd = cmd->opcode;
+		autocmd |= (SDHCI_W3K_RESP_R1 << 7);
+		autocmd |= (1 << 10);
+		autocmd |= (0 << 11);	/* no data */
+		autocmd |= (0 << 14);
+		autocmd |= (1 << 30);
+		sdhci_writel(host, autocmd, SDHCI_ACMD_REG);
+#if 0
+	} else if (cmd->opcode == MMC_STOP_TRANSMISSION) {
+		command |= (1 << 28);
+
+		autocmd = cmd->opcode;
+		autocmd |= (SDHCI_W3K_RESP_R1B << 7);	// [9:7],   artyp[2:]
+		autocmd |= (1 << 10);				// [10]:    ar1_cst
+		autocmd |= (0 << 11);	/* no data */		// [12:11]: adtyp[1:0]
+		autocmd |= (1 << 14);				// [14]:    astop
+		autocmd |= (1 << 30);				// [30]:    achk_c7
+		sdhci_writel(host, autocmd, SDHCI_ACMD_REG);
+#endif
+	}
+
+	if (data) {
+		/* set controller data length */
+		command |= ((data->blksz & 0xFFF) << 16);
+
+		/* set controller block count */
+		if (data->blocks == 1) {
+			command |= (1 << 11);
+		} else if (data->blocks > 1) {
+			command |= (2 << 11);
+		}
+
+		if (data->flags & MMC_DATA_WRITE) {
+			command |= (1 << 13);
+		}
+	}
+
+	/* Translate mmc_resp_type(cmd) to known form of w3k sd/mmc controller */
+	switch (mmc_resp_type(cmd)) {
+	case MMC_RSP_NONE:
+		flags = SDHCI_W3K_RESP_NO;
+		DBG("SDHCI_W3K_RESP_NO\n");
+		break;
+	case MMC_RSP_R1:	/* MMC_RSP_R5 | MMC_RSP_R6 | MMC_RSP_R7 */
+	case (MMC_RSP_PRESENT | MMC_RSP_OPCODE):
+		flags = SDHCI_W3K_RESP_R1;
+		DBG("SDHCI_W3K_RESP_R1\n");
+		break;
+	case MMC_RSP_R1B:
+		flags = SDHCI_W3K_RESP_R1B;
+		DBG("SDHCI_W3K_RESP_R1B\n");
+		break;
+	case MMC_RSP_R2:
+		flags = SDHCI_W3K_RESP_R2;
+		DBG("SDHCI_W3K_RESP_R2\n");
+		break;
+	case MMC_RSP_R3:	/* MMC_RSP_R4 */
+		flags = SDHCI_W3K_RESP_R3;
+		DBG("SDHCI_W3K_RESP_R3\n");
+		break;
+	default :
+		printk("Unknown response type (0x%x)!!!\n", mmc_resp_type(cmd));
+		flags = SDHCI_W3K_RESP_NO;
+		break;
+	}
+
+	/* clear status bits */
+	sdhci_writel(host, sdhci_readl(host, SDHCI_INT_STATUS), SDHCI_INT_STATUS);
+
+	/* write command, arg, resptype registers */
+	sdhci_writel(host, SDHCI_MAKE_CMD(cmd->opcode, flags)|command, SDHCI_COMMAND);
+	DBG("write reg - SDHCI_COMMAND 0x%x\n", SDHCI_MAKE_CMD(cmd->opcode, flags)|command);
+#ifdef USE_SRAM
+out:
+	return;
+#endif
+}
+EXPORT_SYMBOL_GPL(sdhci_send_command);
+
+static void sdhci_finish_command(struct sdhci_host *host)
+{
+	int i;
+
+	//pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	BUG_ON(host->cmd == NULL);
+
+	if (host->cmd->flags & MMC_RSP_PRESENT) {
+		if (host->cmd->flags & MMC_RSP_136) {
+			/* CRC is stripped so we need to do some shifting. */
+			for (i = 0;i < 4;i++) {
+#if 0
+				host->cmd->resp[i] = sdhci_readl(host,
+					SDHCI_RESPONSE + (3-i)*4) << 8;
+				if (i != 3)
+					host->cmd->resp[i] |=
+						sdhci_readb(host,
+						SDHCI_RESPONSE + (3-i)*4-1);
+#else
+				host->cmd->resp[i] = sdhci_readl(host,
+					SDHCI_RESPONSE + (3-i)*4);
+#endif
+			}
+		} else {
+			host->cmd->resp[0] = sdhci_readl(host, SDHCI_RESPONSE);
+		}
+	}
+
+	host->cmd->error = 0;
+
+	/* Finished CMD23, now send actual command. */
+	if (host->cmd == host->mrq->sbc) {
+		host->cmd = NULL;
+		sdhci_send_command(host, host->mrq->cmd);
+	} else {
+		/* Processed actual command. */
+		if (host->data && host->data_early)
+			sdhci_finish_data(host);
+
+		if (!host->cmd->data)
+			tasklet_schedule(&host->finish_tasklet);
+
+		host->cmd = NULL;
+	}
+}
+
+static u16 sdhci_get_preset_value(struct sdhci_host *host)
+{
+	u16 preset = 0;
+
+	switch (host->timing) {
+	case MMC_TIMING_UHS_SDR12:
+		preset = sdhci_readw(host, SDHCI_PRESET_FOR_SDR12);
+		break;
+	case MMC_TIMING_UHS_SDR25:
+		preset = sdhci_readw(host, SDHCI_PRESET_FOR_SDR25);
+		break;
+	case MMC_TIMING_UHS_SDR50:
+		preset = sdhci_readw(host, SDHCI_PRESET_FOR_SDR50);
+		break;
+	case MMC_TIMING_UHS_SDR104:
+	case MMC_TIMING_MMC_HS200:
+		preset = sdhci_readw(host, SDHCI_PRESET_FOR_SDR104);
+		break;
+	case MMC_TIMING_UHS_DDR50:
+		preset = sdhci_readw(host, SDHCI_PRESET_FOR_DDR50);
+		break;
+	case MMC_TIMING_MMC_HS400:
+		preset = sdhci_readw(host, SDHCI_PRESET_FOR_HS400);
+		break;
+	default:
+		pr_warn("%s: Invalid UHS-I mode selected\n",
+			mmc_hostname(host->mmc));
+		preset = sdhci_readw(host, SDHCI_PRESET_FOR_SDR12);
+		break;
+	}
+	return preset;
+}
+
+void sdhci_set_clock(struct sdhci_host *host, unsigned int clock)
+{
+	int div = 0; /* Initialized for compiler warning */
+	int real_div = div, clk_mul = 1;
+	u32 clk = 0;
+	unsigned long timeout;
+
+	host->mmc->actual_clock = 0;
+
+	if (clock == 0)
+		return;
+
+	if (host->version >= SDHCI_SPEC_300) {
+		if (host->preset_enabled) {
+			u16 pre_val;
+
+			clk = sdhci_readw(host, SDHCI_CLOCK_CONTROL);
+			pre_val = sdhci_get_preset_value(host);
+			div = (pre_val & SDHCI_PRESET_SDCLK_FREQ_MASK)
+				>> SDHCI_PRESET_SDCLK_FREQ_SHIFT;
+			if (host->clk_mul &&
+				(pre_val & SDHCI_PRESET_CLKGEN_SEL_MASK)) {
+				clk = SDHCI_PROG_CLOCK_MODE;
+				real_div = div + 1;
+				clk_mul = host->clk_mul;
+			} else {
+				real_div = max_t(int, 1, div << 1);
+			}
+			goto clock_set;
+		}
+
+		/*
+		 * Check if the Host Controller supports Programmable Clock
+		 * Mode.
+		 */
+		if (host->clk_mul) {
+			for (div = 1; div <= 1024; div++) {
+				if ((host->max_clk * host->clk_mul / div)
+					<= clock)
+					break;
+			}
+			/*
+			 * Set Programmable Clock Mode in the Clock
+			 * Control register.
+			 */
+			clk = SDHCI_PROG_CLOCK_MODE;
+			real_div = div;
+			clk_mul = host->clk_mul;
+			div--;
+		} else {
+			/* Version 3.00 divisors must be a multiple of 2. */
+			if (host->max_clk <= clock)
+				div = 1;
+			else {
+				for (div = 2; div < SDHCI_MAX_DIV_SPEC_300;
+				     div += 2) {
+					if ((host->max_clk / div) <= clock)
+						break;
+				}
+			}
+			real_div = div;
+			div >>= 1;
+		}
+	} else {
+		/* Version 2.00 divisors must be a power of 2. */
+		for (div = 1; div < SDHCI_MAX_DIV_SPEC_200; div *= 2) {
+			if ((host->max_clk / div) <= clock)
+				break;
+		}
+		real_div = div;
+		div >>= 1;
+	}
+
+clock_set:
+	if (real_div)
+		host->mmc->actual_clock = (host->max_clk * clk_mul) / real_div;
+
+	clk = sdhci_readl(host, SDHCI_CK_REG);
+	clk &= ~(0x003FFF00);
+
+	if (div == 0)
+		clk |= 0x00200000;
+	else {
+		clk |= ((div - 1) & SDHCI_DIV_MASK) << SDHCI_DIVIDER_SHIFT;
+//		clk |= ((div & SDHCI_DIV_HI_MASK) >> SDHCI_DIV_MASK_LEN)
+//			<< SDHCI_DIVIDER_HI_SHIFT;
+//		clk |= SDHCI_CLOCK_INT_EN;
+	}
+//	sdhci_writew(host, clk, SDHCI_CLOCK_CONTROL);
+	sdhci_writel(host, clk, SDHCI_CK_REG);
+
+	//printk("%s : actual clock : %d\n",
+	//		mmc_hostname(host->mmc), host->mmc->actual_clock);
+
+	/* Wait max 20 ms */
+	timeout = 20000;
+//	while (!((clk = sdhci_readw(host, SDHCI_CLOCK_CONTROL))
+//		& SDHCI_CLOCK_INT_STABLE)) {
+	while (sdhci_readl(host, SDHCI_CK_REG)
+		& SDHCI_CLOCK_INT_STABLE) {
+		if (timeout == 0) {
+			pr_err("%s: Internal clock never "
+				"stabilised.\n", mmc_hostname(host->mmc));
+			sdhci_dumpregs(host);
+			return;
+		}
+		timeout--;
+		//mdelay(1);
+	}
+
+//	clk |= SDHCI_CLOCK_CARD_EN;
+//	sdhci_writew(host, clk, SDHCI_CLOCK_CONTROL);
+}
+EXPORT_SYMBOL_GPL(sdhci_set_clock);
+
+static void sdhci_set_power(struct sdhci_host *host, unsigned char mode,
+			    unsigned short vdd)
+{
+	u8 pwr = 0;
+	u32 val;
+	//void __iomem *base = ioremap(0xFFE54000, 0x1000);
+
+	//pr_info(KERN_INFO "%s : %s(0x%x)\n", mmc_hostname(mmc), __func__, vdd);
+#if 0
+	if (!IS_ERR(mmc->supply.vmmc)) {
+		spin_unlock_irq(&host->lock);
+		mmc_regulator_set_ocr(mmc, mmc->supply.vmmc, vdd);
+		spin_lock_irq(&host->lock);
+
+		/* set IO Power Config */
+		pwr_cfg = readl(base + 0xF00);
+
+		switch (1 << vdd) {
+		case MMC_VDD_165_195:
+			if (host->slot_id == SLOT_EMMC) {
+				pwr_cfg &= ~0x3;
+			} else if (host->slot_id == SLOT_SD) {
+				pwr_cfg &= ~0xC;
+			}
+			break;
+		case MMC_VDD_29_30:
+		case MMC_VDD_30_31:
+			break;
+		case MMC_VDD_32_33:
+		case MMC_VDD_33_34:
+			if (host->slot_id == SLOT_EMMC) {
+				pwr_cfg |= 0x3;
+			} else if (host->slot_id == SLOT_SD) {
+				pwr_cfg |= 0xC;
+			}
+			break;
+		default:
+			printk("%s : %s(0x%x)\n", mmc_hostname(mmc), __func__, vdd);
+			break;
+		}
+
+		writel(pwr_cfg, base + 0xF00);
+
+		val = sdhci_readl(host, SDHCI_CK_REG);
+		DBG("read reg - SDHCI_CK_REG 0x%x\n", val);
+		if (mode != MMC_POWER_OFF) {
+//			sdhci_writeb(host, SDHCI_POWER_ON, SDHCI_POWER_CONTROL);
+			sdhci_writel(host, val & ~(0x10), SDHCI_CK_REG);
+		} else {
+//			sdhci_writeb(host, 0, SDHCI_POWER_CONTROL);
+//			sdhci_writel(host, val | 0x10, SDHCI_CK_REG);
+		}
+		DBG("write reg - SDHCI_CK_REG 0x%x\n", val);
+		return;
+	}
+#endif
+	if (mode != MMC_POWER_OFF) {
+		switch (1 << vdd) {
+		case MMC_VDD_165_195:
+//			printk("SDHCI_POWER_180\n");
+			pwr = SDHCI_POWER_180;
+			break;
+		case MMC_VDD_29_30:
+		case MMC_VDD_30_31:
+//			printk("SDHCI_POWER_300\n");
+			pwr = SDHCI_POWER_300;
+			break;
+		case MMC_VDD_32_33:
+		case MMC_VDD_33_34:
+//			printk("SDHCI_POWER_330\n");
+			pwr = SDHCI_POWER_330;
+			break;
+		default:
+			BUG();
+		}
+	}
+
+	if (host->pwr == pwr)
+		return;
+
+	host->pwr = pwr;
+
+	if (pwr == 0) {
+//		sdhci_writeb(host, 0, SDHCI_POWER_CONTROL);
+		val = sdhci_readl(host, SDHCI_CK_REG);
+		DBG("read reg - SDHCI_CK_REG 0x%x\n", val);
+		sdhci_writel(host, (val | SDCK_SD_OFF), SDHCI_CK_REG);
+		DBG("write reg - SDHCI_CK_REG 0x%x\n", (val | SDCK_SD_OFF));
+		if (host->quirks2 & SDHCI_QUIRK2_CARD_ON_NEEDS_BUS_ON)
+			sdhci_runtime_pm_bus_off(host);
+		vdd = 0;
+	} else {
+		/*
+		 * Spec says that we should clear the power reg before setting
+		 * a new value. Some controllers don't seem to like this though.
+		 */
+		if (!(host->quirks & SDHCI_QUIRK_SINGLE_POWER_WRITE)) {
+//			sdhci_writeb(host, 0, SDHCI_POWER_CONTROL);
+			val = sdhci_readl(host, SDHCI_CK_REG);
+			DBG("read reg - SDHCI_CK_REG 0x%x\n", val);
+			sdhci_writel(host, (val | SDCK_SD_OFF), SDHCI_CK_REG);
+			DBG("write reg - SDHCI_CK_REG 0x%x\n", (val | SDCK_SD_OFF));
+		}
+
+		/*
+		 * At least the Marvell CaFe chip gets confused if we set the
+		 * voltage and set turn on power at the same time, so set the
+		 * voltage first.
+		 */
+		if (host->quirks & SDHCI_QUIRK_NO_SIMULT_VDD_AND_POWER)
+			sdhci_writeb(host, pwr, SDHCI_POWER_CONTROL);
+
+		pwr |= SDHCI_POWER_ON;
+
+//		sdhci_writeb(host, pwr, SDHCI_POWER_CONTROL);
+		val = sdhci_readl(host, SDHCI_CK_REG);
+		DBG("read reg - SDHCI_CK_REG 0x%x\n", val);
+		sdhci_writel(host, (val & (~SDCK_SD_OFF)), SDHCI_CK_REG);
+		DBG("write reg - SDHCI_CK_REG 0x%x\n", (val & (~SDCK_SD_OFF)));
+
+		if (host->quirks2 & SDHCI_QUIRK2_CARD_ON_NEEDS_BUS_ON)
+			sdhci_runtime_pm_bus_on(host);
+
+		/*
+		 * Some controllers need an extra 10ms delay of 10ms before
+		 * they can apply clock after applying power
+		 */
+		if (host->quirks & SDHCI_QUIRK_DELAY_AFTER_POWER)
+			mdelay(10);
+	}
+}
+
+/*****************************************************************************\
+ *                                                                           *
+ * MMC callbacks                                                             *
+ *                                                                           *
+\*****************************************************************************/
+
+static void sdhci_request(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct sdhci_host *host;
+	int present;
+	unsigned long flags;
+	u32 tuning_opcode;
+
+	host = mmc_priv(mmc);
+
+	//pr_info(KERN_INFO "\n%s : %s()\n", mmc_hostname(mmc), __func__);
+
+	sdhci_runtime_pm_get(host);
+
+	/* Firstly check card presence */
+	present = sdhci_do_get_cd(host);
+
+	spin_lock_irqsave(&host->lock, flags);
+
+	WARN_ON(host->mrq != NULL);
+
+	/*
+	 * Ensure we don't send the STOP for non-SET_BLOCK_COUNTED
+	 * requests if Auto-CMD12 is enabled.
+	 */
+	if (!mrq->sbc && (host->flags & SDHCI_AUTO_CMD12)) {
+		if (mrq->stop) {
+			mrq->data->stop = NULL;
+			mrq->stop = NULL;
+		}
+	}
+
+	host->mrq = mrq;
+
+	if (!present || host->flags & SDHCI_DEVICE_DEAD) {
+		host->mrq->cmd->error = -ENOMEDIUM;
+		tasklet_schedule(&host->finish_tasklet);
+	} else {
+		u32 present_state;
+
+//		present_state = sdhci_readl(host, SDHCI_PRESENT_STATE);
+                if (host->quirks & SDHCI_QUIRK_BROKEN_CARD_DETECTION)
+                        present = 1;
+                else
+                        present = ((sdhci_readl(host, SDHCI_PIN_REG) & 0x00080000) >> 19);
+
+		/*
+		 * Check if the re-tuning timer has already expired and there
+		 * is no on-going data transfer and DAT0 is not busy. If so,
+		 * we need to execute tuning procedure before sending command.
+		 */
+		if ((host->flags & SDHCI_NEEDS_RETUNING) &&
+//		    !(present_state & (SDHCI_DOING_WRITE | SDHCI_DOING_READ)) &&
+		    (present_state & SDHCI_DATA_0_LVL_MASK)) {
+			if (mmc->card) {
+				/* eMMC uses cmd21 but sd and sdio use cmd19 */
+				tuning_opcode =
+					mmc->card->type == MMC_TYPE_MMC ?
+					MMC_SEND_TUNING_BLOCK_HS200 :
+					MMC_SEND_TUNING_BLOCK;
+
+				/* Here we need to set the host->mrq to NULL,
+				 * in case the pending finish_tasklet
+				 * finishes it incorrectly.
+				 */
+				host->mrq = NULL;
+
+				spin_unlock_irqrestore(&host->lock, flags);
+				sdhci_execute_tuning(mmc, tuning_opcode);
+				spin_lock_irqsave(&host->lock, flags);
+
+				/* Restore original mmc_request structure */
+				host->mrq = mrq;
+			}
+		}
+
+		if (mrq->sbc && !(host->flags & SDHCI_AUTO_CMD23)) {
+			//printk(KERN_INFO "send cmd w/o acmd 23\n");
+			sdhci_send_command(host, mrq->sbc);
+		}
+		else {
+			//printk(KERN_INFO "send cmd w/ acmd 23\n");
+			sdhci_send_command(host, mrq->cmd);
+		}
+	}
+
+	mb();
+	spin_unlock_irqrestore(&host->lock, flags);
+}
+
+void sdhci_set_bus_width(struct sdhci_host *host, int width)
+{
+#if 0
+	u8 ctrl;
+
+	ctrl = sdhci_readb(host, SDHCI_HOST_CONTROL);
+	if (width == MMC_BUS_WIDTH_8) {
+		ctrl &= ~SDHCI_CTRL_4BITBUS;
+		if (host->version >= SDHCI_SPEC_300)
+			ctrl |= SDHCI_CTRL_8BITBUS;
+	} else {
+		if (host->version >= SDHCI_SPEC_300)
+			ctrl &= ~SDHCI_CTRL_8BITBUS;
+		if (width == MMC_BUS_WIDTH_4)
+			ctrl |= SDHCI_CTRL_4BITBUS;
+		else
+			ctrl &= ~SDHCI_CTRL_4BITBUS;
+	}
+	sdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);
+#else
+	u32 ctrl;
+
+	//pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	ctrl = sdhci_readl(host, SDHCI_CFG_REG);
+	ctrl &= ~(0x00030000);
+	if (width == MMC_BUS_WIDTH_8) {
+		if (host->version >= SDHCI_SPEC_300) {
+			ctrl |= 0x00020000;
+		}
+	} else {
+		if (width == MMC_BUS_WIDTH_4) {
+			ctrl |= 0x00010000;
+		}
+	}
+	sdhci_writel(host, ctrl, SDHCI_CFG_REG);
+#endif
+}
+EXPORT_SYMBOL_GPL(sdhci_set_bus_width);
+
+void sdhci_set_uhs_signaling(struct sdhci_host *host, unsigned timing)
+{
+	u32 ctrl, ddr, dsp, hs400;
+	u16 ctrl_2;
+	int count;
+
+	//pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+//	ctrl_2 = sdhci_readw(host, SDHCI_HOST_CONTROL2);
+	ctrl_2 = host->sdhci_host_control2;
+	/* Select Bus Speed Mode for host */
+	ctrl_2 &= ~SDHCI_CTRL_UHS_MASK;
+
+	ctrl = sdhci_readl(host, SDHCI_ODL_REG);
+	ctrl &= ~(0x0000FFFF);
+
+	if (timing == MMC_TIMING_MMC_HS200) {
+		printk("SDHCI_CTRL_UHS_HS200\n");
+		ctrl_2 |= SDHCI_CTRL_UHS_SDR104;
+		ddr = 0;
+		dsp = 0;
+		hs400 = 0;
+
+		ctrl |= 0x00001C1C;	/* eMMC : 1.4 */
+
+	} else if (timing == MMC_TIMING_UHS_SDR104) {
+		printk("SDHCI_CTRL_UHS_SDR104\n");
+		ctrl_2 |= SDHCI_CTRL_UHS_SDR104;
+		ddr = 0;
+		dsp = 0;
+		hs400 = 0;
+
+		ctrl |= 0x00001C1C;	/* SD : 1.4 */
+
+	} else if (timing == MMC_TIMING_UHS_SDR12) {
+		printk("SDHCI_CTRL_UHS_SDR12\n");
+		ctrl_2 |= SDHCI_CTRL_UHS_SDR12;
+		ddr = 0;
+		dsp = 1;
+		hs400 = 0;
+
+		ctrl |= 0x00003C3C;	/* eMMC : 3 */
+//		ctrl |= 0x00003C3C;	/* SD : 3 */
+
+	} else if (timing == MMC_TIMING_UHS_SDR25) {
+		printk("SDHCI_CTRL_UHS_SDR25\n");
+		ctrl_2 |= SDHCI_CTRL_UHS_SDR25;
+		ddr = 0;
+		dsp = 1;
+		hs400 = 0;
+
+		ctrl |= 0x00003C3C;	/* eMMC : 3 */
+//		ctrl |= 0x00003C3C;	/* SD : 3 */
+
+	} else if (timing == MMC_TIMING_UHS_SDR50) {
+		printk("SDHCI_CTRL_UHS_SDR50\n");
+		ctrl_2 |= SDHCI_CTRL_UHS_SDR50;
+		ddr = 0;
+		dsp = 0;
+		hs400 = 0;
+
+		ctrl |= 0x00003C3C;	/* eMMC : 3 */
+//		ctrl |= 0x00003C3C;	/* SD : 3 */
+
+	} else if ((timing == MMC_TIMING_UHS_DDR50) ||
+		   (timing == MMC_TIMING_MMC_DDR52)) {
+		printk("SDHCI_CTRL_UHS_DDR50\n");
+		ctrl_2 |= SDHCI_CTRL_UHS_DDR50;
+		ddr = 1;
+		dsp = 0;
+		hs400 = 0;
+
+//		if (host->mmc->card->type == MMC_TYPE_MMC) {
+//			ctrl |= 0x0000323C;	/* eMMC : 3 / 2.5 */
+//		} else {
+			ctrl |= 0x00003C3C;	/* SD : 3 */
+//		}
+
+	} else if (timing == MMC_TIMING_MMC_HS400) {
+		printk("SDHCI_CTRL_HS400\n");
+		ctrl_2 |= SDHCI_CTRL_HS400; /* Non-standard */
+		ddr = 1;
+		dsp = 0;
+		hs400 = 1;
+
+//		ctrl |= 0x0000081C;	/* eMMC : 1.4 / 0.4 */
+		ctrl |= 0x00001010;
+
+	} else {
+		ddr = 0;
+		dsp = 1;
+		hs400 = 0;
+
+//		if (host->mmc->card->type == MMC_TYPE_MMC) {
+//			ctrl |= 0x00003C3C;	/* eMMC : 3 */
+//		} else {
+//			ctrl |= 0x00006464;	/* SD : 5 */
+//		}
+	}
+
+	sdhci_writel(host, ctrl, SDHCI_ODL_REG);
+
+	/* enable data out delay, command out delay */
+	ctrl = sdhci_readl(host, SDHCI_KDL_REG);
+	ctrl &= ~0x0000000F;
+	ctrl |= 0x00000002;
+	ctrl |= (3 << 7);
+	sdhci_writel(host, ctrl, SDHCI_KDL_REG);
+	while (sdhci_readl(host, SDHCI_KDL_REG) & 0x00000180);
+
+	if (timing == MMC_TIMING_MMC_HS400) {
+		/* reset to default value */
+		ctrl = sdhci_readl(host, SDHCI_LAT_REG);
+		ctrl &= ~0x00FFFF7F;
+		sdhci_writel(host, ctrl, SDHCI_LAT_REG);
+
+		ctrl = sdhci_readl(host, SDHCI_KDL_REG);
+		ctrl &= ~0x0000000F;
+		ctrl |= 0x00000002;
+		ctrl |= ((1 << 6) | (1 << 5));
+		sdhci_writel(host, ctrl, SDHCI_KDL_REG);
+		while (sdhci_readl(host, SDHCI_KDL_REG) & 0x0000060);
+
+//		ctrl = sdhci_readl(host, SDHCI_PCH1_REG);
+//		ctrl &= ~0x000000FF;
+//		sdhci_writel(host, ctrl, SDHCI_PCH1_REG);
+	}
+
+	if ((timing == MMC_TIMING_MMC_HS200) ||
+	    (timing == MMC_TIMING_UHS_SDR104) ||
+	    (timing == MMC_TIMING_UHS_DDR50) ||
+	    (timing == MMC_TIMING_MMC_DDR52) ||
+	    (timing == MMC_TIMING_MMC_HS400)) {
+		/* Nerc & Necs */
+		ctrl = sdhci_readl(host, SDHCI_PCH1_REG);
+		ctrl &= ~0x000000FF;
+		ctrl |= 0x55;
+		sdhci_writel(host, ctrl, SDHCI_PCH1_REG);
+
+		ctrl = sdhci_readl(host, SDHCI_LAT_REG);
+		ctrl &= ~0x0000007F;
+		if (ddr == 1)
+			ctrl |= 0x00000050;
+		else
+			ctrl |= 0x00000000;
+		sdhci_writel(host, ctrl, SDHCI_LAT_REG);
+	}
+
+	if (timing == MMC_TIMING_MMC_HS400) {
+		count = 0;
+		ctrl = sdhci_readl(host, SDHCI_DLL_REG);
+		ctrl &= ~0x1;
+		sdhci_writel(host, ctrl, SDHCI_DLL_REG);
+		mdelay(1);
+		ctrl |= 0x1;
+		sdhci_writel(host, ctrl, SDHCI_DLL_REG);
+
+		while ((sdhci_readl(host, SDHCI_DLL_REG) & 0x6) == 0x0) {
+			count++;
+			if (count > 10000) {
+				count = 0;
+				ctrl = sdhci_readl(host, SDHCI_DLL_REG);
+				ctrl &= ~0x1;
+				sdhci_writel(host, ctrl, SDHCI_DLL_REG);
+				mdelay(1);
+				ctrl |= 0x1;
+				sdhci_writel(host, ctrl, SDHCI_DLL_REG);
+				printk("<error> reset DLL\n");
+			}
+		}
+		printk("SDHCI_DLL_REG : 0x%x\n", sdhci_readl(host, SDHCI_DLL_REG));
+	}
+
+//	sdhci_writew(host, ctrl_2, SDHCI_HOST_CONTROL2);
+	host->sdhci_host_control2 = ctrl_2;
+
+	ctrl = sdhci_readl(host, SDHCI_CK_REG);
+	DBG("read reg - SDHCI_CK_REG 0x%x\n", ctrl);
+	ctrl &= ~(0x7 << 22);
+	ctrl |= (ddr << 22) | (dsp << 23) | (hs400 << 24);
+	sdhci_writel(host, ctrl, SDHCI_CK_REG);
+	DBG("write reg - SDHCI_CK_REG 0x%x\n", ctrl);
+
+	while (sdhci_readl(host, SDHCI_CK_REG) & 0x80);
+}
+EXPORT_SYMBOL_GPL(sdhci_set_uhs_signaling);
+
+static void sdhci_do_set_ios(struct sdhci_host *host, struct mmc_ios *ios)
+{
+	unsigned long flags;
+	u8 ctrl;
+	struct mmc_host *mmc = host->mmc;
+
+	spin_lock_irqsave(&host->lock, flags);
+
+	if (host->flags & SDHCI_DEVICE_DEAD) {
+		spin_unlock_irqrestore(&host->lock, flags);
+		if (!IS_ERR(mmc->supply.vmmc) &&
+		    ios->power_mode == MMC_POWER_OFF)
+			mmc_regulator_set_ocr(mmc, mmc->supply.vmmc, 0);
+		return;
+	}
+
+	/*
+	 * Reset the chip on each power off.
+	 * Should clear out any weird states.
+	 */
+	if (ios->power_mode == MMC_POWER_OFF) {
+//		sdhci_writel(host, 0, SDHCI_SIGNAL_ENABLE);
+		sdhci_writel(host, sdhci_readl(host, SDHCI_INT_STATUS), SDHCI_INT_STATUS);
+		sdhci_reinit(host);
+	}
+
+	if (host->version >= SDHCI_SPEC_300 &&
+		(ios->power_mode == MMC_POWER_UP) &&
+		!(host->quirks2 & SDHCI_QUIRK2_PRESET_VALUE_BROKEN))
+		sdhci_enable_preset_value(host, false);
+
+	sdhci_writel(host, (sdhci_readl(host, SDHCI_CK_REG) | 0x10), SDHCI_CK_REG);
+#if 0
+	if ((ios->timing == MMC_TIMING_MMC_HS400) ||
+	    (ios->timing == MMC_TIMING_UHS_SDR104)) {
+
+#if 0
+		writel((0 & 0x0000007F), base + 0x0060);
+		writel((99 & 0x0001FFFF), base + 0x0064);
+		writel((12 & 0x0000003F), base + 0x0068);
+		writel(((0x0 << 0) | (0x0 << 1) | (0x0 << 2)), base + 0x006C);
+
+		while ((readl(base + 0x006C) & (0x1 << 3)) == 0);
+
+		switch (host->slot_id) {
+		case SLOT_EMMC:
+			writel(0x00004000, base + 0x00C4);
+			writel(0x0000C000, base + 0x00C4);
+			writel(0x00004004, base + 0x00C4);
+			break;
+		case SLOT_SDIO_WIFI:
+			writel(0x00004000, base + 0x0094);
+			writel(0x0000C000, base + 0x0094);
+			writel(0x00004004, base + 0x0094);
+			break;
+		case SLOT_SDIO:
+			writel(0x00004000, base + 0x0098);
+			writel(0x0000C000, base + 0x0098);
+			writel(0x00004004, base + 0x0098);
+			break;
+		case SLOT_SD:
+			writel(0x00004003, base + 0x009C);
+			writel(0x0000C003, base + 0x009C);
+			writel(0x00004007, base + 0x009C);
+			break;
+		}
+
+		host->max_clk = 200000000;
+#endif
+
+#if 0
+		switch (host->slot_id) {
+		case SLOT_EMMC:
+			writel(0x000A4000, base + 0x00C4);
+			writel(0x000AC000, base + 0x00C4);
+			writel(0x000A4004, base + 0x00C4);
+			break;
+		case SLOT_SDIO_WIFI:
+			writel(0x000A4000, base + 0x0094);
+			writel(0x000AC000, base + 0x0094);
+			writel(0x000A4004, base + 0x0094);
+			break;
+		case SLOT_SDIO:
+			writel(0x000A4000, base + 0x0098);
+			writel(0x000AC000, base + 0x0098);
+			writel(0x000A4004, base + 0x0098);
+			break;
+		case SLOT_SD:
+			writel(0x000A4003, base + 0x009C);
+			writel(0x000AC003, base + 0x009C);
+			writel(0x000A4007, base + 0x009C);
+			break;
+		}
+
+		host->max_clk = 100000000;
+#endif
+
+#if 1
+		switch (host->slot_id) {
+		case SLOT_EMMC:
+			writel(0x00064000, base + 0x00C4);
+			writel(0x0006C000, base + 0x00C4);
+			writel(0x00064004, base + 0x00C4);
+			break;
+		case SLOT_SDIO_WIFI:
+			writel(0x00064000, base + 0x0094);
+			writel(0x0006C000, base + 0x0094);
+			writel(0x00064004, base + 0x0094);
+			break;
+		case SLOT_SDIO:
+			writel(0x00064000, base + 0x0098);
+			writel(0x0006C000, base + 0x0098);
+			writel(0x00064004, base + 0x0098);
+			break;
+		case SLOT_SD:
+			writel(0x00064003, base + 0x009C);
+			writel(0x0006C003, base + 0x009C);
+			writel(0x00064007, base + 0x009C);
+			break;
+		}
+
+		host->max_clk = 166666666;
+#endif
+
+	} else {
+
+		switch (host->slot_id) {
+		case SLOT_EMMC:
+			writel(0x00054000, base + 0x00C4);
+			writel(0x0005C000, base + 0x00C4);
+			writel(0x00054004, base + 0x00C4);
+			break;
+		case SLOT_SDIO_WIFI:
+			writel(0x00054000, base + 0x0094);
+			writel(0x0005C000, base + 0x0094);
+			writel(0x00054004, base + 0x0094);
+			break;
+		case SLOT_SDIO:
+			writel(0x00054000, base + 0x0098);
+			writel(0x0005C000, base + 0x0098);
+			writel(0x00054004, base + 0x0098);
+			break;
+		case SLOT_SD:
+			writel(0x00054003, base + 0x009C);
+			writel(0x0005C003, base + 0x009C);
+			writel(0x00054007, base + 0x009C);
+			break;
+		}
+
+		host->max_clk = 200000000;
+
+	}
+#endif
+	sdhci_writel(host, (sdhci_readl(host, SDHCI_CK_REG) & ~0x10), SDHCI_CK_REG);
+
+	if (!ios->clock || ios->clock != host->clock) {
+		sdhci_set_clock(host, ios->clock);
+		host->clock = ios->clock;
+
+		if (host->quirks & SDHCI_QUIRK_DATA_TIMEOUT_USES_SDCLK &&
+		    host->clock) {
+			host->timeout_clk = host->mmc->actual_clock ?
+						host->mmc->actual_clock / 1000 :
+						host->clock / 1000;
+			host->mmc->max_busy_timeout =
+				sdhci_w3k_get_max_timeout_count(host);
+			host->mmc->max_busy_timeout /= host->timeout_clk;
+		}
+	}
+
+	sdhci_set_power(host, ios->power_mode, ios->vdd);
+
+	sdhci_w3k_platform_send_init_74_clocks(host, ios->power_mode);
+
+	sdhci_set_bus_width(host, ios->bus_width);
+
+//	ctrl = sdhci_readb(host, SDHCI_HOST_CONTROL);
+	ctrl = host->sdhci_host_control;
+
+	if ((ios->timing == MMC_TIMING_SD_HS ||
+	     ios->timing == MMC_TIMING_MMC_HS)
+	    && !(host->quirks & SDHCI_QUIRK_NO_HISPD_BIT))
+		ctrl |= SDHCI_CTRL_HISPD;
+	else
+		ctrl &= ~SDHCI_CTRL_HISPD;
+
+	if (host->version >= SDHCI_SPEC_300) {
+		u16 /*clk,*/ ctrl_2;
+
+		/* In case of UHS-I modes, set High Speed Enable */
+		if ((ios->timing == MMC_TIMING_MMC_HS400) ||
+		    (ios->timing == MMC_TIMING_MMC_HS200) ||
+		    (ios->timing == MMC_TIMING_MMC_DDR52) ||
+		    (ios->timing == MMC_TIMING_UHS_SDR50) ||
+		    (ios->timing == MMC_TIMING_UHS_SDR104) ||
+		    (ios->timing == MMC_TIMING_UHS_DDR50) ||
+		    (ios->timing == MMC_TIMING_UHS_SDR25))
+			ctrl |= SDHCI_CTRL_HISPD;
+
+		if (!host->preset_enabled) {
+//			sdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);
+			host->sdhci_host_control = ctrl;
+			/*
+			 * We only need to set Driver Strength if the
+			 * preset value enable is not set.
+			 */
+//			ctrl_2 = sdhci_readw(host, SDHCI_HOST_CONTROL2);
+			ctrl_2 = host->sdhci_host_control2;
+			ctrl_2 &= ~SDHCI_CTRL_DRV_TYPE_MASK;
+			if (ios->drv_type == MMC_SET_DRIVER_TYPE_A)
+				ctrl_2 |= SDHCI_CTRL_DRV_TYPE_A;
+			else if (ios->drv_type == MMC_SET_DRIVER_TYPE_C)
+				ctrl_2 |= SDHCI_CTRL_DRV_TYPE_C;
+
+//			sdhci_writew(host, ctrl_2, SDHCI_HOST_CONTROL2);
+			host->sdhci_host_control2 = ctrl_2;
+		} else {
+			/*
+			 * According to SDHC Spec v3.00, if the Preset Value
+			 * Enable in the Host Control 2 register is set, we
+			 * need to reset SD Clock Enable before changing High
+			 * Speed Enable to avoid generating clock gliches.
+			 */
+
+			/* Reset SD Clock Enable */
+//			clk = sdhci_readw(host, SDHCI_CLOCK_CONTROL);
+//			clk &= ~SDHCI_CLOCK_CARD_EN;
+//			sdhci_writew(host, clk, SDHCI_CLOCK_CONTROL);
+
+//			sdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);
+			host->sdhci_host_control = ctrl;
+
+			/* Re-enable SD Clock */
+			sdhci_set_clock(host, host->clock);
+		}
+
+		/* Reset SD Clock Enable */
+//		clk = sdhci_readw(host, SDHCI_CLOCK_CONTROL);
+//		clk &= ~SDHCI_CLOCK_CARD_EN;
+//		sdhci_writew(host, clk, SDHCI_CLOCK_CONTROL);
+
+		sdhci_set_uhs_signaling(host, ios->timing);
+		host->timing = ios->timing;
+
+		if (!(host->quirks2 & SDHCI_QUIRK2_PRESET_VALUE_BROKEN) &&
+				((ios->timing == MMC_TIMING_UHS_SDR12) ||
+				 (ios->timing == MMC_TIMING_UHS_SDR25) ||
+				 (ios->timing == MMC_TIMING_UHS_SDR50) ||
+				 (ios->timing == MMC_TIMING_UHS_SDR104) ||
+				 (ios->timing == MMC_TIMING_UHS_DDR50))) {
+			u16 preset;
+
+			sdhci_enable_preset_value(host, true);
+			preset = sdhci_get_preset_value(host);
+			ios->drv_type = (preset & SDHCI_PRESET_DRV_MASK)
+				>> SDHCI_PRESET_DRV_SHIFT;
+		}
+
+		/* Re-enable SD Clock */
+		sdhci_set_clock(host, host->clock);
+	} else
+//		sdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);
+		host->sdhci_host_control = ctrl;
+#if 0
+	switch (host->slot_id) {
+	case SLOT_EMMC:
+		if (host->clock < 50000000)
+			driving = 0x0;
+		else if ((host->clock >= 50000000) &&
+			 (host->clock < 100000000))
+			driving = 0x1;
+		else if ((host->clock >= 100000000)/* &&
+			 (host->clock <  200000000)*/)
+			driving = 0x3;
+
+		pr_info(KERN_INFO "driving : %d (%d)\n", driving, host->clock);
+
+		pad_cfg = readl(base + 0x4AE0);	/* eMMC clk pad config */
+		pad_cfg &= ~(0x7 << 8);
+		pad_cfg |= (driving << 8);
+		writel(pad_cfg, base + 0x4AE0);
+		pr_info(KERN_INFO "eMMC clk pad config 0x%x\n", readl(base + 0x4AE0));
+
+		pad_cfg = readl(base + 0x4AE4);	/* eMMC cmd pad config */
+		pad_cfg &= ~(0x7 << 8);
+		pad_cfg |= (driving << 8);
+		writel(pad_cfg, base + 0x4AE4);
+		pr_info(KERN_INFO "eMMC cmd pad config 0x%x\n", readl(base + 0x4AE4));
+
+		pad_cfg = readl(base + 0x4AE8);	/* eMMC data pad config */
+		pad_cfg &= ~(0x7 << 8);
+		pad_cfg |= (driving << 8);
+		writel(pad_cfg, base + 0x4AE8);
+		pr_info(KERN_INFO "eMMC data pad config 0x%x\n", readl(base + 0x4AE8));
+
+		pad_cfg = readl(base + 0x4AF0);	/* eMMC strobe pad config */
+		pad_cfg &= ~0x00000004;
+		pad_cfg |= 0x00000004;
+		writel(pad_cfg, base + 0x4AF0);
+		pr_info(KERN_INFO "eMMC strobe pad config 0x%x\n", readl(base + 0x4AF0));
+		break;
+
+	case SLOT_SD:
+		if (host->clock < 50000000)
+			driving = 0x0;
+		else if ((host->clock >= 50000000) &&
+			 (host->clock <  75000000))
+			driving = 0x0;
+		else if ((host->clock >= 75000000) &&
+			 (host->clock < 100000000))
+			driving = 0x1;
+		else if ((host->clock >= 100000000) &&
+			 (host->clock <  166000000))
+			driving = 0x2;
+		else /*if ((host->clock >= 166000000) &&
+			 (host->clock < 200000000))*/
+			driving = 0x3;
+
+		pr_info(KERN_INFO "driving : %d\n", driving);
+
+		pad_cfg = readl(base + 0x49E0);	/* SD3 clk pad config */
+		pad_cfg &= ~(0x7 << 8);
+		pad_cfg |= (driving << 8);
+		writel(pad_cfg, base + 0x49E0);
+		pr_info(KERN_INFO "SD3 clk pad : 0x%x\n", readl(base + 0x49E0));
+
+		pad_cfg = readl(base + 0x49E4);	/* SD3 cmd pad config */
+		pad_cfg &= ~(0x7 << 8);
+		pad_cfg |= (driving << 8);
+		writel(pad_cfg, base + 0x49E4);
+		pr_info(KERN_INFO "SD3 cmd pad : 0x%x\n", readl(base + 0x49E4));
+
+		pad_cfg = readl(base + 0x49E8);	/* SD3 data pad config */
+		pad_cfg &= ~(0x7 << 8);
+		pad_cfg |= (driving << 8);
+		writel(pad_cfg, base + 0x49E8);
+		pr_info(KERN_INFO "SD3 data pad : 0x%x\n", readl(base + 0x49E8));
+		break;
+	}
+#endif
+#if 0
+	/* debounce time : 88.47 us */
+	debounce = 88 * (host->clock / 1000) / 766666;
+	if (debounce <= 0)
+		debounce = 3;
+	if (debounce > 255)
+		debounce = 255;
+	pr_info(KERN_INFO "debounce : %d\n", debounce);
+
+	pin_cfg = sdhci_readl(host, SDHCI_PIN_REG);
+	pin_cfg &= ~(0xFF << 8);
+	pin_cfg |= (debounce << 8);
+	sdhci_writel(host, pin_cfg, SDHCI_PIN_REG);
+#endif
+
+	/*
+	 * Some (ENE) controllers go apeshit on some ios operation,
+	 * signalling timeout and CRC errors even on CMD0. Resetting
+	 * it on each ios seems to solve the problem.
+	 */
+	if (host->quirks & SDHCI_QUIRK_RESET_CMD_DATA_ON_IOS)
+		sdhci_do_reset(host, SDHCI_RESET_CMD | SDHCI_RESET_DATA);
+
+	mb();
+	spin_unlock_irqrestore(&host->lock, flags);
+}
+
+static void sdhci_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct sdhci_host *host = mmc_priv(mmc);
+
+	sdhci_runtime_pm_get(host);
+	sdhci_do_set_ios(host, ios);
+	sdhci_runtime_pm_put(host);
+}
+
+static int sdhci_do_get_cd(struct sdhci_host *host)
+{
+	int gpio_cd = mmc_gpio_get_cd(host->mmc);
+
+	//pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	if (host->flags & SDHCI_DEVICE_DEAD)
+		return 0;
+
+	/* If polling/nonremovable, assume that the card is always present. */
+	if ((host->quirks & SDHCI_QUIRK_BROKEN_CARD_DETECTION) ||
+	    (host->mmc->caps & MMC_CAP_NONREMOVABLE))
+		return 1;
+
+	/* Try slot gpio detect */
+	if (!IS_ERR_VALUE(gpio_cd))
+		return !!gpio_cd;
+
+	return ((sdhci_readl(host, SDHCI_PIN_REG) & 0x00080000) >> 19);
+
+#if 0
+	for (count = 0; count < 10000; count++) {
+		/* Host native card detect */
+		present = sdhci_readl(host, SDHCI_PRESENT_STATE);
+		if (present & SDHCI_CARD_PRESENT)
+			break;
+	}
+
+	if (present & 0x1) {
+		host->card_present = !!(present & SDHCI_CARD_PRESENT);
+		if (!host->card_present)
+			pr_err("%s: card removed\n", mmc_hostname(host->mmc));
+
+		return !!(present & SDHCI_CARD_PRESENT);
+	} else {
+		pr_err("%s: Doesn't enable card detect.\n",
+			mmc_hostname(host->mmc));
+		return host->card_present;
+	}
+#endif
+}
+
+static int sdhci_get_cd(struct mmc_host *mmc)
+{
+	struct sdhci_host *host = mmc_priv(mmc);
+	int ret;
+
+	sdhci_runtime_pm_get(host);
+	ret = sdhci_do_get_cd(host);
+	sdhci_runtime_pm_put(host);
+	return ret;
+}
+
+static int sdhci_check_ro(struct sdhci_host *host)
+{
+	unsigned long flags;
+	int is_readonly;
+
+	spin_lock_irqsave(&host->lock, flags);
+
+	if (host->flags & SDHCI_DEVICE_DEAD)
+		is_readonly = 0;
+	else if (1)
+		is_readonly = sdhci_w3k_get_ro(host);
+	else
+		is_readonly = !(sdhci_readl(host, SDHCI_PRESENT_STATE)
+				& SDHCI_WRITE_PROTECT);
+
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	/* This quirk needs to be replaced by a callback-function later */
+	return host->quirks & SDHCI_QUIRK_INVERTED_WRITE_PROTECT ?
+		!is_readonly : is_readonly;
+}
+
+#define SAMPLE_COUNT	5
+
+static int sdhci_do_get_ro(struct sdhci_host *host)
+{
+	int i, ro_count;
+
+	if (!(host->quirks & SDHCI_QUIRK_UNSTABLE_RO_DETECT))
+		return sdhci_check_ro(host);
+
+	ro_count = 0;
+	for (i = 0; i < SAMPLE_COUNT; i++) {
+		if (sdhci_check_ro(host)) {
+			if (++ro_count > SAMPLE_COUNT / 2)
+				return 1;
+		}
+		msleep(30);
+	}
+	return 0;
+}
+
+static void sdhci_hw_reset(struct mmc_host *mmc)
+{
+	struct sdhci_host *host = mmc_priv(mmc);
+
+	sdhci_w3k_hw_reset(host);
+}
+
+static int sdhci_get_ro(struct mmc_host *mmc)
+{
+	struct sdhci_host *host = mmc_priv(mmc);
+	int ret;
+
+	sdhci_runtime_pm_get(host);
+	ret = sdhci_do_get_ro(host);
+	sdhci_runtime_pm_put(host);
+	return ret;
+}
+
+static void sdhci_enable_sdio_irq_nolock(struct sdhci_host *host, int enable)
+{
+#if 0	/* unsupported */
+	if (!(host->flags & SDHCI_DEVICE_DEAD)) {
+		if (enable)
+			host->ier |= SDHCI_INT_CARD_INT;
+		else
+			host->ier &= ~SDHCI_INT_CARD_INT;
+
+		sdhci_writel(host, host->ier, SDHCI_INT_ENABLE);
+		sdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);
+		mb();
+	}
+#endif
+}
+
+static void sdhci_enable_sdio_irq(struct mmc_host *mmc, int enable)
+{
+#ifdef RTL_SDIO_GPIO_TEST
+	if (enable && wifi_eirq_enable)
+		wifi_irq_trg(SDIO_INTERRUPT_GPIO, enable);
+	else
+		wifi_irq_trg(SDIO_INTERRUPT_GPIO, false);
+#else
+	struct sdhci_host *host = mmc_priv(mmc);
+	unsigned long flags;
+
+	sdhci_runtime_pm_get(host);
+
+	spin_lock_irqsave(&host->lock, flags);
+	if (enable)
+		host->flags |= SDHCI_SDIO_IRQ_ENABLED;
+	else
+		host->flags &= ~SDHCI_SDIO_IRQ_ENABLED;
+
+	sdhci_enable_sdio_irq_nolock(host, enable);
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	sdhci_runtime_pm_put(host);
+#endif
+}
+
+static int sdhci_do_start_signal_voltage_switch(struct sdhci_host *host,
+						struct mmc_ios *ios)
+{
+	struct mmc_host *mmc = host->mmc;
+	u16 ctrl;
+	int ret;
+	u32 pwr_cfg;
+	//void __iomem *base = ioremap(0xFFE54000, 0x1000);
+
+	//pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(mmc), __func__);
+
+	/*
+	 * Signal Voltage Switching is only applicable for Host Controllers
+	 * v3.00 and above.
+	 */
+	if (host->version < SDHCI_SPEC_300)
+		return 0;
+	return 0;
+//	ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
+	ctrl = host->sdhci_host_control2;
+
+	switch (ios->signal_voltage) {
+	case MMC_SIGNAL_VOLTAGE_330:
+		/* Set 1.8V Signal Enable in the Host Control2 register to 0 */
+		ctrl &= ~SDHCI_CTRL_VDD_180;
+//		sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
+		host->sdhci_host_control2 = ctrl;
+
+		if (!IS_ERR(mmc->supply.vmmc)) {
+			ret = regulator_set_voltage(mmc->supply.vmmc, 2700000,
+						    3600000);
+			if (ret) {
+				pr_warn("%s: Switching to 3.3V signalling voltage failed\n",
+					mmc_hostname(mmc));
+				return -EIO;
+			}
+		}
+		/* Wait for 5ms */
+		usleep_range(5000, 5500);
+
+		/* set IO Power Config */
+		//pwr_cfg = readl(base + 0xF00);
+
+		//if (host->slot_id == SLOT_EMMC) {
+		//	pwr_cfg |= 0x3;
+		//} else if (host->slot_id == SLOT_SD) {
+		//	pwr_cfg |= 0xC;
+		//}
+
+		//writel(pwr_cfg, base + 0xF00);
+
+		/* 3.3V regulator output should be stable within 5 ms */
+//		ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
+		ctrl = host->sdhci_host_control2;
+		if (!(ctrl & SDHCI_CTRL_VDD_180))
+			return 0;
+
+		pr_warn("%s: 3.3V regulator output did not became stable\n",
+			mmc_hostname(mmc));
+
+		return -EAGAIN;
+	case MMC_SIGNAL_VOLTAGE_180:
+		if (!IS_ERR(mmc->supply.vmmc)) {
+			ret = regulator_set_voltage(mmc->supply.vmmc,
+					1700000, 1950000);
+			if (ret) {
+				pr_warn("%s: Switching to 1.8V signalling voltage failed\n",
+					mmc_hostname(mmc));
+				return -EIO;
+			}
+		}
+
+		/*
+		 * Enable 1.8V Signal Enable in the Host Control2
+		 * register
+		 */
+		ctrl |= SDHCI_CTRL_VDD_180;
+//		sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
+		host->sdhci_host_control2 = ctrl;
+
+		/* Some controller need to do more when switching */
+		sdhci_w3k_voltage_switch(host);
+
+		/* set IO Power Config */
+		//pwr_cfg = readl(base + 0xF00);
+
+		//if (host->slot_id == SLOT_EMMC) {
+		//	pwr_cfg &= ~0x3;
+		//} else if (host->slot_id == SLOT_SD) {
+		//	pwr_cfg &= ~0xC;
+		//}
+
+		//writel(pwr_cfg, base + 0xF00);
+
+		/* 1.8V regulator output should be stable within 5 ms */
+//		ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
+		ctrl = host->sdhci_host_control2;
+		if (ctrl & SDHCI_CTRL_VDD_180)
+			return 0;
+
+		pr_warn("%s: 1.8V regulator output did not became stable\n",
+			mmc_hostname(mmc));
+
+		return -EAGAIN;
+	case MMC_SIGNAL_VOLTAGE_120:
+		if (!IS_ERR(mmc->supply.vmmc)) {
+			ret = regulator_set_voltage(mmc->supply.vmmc, 1100000,
+						    1300000);
+			if (ret) {
+				pr_warn("%s: Switching to 1.2V signalling voltage failed\n",
+					mmc_hostname(mmc));
+				return -EIO;
+			}
+		}
+		return 0;
+	default:
+		/* No signal voltage switch required */
+		return 0;
+	}
+}
+
+static int sdhci_start_signal_voltage_switch(struct mmc_host *mmc,
+	struct mmc_ios *ios)
+{
+	struct sdhci_host *host = mmc_priv(mmc);
+	int err;
+
+	//pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(mmc), __func__);
+
+	if (host->version < SDHCI_SPEC_300)
+		return 0;
+	sdhci_runtime_pm_get(host);
+	err = sdhci_do_start_signal_voltage_switch(host, ios);
+	sdhci_runtime_pm_put(host);
+	return err;
+}
+
+#if 0
+static int sdhci_card_busy(struct mmc_host *mmc)
+{
+	struct sdhci_host *host = mmc_priv(mmc);
+	u32 present_state;
+
+	pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(mmc), __func__);
+
+	sdhci_runtime_pm_get(host);
+	/* Check whether DAT[3:0] is 0000 */
+	present_state = sdhci_readl(host, SDHCI_PRESENT_STATE);
+	sdhci_runtime_pm_put(host);
+
+	return !(present_state & SDHCI_DATA_LVL_MASK);
+}
+#endif
+
+static int sdhci_prepare_hs400_tuning(struct mmc_host *mmc, struct mmc_ios *ios)
+{
+	struct sdhci_host *host = mmc_priv(mmc);
+	unsigned long flags;
+
+	spin_lock_irqsave(&host->lock, flags);
+	host->flags |= SDHCI_HS400_TUNING;
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	return 0;
+}
+
+static int sdhci_execute_tuning(struct mmc_host *mmc, u32 opcode)
+{
+	struct sdhci_host *host = mmc_priv(mmc);
+	u16 ctrl;
+	int tuning_loop_counter = MAX_TUNING_LOOP;
+	int err = 0;
+	unsigned long flags;
+	unsigned int tuning_count = 0;
+	bool hs400_tuning;
+
+	pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(mmc), __func__);
+
+	sdhci_runtime_pm_get(host);
+	spin_lock_irqsave(&host->lock, flags);
+
+	hs400_tuning = host->flags & SDHCI_HS400_TUNING;
+	host->flags &= ~SDHCI_HS400_TUNING;
+
+	if (host->tuning_mode == SDHCI_TUNING_MODE_1)
+		tuning_count = host->tuning_count;
+
+	/*
+	 * The Host Controller needs tuning only in case of SDR104 mode
+	 * and for SDR50 mode when Use Tuning for SDR50 is set in the
+	 * Capabilities register.
+	 * If the Host Controller supports the HS200 mode then the
+	 * tuning function has to be executed.
+	 */
+	switch (host->timing) {
+	/* HS400 tuning is done in HS200 mode */
+	case MMC_TIMING_MMC_HS400:
+		err = -EINVAL;
+		goto out_unlock;
+
+	case MMC_TIMING_MMC_HS200:
+		/*
+		 * Periodic re-tuning for HS400 is not expected to be needed, so
+		 * disable it here.
+		 */
+		if (hs400_tuning)
+			tuning_count = 0;
+		break;
+
+	case MMC_TIMING_UHS_SDR104:
+		break;
+
+	case MMC_TIMING_UHS_SDR50:
+		if (host->flags & SDHCI_SDR50_NEEDS_TUNING ||
+		    host->flags & SDHCI_SDR104_NEEDS_TUNING)
+			break;
+		/* FALLTHROUGH */
+
+	default:
+		goto out_unlock;
+	}
+
+	if (1) {
+		spin_unlock_irqrestore(&host->lock, flags);
+		err = sdhci_w3k_platform_execute_tuning(host, opcode);
+		sdhci_runtime_pm_put(host);
+		return err;
+	}
+
+//	ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
+	ctrl = host->sdhci_host_control2;
+	ctrl |= SDHCI_CTRL_EXEC_TUNING;
+	if (host->quirks2 & SDHCI_QUIRK2_TUNING_WORK_AROUND)
+		ctrl |= SDHCI_CTRL_TUNED_CLK;
+//	sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
+	host->sdhci_host_control2 = ctrl;
+
+	/*
+	 * As per the Host Controller spec v3.00, tuning command
+	 * generates Buffer Read Ready interrupt, so enable that.
+	 *
+	 * Note: The spec clearly says that when tuning sequence
+	 * is being performed, the controller does not generate
+	 * interrupts other than Buffer Read Ready interrupt. But
+	 * to make sure we don't hit a controller bug, we _only_
+	 * enable Buffer Read Ready interrupt here.
+	 */
+	sdhci_writel(host, SDHCI_INT_DATA_AVAIL, SDHCI_IEN_REG);
+//	sdhci_writel(host, SDHCI_INT_DATA_AVAIL, SDHCI_SIGNAL_ENABLE);
+
+	/*
+	 * Issue CMD19 repeatedly till Execute Tuning is set to 0 or the number
+	 * of loops reaches 40 times or a timeout of 150ms occurs.
+	 */
+	do {
+		struct mmc_command cmd = {0};
+		struct mmc_request mrq = {NULL};
+
+		cmd.opcode = opcode;
+		cmd.arg = 0;
+		cmd.flags = MMC_RSP_R1 | MMC_CMD_ADTC;
+		cmd.retries = 0;
+		cmd.data = NULL;
+		cmd.error = 0;
+
+		if (tuning_loop_counter-- == 0)
+			break;
+
+		mrq.cmd = &cmd;
+		host->mrq = &mrq;
+
+		/*
+		 * In response to CMD19, the card sends 64 bytes of tuning
+		 * block to the Host Controller. So we set the block size
+		 * to 64 here.
+		 */
+		if (cmd.opcode == MMC_SEND_TUNING_BLOCK_HS200) {
+//			if (mmc->ios.bus_width == MMC_BUS_WIDTH_8)
+//				sdhci_writew(host, SDHCI_MAKE_BLKSZ(7, 128),
+//					     SDHCI_BLOCK_SIZE);
+//			else if (mmc->ios.bus_width == MMC_BUS_WIDTH_4)
+//				sdhci_writew(host, SDHCI_MAKE_BLKSZ(7, 64),
+//					     SDHCI_BLOCK_SIZE);
+		} else {
+//			sdhci_writew(host, SDHCI_MAKE_BLKSZ(7, 64),
+//				     SDHCI_BLOCK_SIZE);
+		}
+
+		/*
+		 * The tuning block is sent by the card to the host controller.
+		 * So we set the TRNS_READ bit in the Transfer Mode register.
+		 * This also takes care of setting DMA Enable and Multi Block
+		 * Select in the same register to 0.
+		 */
+//		sdhci_writew(host, SDHCI_TRNS_READ, SDHCI_TRANSFER_MODE);
+
+		sdhci_send_command(host, &cmd);
+
+		host->cmd = NULL;
+		host->mrq = NULL;
+
+		spin_unlock_irqrestore(&host->lock, flags);
+		/* Wait for Buffer Read Ready interrupt */
+		wait_event_interruptible_timeout(host->buf_ready_int,
+					(host->tuning_done == 1),
+					msecs_to_jiffies(50));
+		spin_lock_irqsave(&host->lock, flags);
+
+		if (!host->tuning_done) {
+			pr_info(DRIVER_NAME ": Timeout waiting for "
+				"Buffer Read Ready interrupt during tuning "
+				"procedure, falling back to fixed sampling "
+				"clock\n");
+//			ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
+			ctrl = host->sdhci_host_control2;
+			ctrl &= ~SDHCI_CTRL_TUNED_CLK;
+			ctrl &= ~SDHCI_CTRL_EXEC_TUNING;
+//			sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
+			host->sdhci_host_control2 = ctrl;
+
+			err = -EIO;
+			goto out;
+		}
+
+		host->tuning_done = 0;
+
+//		ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
+		ctrl = host->sdhci_host_control2;
+
+		/* eMMC spec does not require a delay between tuning cycles */
+		if (opcode == MMC_SEND_TUNING_BLOCK)
+			mdelay(1);
+	} while (ctrl & SDHCI_CTRL_EXEC_TUNING);
+
+	/*
+	 * The Host Driver has exhausted the maximum number of loops allowed,
+	 * so use fixed sampling frequency.
+	 */
+	if (tuning_loop_counter < 0) {
+		ctrl &= ~SDHCI_CTRL_TUNED_CLK;
+//		sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
+		host->sdhci_host_control2 = ctrl;
+	}
+	if (!(ctrl & SDHCI_CTRL_TUNED_CLK)) {
+		pr_info(DRIVER_NAME ": Tuning procedure"
+			" failed, falling back to fixed sampling"
+			" clock\n");
+		err = -EIO;
+	}
+
+out:
+	host->flags &= ~SDHCI_NEEDS_RETUNING;
+
+	if (tuning_count) {
+		host->flags |= SDHCI_USING_RETUNING_TIMER;
+		mod_timer(&host->tuning_timer, jiffies + tuning_count * HZ);
+	}
+
+	/*
+	 * In case tuning fails, host controllers which support re-tuning can
+	 * try tuning again at a later time, when the re-tuning timer expires.
+	 * So for these controllers, we return 0. Since there might be other
+	 * controllers who do not have this capability, we return error for
+	 * them. SDHCI_USING_RETUNING_TIMER means the host is currently using
+	 * a retuning timer to do the retuning for the card.
+	 */
+	if (err && (host->flags & SDHCI_USING_RETUNING_TIMER))
+		err = 0;
+
+	sdhci_writel(host, host->ier, SDHCI_IEN_REG);
+//	sdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);
+out_unlock:
+	spin_unlock_irqrestore(&host->lock, flags);
+	sdhci_runtime_pm_put(host);
+
+	return err;
+}
+
+
+static void sdhci_enable_preset_value(struct sdhci_host *host, bool enable)
+{
+	/* Host Controller v3.00 defines preset value registers */
+	if (host->version < SDHCI_SPEC_300)
+		return;
+
+	/*
+	 * We only enable or disable Preset Value if they are not already
+	 * enabled or disabled respectively. Otherwise, we bail out.
+	 */
+	if (host->preset_enabled != enable) {
+		u16 ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
+
+		if (enable)
+			ctrl |= SDHCI_CTRL_PRESET_VAL_ENABLE;
+		else
+			ctrl &= ~SDHCI_CTRL_PRESET_VAL_ENABLE;
+
+		sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
+
+		if (enable)
+			host->flags |= SDHCI_PV_ENABLED;
+		else
+			host->flags &= ~SDHCI_PV_ENABLED;
+
+		host->preset_enabled = enable;
+	}
+}
+
+static void sdhci_post_req(struct mmc_host *mmc, struct mmc_request *mrq,
+				int err)
+{
+	struct sdhci_host *host = mmc_priv(mmc);
+	struct mmc_data *data = mrq->data;
+
+	if (host->flags & SDHCI_REQ_USE_DMA) {
+		if (data->host_cookie)
+			dma_unmap_sg(mmc_dev(host->mmc), data->sg, data->sg_len,
+					 data->flags & MMC_DATA_WRITE ?
+					 DMA_TO_DEVICE : DMA_FROM_DEVICE);
+		mrq->data->host_cookie = 0;
+	}
+}
+
+static int sdhci_pre_dma_transfer(struct sdhci_host *host,
+				       struct mmc_data *data,
+				       struct sdhci_host_next *next)
+{
+	int sg_count;
+
+	if (!next && data->host_cookie &&
+	    data->host_cookie != host->next_data.cookie) {
+		/*maybe bug*/
+		//pr_info(KERN_INFO DRIVER_NAME "[%s] invalid cookie: %d, next-cookie %d\n",
+		//	__func__, data->host_cookie, host->next_data.cookie);
+		data->host_cookie = 0;
+	}
+
+	/* Check if next job is already prepared */
+	if (next ||
+	    (!next && data->host_cookie != host->next_data.cookie)) {
+		sg_count = dma_map_sg(mmc_dev(host->mmc), data->sg,
+				     data->sg_len,
+				     data->flags & MMC_DATA_WRITE ?
+				     DMA_TO_DEVICE : DMA_FROM_DEVICE);
+
+	} else {
+		sg_count = host->next_data.sg_count;
+		host->next_data.sg_count = 0;
+	}
+
+
+	if (sg_count == 0)
+		return -EINVAL;
+
+	if (next) {
+		next->sg_count = sg_count;
+		data->host_cookie = ++next->cookie < 0 ? 1 : next->cookie;
+	} else
+		host->sg_count = sg_count;
+
+	return sg_count;
+}
+
+static void sdhci_pre_req(struct mmc_host *mmc, struct mmc_request *mrq)
+{
+	struct sdhci_host *host = mmc_priv(mmc);
+
+	if (mrq->data->host_cookie) {
+		mrq->data->host_cookie = 0;
+		return;
+	}
+
+	if (host->flags & SDHCI_REQ_USE_DMA)
+		if (sdhci_pre_dma_transfer(host,
+					mrq->data,
+					&host->next_data) < 0)
+			mrq->data->host_cookie = 0;
+}
+
+static void sdhci_card_event(struct mmc_host *mmc)
+{
+	struct sdhci_host *host = mmc_priv(mmc);
+	unsigned long flags;
+	int present;
+
+	//pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	/* First check if client has provided their own card event */
+	sdhci_w3k_card_event(host);
+
+	present = sdhci_do_get_cd(host);
+
+	spin_lock_irqsave(&host->lock, flags);
+
+	/* Check host->mrq first in case we are runtime suspended */
+	if (host->mrq && !present) {
+		pr_err("%s: Card removed during transfer!\n",
+			mmc_hostname(host->mmc));
+		pr_err("%s: Resetting controller.\n",
+			mmc_hostname(host->mmc));
+
+		sdhci_do_reset(host, SDHCI_RESET_CMD);
+//		sdhci_do_reset(host, SDHCI_RESET_DATA);
+
+		host->mrq->cmd->error = -ENOMEDIUM;
+		tasklet_schedule(&host->finish_tasklet);
+	}
+
+	spin_unlock_irqrestore(&host->lock, flags);
+}
+
+/******************************************************************************/
+
+static void sdhci_w3k_flush_dma(struct sdhci_host *host)
+{
+	//pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	sdhci_writel(host, 0x00020000, SDHCI_DMA_CTL_REG);
+	DBG("SDHCI_DMA_CTL_REG 0x%x\n", sdhci_readl(host, SDHCI_DMA_CTL_REG));
+
+	while (sdhci_readl(host, SDHCI_DMA_CTL_REG) & 0x00020000);
+}
+
+
+static int sdhci_w3k_enable_dma(struct sdhci_host *host)
+{
+	return 0;
+}
+
+static unsigned int sdhci_w3k_get_max_clock(struct sdhci_host *host)
+{
+#if 0
+#define SDHCI_W3K_MAX_CLK	200000000	/* 200MHz */
+#define SDHCI_W3K_MAX_CLK	166666666	/* 6 */
+#define SDHCI_W3K_MAX_CLK	142857140	/* 7 */
+#define SDHCI_W3K_MAX_CLK	125000000	/* 8 */
+#define SDHCI_W3K_MAX_CLK	111111110	/* 9 */
+#define SDHCI_W3K_MAX_CLK	100000000	/* 10 */
+#define SDHCI_W3K_MAX_CLK	 90909090	/* 11 */
+#define SDHCI_W3K_MAX_CLK	 83333333	/* 12 */
+#define SDHCI_W3K_MAX_CLK	 76923076	/* 13 */
+#define SDHCI_W3K_MAX_CLK	 71428571	/* 14 */
+#define SDHCI_W3K_MAX_CLK	 66666666	/* 15 */
+#define SDHCI_W3K_MAX_CLK	 62500000	/* 16 */
+#define SDHCI_W3K_MAX_CLK	 58823529	/* 17 */
+#define SDHCI_W3K_MAX_CLK	 55555555	/* 18 */
+#define SDHCI_W3K_MAX_CLK	 52631578	/* 19 */
+#define SDHCI_W3K_MAX_CLK	 50000000	/* 20 */
+#endif
+
+	return 50000000;
+}
+
+static unsigned int sdhci_w3k_get_min_clock(struct sdhci_host *host)
+{
+	return 0;
+}
+
+static unsigned int sdhci_w3k_get_timeout_clock(struct sdhci_host *host)
+{
+	return 0;
+}
+
+static unsigned int sdhci_w3k_get_max_timeout_count(struct sdhci_host *host)
+{
+	return (1 << 27);
+}
+
+static void sdhci_w3k_platform_send_init_74_clocks(struct sdhci_host *host,
+						      u8 power_mode)
+{
+
+}
+
+static unsigned int sdhci_w3k_get_ro(struct sdhci_host *host)
+{
+	return 0;
+}
+
+#ifdef DISPLAY_SHMOO
+static void print_binary(u32 val)
+{
+	int i;
+
+	printk("{ 0, ");
+	for (i = 31; i > 0; i--) {
+		printk("%d, ", (((val >> i) & 0x1) == 1) ? 0 : 1);
+	}
+	printk("%d, 0 },\n", (((val >> i) & 0x1) == 1) ? 0 : 1);
+}
+#endif
+
+struct shmoo_result {
+	u32 run;
+	u32 rlat_neg;
+	u32 dlat_neg;
+	u32 sel_fck;
+	u32 rlat_sel;
+	u32 dlat_sel;
+	u32 fdl_n;
+	u32 idl_n;
+};
+
+static unsigned char shmoo[128][34][34];
+
+#define SHMOO_RESULT	300
+static struct shmoo_result result[SHMOO_RESULT];
+static int shmoo_count = 0;
+
+void display_tuning_array(int mode)
+{
+	int i, j;
+
+	printk("\n");
+
+	for (i = 0; i < 34; i++) {
+		printk("%02d ", i);
+		for (j = 33; j >= 0; j--) {
+			printk("%d ", shmoo[mode][i][j]);
+		}
+		printk("\n");
+	}
+}
+
+void shmoo_find_useful_value(int mode, u32 rlat_neg, u32 dlat_neg, u32 sel_fck,
+				u32 rlat_sel, u32 dlat_sel)
+{
+	int x, y, p = 0;
+	int run, count = 0;
+	static unsigned char tuning[2][34][34];
+
+	for (x = 0; x < 34; x++) {
+		for (y = 33; y >= 0; y--) {
+			tuning[0][x][y] = shmoo[mode][x][y];
+			tuning[1][x][y] = shmoo[mode][x][y];
+		}
+	}
+
+	for (run = 0; run < 16; run++) {
+		for (x = 1; x < 33; x++) {
+			for (y = 1; y < 33; y++) {
+				if ((tuning[p][x - 1][y - 1] == 0) ||
+				    (tuning[p][x - 1][y] == 0) ||
+				    (tuning[p][x - 1][y + 1] == 0) ||
+				    (tuning[p][x][y - 1] == 0) ||
+				    (tuning[p][x][y] == 0) ||
+				    (tuning[p][x][y + 1] == 0) ||
+				    (tuning[p][x + 1][y - 1] == 0) ||
+				    (tuning[p][x + 1][y] == 0) ||
+				    (tuning[p][x + 1][y + 1] == 0)) {
+					tuning[1 - p][x][y] = 0;
+				} else {
+					tuning[1 - p][x][y] = 1;
+				}
+			}
+		}
+		p = 1 - p;
+
+#if 0		/* output */
+		printk("\n");
+		for (x = 0; x < 34; x++) {
+			printk("%02d  ", x);
+//			for (y = 0; y < 34; y++)
+			for (y = 33; y >= 0; y--) {
+				printk("%d ", tuning[p][x][y]);
+			printk("\n");
+		}
+		printk("\n");
+#endif
+		count = 0;
+
+		for (x = 0; x < 34; x++)
+			for (y = 0; y < 34; y++)
+				if (tuning[p][x][y] == 1)
+					count++;
+
+		if (count == 0) {
+			if (run < 4) {
+				printk("<ERROR> windows too small, skip! %d\n", run);
+				return;
+			}
+
+			for (x = 0; x < 34; x++)
+				for (y = 0; y < 34; y++)
+					if (tuning[1 - p][x][y] == 1) {
+						if (shmoo_count >= SHMOO_RESULT) {
+							printk("<ERROR> result %d\n", shmoo_count);
+							return;
+						}
+						result[shmoo_count].run = run;
+						result[shmoo_count].rlat_neg = rlat_neg;
+						result[shmoo_count].dlat_neg = dlat_neg;
+						result[shmoo_count].sel_fck = sel_fck;
+						result[shmoo_count].rlat_sel = rlat_sel;
+						result[shmoo_count].dlat_sel = dlat_sel;
+						result[shmoo_count].fdl_n = ((x * 2) + 1);
+						result[shmoo_count].idl_n = ((y * 2) + 1);
+						shmoo_count++;
+					}
+		}
+	}
+}
+
+void shmoo_set_best_value(struct sdhci_host *host)
+{
+	u32 rlat_neg = 0, dlat_neg = 0, sel_fck = 1, rlat_sel = 0, dlat_sel = 0;
+	u32 fdl_n = 0, idl_n = 0;
+	u32 val;
+
+	int i, run = 0;
+
+	for (i = 0; i < SHMOO_RESULT; i++) {
+		if (result[i].run > run) {
+			run = result[i].run;
+			rlat_neg = result[i].rlat_neg;
+			dlat_neg = result[i].dlat_neg;
+			sel_fck = result[i].sel_fck;
+			rlat_sel = result[i].rlat_sel;
+			dlat_sel = result[i].dlat_sel;
+			fdl_n = result[i].fdl_n;
+			idl_n = result[i].idl_n;
+		}
+	}
+
+	while (sdhci_readl(host, SDHCI_STA_REG) & 0x3);
+
+	val = sdhci_readl(host, SDHCI_LAT_REG);
+	val &= ~0x00FFFF7F;
+	val |= ((fdl_n << 16) | (idl_n << 8) |
+		(dlat_sel << 5) |
+		(rlat_sel << 3) | (dlat_neg << 2) |
+		(rlat_neg << 1) | (sel_fck << 0));
+	sdhci_writel(host, val, SDHCI_LAT_REG);
+
+	printk("SDHCI_LAT_REG : 0x%x\n", sdhci_readl(host, SDHCI_LAT_REG));
+
+	val = sdhci_readl(host, SDHCI_KDL_REG);
+	val &= ~0x0000000F;
+	val |= 0x00000002;
+	val |= ((1 << 6) | (1 << 5));
+	sdhci_writel(host, val, SDHCI_KDL_REG);
+	while (sdhci_readl(host, SDHCI_KDL_REG) & 0x0000060);
+}
+
+static int sdhci_w3k_platform_execute_tuning(struct sdhci_host *host, u32 opcode)
+{
+	u16 ctrl;
+	int tuning_loop_counter = MAX_TUNING_LOOP;
+	int err = 0;
+	unsigned long flags;
+	unsigned int tuning_count = 0;
+
+	printk("%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	spin_lock_irqsave(&host->lock, flags);
+
+	memset(shmoo, 0, sizeof(shmoo));
+	memset(result, 0, sizeof(result));
+	shmoo_count = 0;
+
+//	ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
+	ctrl = host->sdhci_host_control2;
+	ctrl |= SDHCI_CTRL_EXEC_TUNING;
+	if (host->quirks2 & SDHCI_QUIRK2_TUNING_WORK_AROUND)
+		ctrl |= SDHCI_CTRL_TUNED_CLK;
+//	sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
+	host->sdhci_host_control2 = ctrl;
+
+	/*
+	 * As per the Host Controller spec v3.00, tuning command
+	 * generates Buffer Read Ready interrupt, so enable that.
+	 *
+	 * Note: The spec clearly says that when tuning sequence
+	 * is being performed, the controller does not generate
+	 * interrupts other than Buffer Read Ready interrupt. But
+	 * to make sure we don't hit a controller bug, we _only_
+	 * enable Buffer Read Ready interrupt here.
+	 */
+	sdhci_writel(host, SDHCI_INT_DATA_AVAIL, SDHCI_IEN_REG);
+//	sdhci_writel(host, SDHCI_INT_DATA_AVAIL, SDHCI_SIGNAL_ENABLE);
+
+	/*
+	 * Issue CMD19 repeatedly till Execute Tuning is set to 0 or the number
+	 * of loops reaches 40 times or a timeout of 150ms occurs.
+	 */
+	do {
+		struct mmc_command cmd = {0};
+		struct mmc_request mrq = {NULL};
+
+		int mode;
+
+		u32 rlat_neg = 0, dlat_neg = 0, sel_fck = 1, rlat_sel = 0, dlat_sel = 0;
+		u32 fdl_n = 0, idl_n = 0;
+
+		u32 val;
+
+#if 0	/* 128 mode */
+		for (rlat_neg = 0; rlat_neg < 2; rlat_neg++) {
+		for (dlat_neg = 0; dlat_neg < 2; dlat_neg++) {
+		for (sel_fck = 0; sel_fck < 2; sel_fck++) {
+		for (rlat_sel = 0; rlat_sel < 4; rlat_sel++) {
+		for (dlat_sel = 0; dlat_sel < 4; dlat_sel++) {
+#endif
+#if 0	/* 16 mode */
+		for (rlat_neg = 0; rlat_neg < 2; rlat_neg++) {
+		{
+		for (sel_fck = 0; sel_fck < 2; sel_fck++) {
+		for (rlat_sel = 0; rlat_sel < 4; rlat_sel++) {
+		{
+			dlat_neg = rlat_neg;
+			dlat_sel = rlat_sel;
+#endif
+#if 1	/* 4 mode */
+		for (rlat_neg = 0; rlat_neg < 2; rlat_neg++) {
+		{
+		{
+		for (rlat_sel = 0; rlat_sel < 2; rlat_sel++) {
+		{
+			dlat_neg = rlat_neg;
+			dlat_sel = rlat_sel;
+#endif
+
+		mode = ((((rlat_neg) * 2 + dlat_neg) * 2 + sel_fck) * 4 + rlat_sel) * 4 + dlat_sel;
+			
+#ifdef DISPLAY_SHMOO
+		printk("\n");
+		printk("{\t /* %d %d %d %d %d */\n", rlat_neg, dlat_neg, sel_fck, rlat_sel, dlat_sel);
+		print_binary(0xFFFFFFFF);
+#endif
+
+		for (fdl_n = 1; fdl_n < 64; fdl_n += 2) {
+#ifdef DISPLAY_SHMOO
+//			printk("< %d, %d, %d, %d, %d, %d>\t",
+//				sel_fck, rlat_neg, dlat_neg, rlat_sel, dlat_sel, fdl_n);
+			printk("<%d>\t", fdl_n);
+#endif
+
+			while (sdhci_readl(host, SDHCI_STA_REG) & 0x3);
+
+			val = sdhci_readl(host, SDHCI_LAT_REG);
+			val &= ~0x00FF007F;
+			val |= ((fdl_n << 16) | (dlat_sel << 5) |
+				(rlat_sel << 3) | (dlat_neg << 2) |
+				(rlat_neg << 1) | (sel_fck << 0));
+			sdhci_writel(host, val, SDHCI_LAT_REG);
+
+			val = sdhci_readl(host, SDHCI_KDL_REG);
+			val &= ~0x0000000F;
+			val |= 0x00000002;
+			val |= (1 << 5);
+			sdhci_writel(host, val, SDHCI_KDL_REG);
+			while (sdhci_readl(host, SDHCI_KDL_REG) & 0x0000020);
+
+			val = sdhci_readl(host, SDHCI_ATRG_REG);
+			val &= ~(0x0000000F);
+			val |= 0x00000002;
+			sdhci_writel(host, val, SDHCI_ATRG_REG);
+
+			val = 0x00000001;
+			sdhci_writel(host, val, SDHCI_BLK_REG);
+
+			sdhci_writel(host, host->adma_addr, SDHCI_SDMA_SADDR_REG);
+			sdhci_writel(host, 0x80000000, SDHCI_DMA_CTL_REG);
+
+			if (host->mmc->ios.bus_width == MMC_BUS_WIDTH_8)
+				sdhci_writel(host, 128, SDHCI_SDMA_LEN_REG);
+			else if (host->mmc->ios.bus_width == MMC_BUS_WIDTH_4)
+				sdhci_writel(host, 64, SDHCI_SDMA_LEN_REG);
+
+		cmd.opcode = opcode;
+		cmd.arg = 0;
+		cmd.flags = MMC_RSP_R1 | MMC_CMD_ADTC;
+		cmd.retries = 0;
+		cmd.data = NULL;
+		cmd.error = 0;
+
+//		if (tuning_loop_counter-- == 0)
+//			break;
+
+		mrq.cmd = &cmd;
+		host->mrq = &mrq;
+
+#if 0
+		/*
+		 * In response to CMD19, the card sends 64 bytes of tuning
+		 * block to the Host Controller. So we set the block size
+		 * to 64 here.
+		 */
+		if (cmd.opcode == MMC_SEND_TUNING_BLOCK_HS200) {
+			if (mmc->ios.bus_width == MMC_BUS_WIDTH_8)
+				sdhci_writew(host, SDHCI_MAKE_BLKSZ(7, 128),
+					     SDHCI_BLOCK_SIZE);
+			else if (mmc->ios.bus_width == MMC_BUS_WIDTH_4)
+				sdhci_writew(host, SDHCI_MAKE_BLKSZ(7, 64),
+					     SDHCI_BLOCK_SIZE);
+		} else {
+			sdhci_writew(host, SDHCI_MAKE_BLKSZ(7, 64),
+				     SDHCI_BLOCK_SIZE);
+		}
+
+		/*
+		 * The tuning block is sent by the card to the host controller.
+		 * So we set the TRNS_READ bit in the Transfer Mode register.
+		 * This also takes care of setting DMA Enable and Multi Block
+		 * Select in the same register to 0.
+		 */
+		sdhci_writew(host, SDHCI_TRNS_READ, SDHCI_TRANSFER_MODE);
+#endif
+
+		sdhci_send_command(host, &cmd);
+
+		host->cmd = NULL;
+		host->mrq = NULL;
+
+		spin_unlock_irqrestore(&host->lock, flags);
+		/* Wait for Buffer Read Ready interrupt */
+		wait_event_interruptible_timeout(host->buf_ready_int,
+					(host->tuning_done == 1),
+					msecs_to_jiffies(50));
+		spin_lock_irqsave(&host->lock, flags);
+
+		if (!host->tuning_done) {
+			pr_info(DRIVER_NAME ": Timeout waiting for "
+				"Buffer Read Ready interrupt during tuning "
+				"procedure, falling back to fixed sampling "
+				"clock\n");
+//			ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
+			ctrl = host->sdhci_host_control2;
+			ctrl &= ~SDHCI_CTRL_TUNED_CLK;
+			ctrl &= ~SDHCI_CTRL_EXEC_TUNING;
+//			sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
+			host->sdhci_host_control2 = ctrl;
+
+			err = -EIO;
+			goto out;
+		}
+
+		mdelay(5);
+
+		if (mode >= 128)
+			printk("<ERROR> mode %d\n", mode);
+		if (((((fdl_n - 1) / 2) + 1) <= 0) || ((((fdl_n - 1) / 2) + 1) >= 33))
+			printk("<ERROR> fdl_n %d\n", fdl_n);
+
+		idl_n = sdhci_readl(host, SDHCI_A19_ST0_REG);
+//		shmoo[mode][(((fdl_n - 1) / 2) + 1)][0] = 0;
+		for (val = 1; val < 33; val++) {
+			shmoo[mode][(((fdl_n - 1) / 2) + 1)][val] = 
+					(((idl_n >> (val - 1)) & 0x1) == 1) ? 0 : 1;
+		}
+//		shmoo[mode][(((fdl_n - 1) / 2) + 1)][33] = 0;
+
+#ifdef DISPLAY_SHMOO
+		print_binary(idl_n);
+		printk("%08x\n", idl_n);
+#endif
+
+		/* eMMC spec does not require a delay between tuning cycles */
+		if (opcode == MMC_SEND_TUNING_BLOCK)
+			mdelay(1);
+		}	/* for (fdl_n = 1; fdl_n < 64; fdl_n += 2) { */
+
+#ifdef DISPLAY_SHMOO
+		print_binary(0xffffffff);
+		printk("},\n");
+#endif
+
+//		display_tuning_array(mode);
+
+		shmoo_find_useful_value(mode, rlat_neg, dlat_neg, sel_fck, rlat_sel, dlat_sel);
+
+		}}}}}
+
+		shmoo_set_best_value(host);
+
+		ctrl = host->sdhci_host_control2;
+		ctrl &= ~SDHCI_CTRL_EXEC_TUNING;
+		host->sdhci_host_control2 = ctrl;
+
+		host->tuning_done = 0;
+
+		ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
+		ctrl = host->sdhci_host_control2;
+
+		/* eMMC spec does not require a delay between tuning cycles */
+		if (opcode == MMC_SEND_TUNING_BLOCK)
+			mdelay(1);
+	} while (ctrl & SDHCI_CTRL_EXEC_TUNING);
+
+	/*
+	 * The Host Driver has exhausted the maximum number of loops allowed,
+	 * so use fixed sampling frequency.
+	 */
+	if (tuning_loop_counter < 0) {
+		ctrl &= ~SDHCI_CTRL_TUNED_CLK;
+//		sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
+		host->sdhci_host_control2 = ctrl;
+	}
+	if (!(ctrl & SDHCI_CTRL_TUNED_CLK)) {
+		pr_info(DRIVER_NAME ": Tuning procedure"
+			" failed, falling back to fixed sampling"
+			" clock\n");
+		err = -EIO;
+	}
+
+out:
+	host->flags &= ~SDHCI_NEEDS_RETUNING;
+
+	if (tuning_count) {
+		host->flags |= SDHCI_USING_RETUNING_TIMER;
+		mod_timer(&host->tuning_timer, jiffies + tuning_count * HZ);
+	}
+
+	/*
+	 * In case tuning fails, host controllers which support re-tuning can
+	 * try tuning again at a later time, when the re-tuning timer expires.
+	 * So for these controllers, we return 0. Since there might be other
+	 * controllers who do not have this capability, we return error for
+	 * them. SDHCI_USING_RETUNING_TIMER means the host is currently using
+	 * a retuning timer to do the retuning for the card.
+	 */
+	if (err && (host->flags & SDHCI_USING_RETUNING_TIMER))
+		err = 0;
+
+	sdhci_writel(host, host->ier, SDHCI_IEN_REG);
+//	sdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);
+
+	printk("%s : %s() done\n", mmc_hostname(host->mmc), __func__);
+
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	return err;
+}
+
+static void sdhci_w3k_hw_reset(struct sdhci_host *host)
+{
+
+}
+
+static void sdhci_w3k_adma_workaround(struct sdhci_host *host, u32 intmask)
+{
+	pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	sdhci_writel(host, 0x00020000, SDHCI_DMA_CTL_REG);
+	DBG("SDHCI_DMA_CTL_REG 0x%x\n", sdhci_readl(host, SDHCI_DMA_CTL_REG));
+
+	while (sdhci_readl(host, SDHCI_DMA_CTL_REG) & 0x00020000);
+}
+
+static void sdhci_w3k_card_event(struct sdhci_host *host)
+{
+
+}
+
+static void sdhci_w3k_voltage_switch(struct sdhci_host *host)
+{
+
+}
+
+/******************************************************************************/
+
+static const struct mmc_host_ops sdhci_ops = {
+	.request	= sdhci_request,
+	.post_req	= sdhci_post_req,
+	.pre_req	= sdhci_pre_req,
+	.set_ios	= sdhci_set_ios,
+	.get_cd		= sdhci_get_cd,
+	.get_ro		= sdhci_get_ro,
+	.hw_reset	= sdhci_hw_reset,
+	.enable_sdio_irq = sdhci_enable_sdio_irq,
+	.start_signal_voltage_switch	= sdhci_start_signal_voltage_switch,
+	.prepare_hs400_tuning		= sdhci_prepare_hs400_tuning,
+	.execute_tuning			= sdhci_execute_tuning,
+	.card_event			= sdhci_card_event,
+#if 0
+	.card_busy	= sdhci_card_busy,
+#endif
+};
+
+/*****************************************************************************\
+ *                                                                           *
+ * Tasklets                                                                  *
+ *                                                                           *
+\*****************************************************************************/
+
+static void sdhci_tasklet_finish(unsigned long param)
+{
+	struct sdhci_host *host;
+	unsigned long flags;
+	struct mmc_request *mrq;
+
+	host = (struct sdhci_host*)param;
+
+	//pr_info(KERN_INFO "%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	spin_lock_irqsave(&host->lock, flags);
+
+        /*
+         * If this tasklet gets rescheduled while running, it will
+         * be run again afterwards but without any active request.
+         */
+	if (!host->mrq) {
+		spin_unlock_irqrestore(&host->lock, flags);
+		return;
+	}
+
+	del_timer(&host->timer);
+
+	mrq = host->mrq;
+
+	/*
+	 * The controller needs a reset of internal state machines
+	 * upon error conditions.
+	 */
+	if (!(host->flags & SDHCI_DEVICE_DEAD) &&
+	    ((mrq->cmd && mrq->cmd->error) ||
+//	     (mrq->sbc && mrq->sbc->error) ||
+	     (mrq->data && ((mrq->data->error && !mrq->data->stop) ||
+			    (mrq->data->stop && mrq->data->stop->error))) ||
+	     (host->quirks & SDHCI_QUIRK_RESET_AFTER_REQUEST))) {
+
+		/* Some controllers need this kick or reset won't work here */
+		if (host->quirks & SDHCI_QUIRK_CLOCK_BEFORE_RESET)
+			/* This is to force an update */
+			sdhci_set_clock(host, host->clock);
+
+		/* Spec says we should do both at the same time, but Ricoh
+		   controllers do not like that. */
+		sdhci_do_reset(host, SDHCI_RESET_CMD);
+//		sdhci_do_reset(host, SDHCI_RESET_DATA);
+	}
+
+	host->mrq = NULL;
+	host->cmd = NULL;
+	host->data = NULL;
+
+	mb();
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	sdhci_enable_card_detect(host);
+
+	mmc_request_done(host->mmc, mrq);
+	sdhci_runtime_pm_put(host);
+}
+
+static void sdhci_timeout_timer(struct timer_list *timer)
+{
+	struct sdhci_host *host;
+	unsigned long flags;
+
+	host = container_of(timer, struct sdhci_host, timer);;
+
+	//pr_info(KERN_INFO "\n%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	spin_lock_irqsave(&host->lock, flags);
+
+	if (host->mrq) {
+		pr_err("%s: Timeout waiting for hardware "
+			"interrupt.\n", mmc_hostname(host->mmc));
+		pr_err("command (%d) flag : 0x%x\n",
+				SDHCI_GET_CMD(sdhci_readl(host, SDHCI_COMMAND)),
+				host->resp_flag);
+
+		sdhci_dumpregs(host);
+
+		if (host->data) {
+			host->data->error = -ETIMEDOUT;
+			sdhci_finish_data(host);
+		} else {
+			if (host->cmd)
+				host->cmd->error = -ETIMEDOUT;
+			else
+				host->mrq->cmd->error = -ETIMEDOUT;
+
+			tasklet_schedule(&host->finish_tasklet);
+		}
+	}
+
+	mb();
+	spin_unlock_irqrestore(&host->lock, flags);
+}
+
+static void sdhci_tuning_timer(struct timer_list *timer)
+{
+	struct sdhci_host *host;
+	unsigned long flags;
+
+	host =  container_of(timer, struct sdhci_host, timer);
+
+	spin_lock_irqsave(&host->lock, flags);
+
+	host->flags |= SDHCI_NEEDS_RETUNING;
+
+	spin_unlock_irqrestore(&host->lock, flags);
+}
+
+/*****************************************************************************\
+ *                                                                           *
+ * Interrupt handling                                                        *
+ *                                                                           *
+\*****************************************************************************/
+
+static void sdhci_cmd_irq(struct sdhci_host *host, u32 intmask, u32 *mask)
+{
+	u32 val = 0;
+
+	BUG_ON(intmask == 0);
+	//printk(KERN_INFO "cmd_irq\n");
+	if (!host->cmd) {
+		pr_err("%s: Got command interrupt 0x%08x even "
+			"though no command operation was in progress.\n",
+			mmc_hostname(host->mmc), (unsigned)intmask);
+		sdhci_dumpregs(host);
+		return;
+	}
+
+	if (intmask & SDHCI_INT_TIMEOUT) {
+		//printk("cmd timeout, ");
+#if 1	/* Fixed IC Bug */
+		if (mmc_resp_type(host->cmd) == MMC_RSP_R1B) {
+			val = sdhci_readl(host, SDHCI_PIN_REG);
+			printk("read reg - SDHCI_PIN_REG 0x%x\n", val);
+		}
+
+		if (val & 0x00ff0000) {	/* [23:16] data pin [7:0] */
+			host->resp_flag |= MMC_CMD_DONE_FLAG;
+		} else {
+			host->cmd->error = -ETIMEDOUT;
+		}
+#else
+		host->cmd->error = -ETIMEDOUT;
+#endif
+	} else if (intmask & (SDHCI_INT_CRC /*| SDHCI_INT_END_BIT |
+			SDHCI_INT_INDEX*/)) {
+		printk("cmd crc error, ");
+		host->cmd->error = -EILSEQ;
+	}
+
+	if (host->cmd->error) {
+		//printk("command (%d)\n", SDHCI_GET_CMD(sdhci_readl(host, SDHCI_COMMAND)));
+		sdhci_dumpregs(host);
+		tasklet_schedule(&host->finish_tasklet);
+		return;
+	}
+
+	/*
+	 * The host can send and interrupt when the busy state has
+	 * ended, allowing us to wait without wasting CPU cycles.
+	 * Unfortunately this is overloaded on the "data complete"
+	 * interrupt, so we need to take some care when handling
+	 * it.
+	 *
+	 * Note: The 1.0 specification is a bit ambiguous about this
+	 *       feature so there might be some problems with older
+	 *       controllers.
+	 */
+	if (host->cmd->flags & MMC_RSP_BUSY) {
+		if (host->cmd->data)
+			DBG("Cannot wait for busy signal when also "
+				"doing a data transfer");
+		else if (!(host->quirks & SDHCI_QUIRK_NO_BUSY_IRQ)
+				&& !host->busy_handle) {
+			/* Mark that command complete before busy is ended */
+			host->busy_handle = 1;
+			return;
+		}
+
+		/* The controller does not support the end-of-busy IRQ,
+		 * fall through and take the SDHCI_INT_RESPONSE */
+	} else if ((host->quirks2 & SDHCI_QUIRK2_STOP_WITH_TC) &&
+		   host->cmd->opcode == MMC_STOP_TRANSMISSION && !host->data) {
+		*mask &= ~SDHCI_INT_DATA_END;
+	}
+
+	if (intmask & SDHCI_INT_RESPONSE)
+		sdhci_finish_command(host);
+}
+
+#ifdef CONFIG_MMC_DEBUG
+static void sdhci_adma_show_error(struct sdhci_host *host)
+{
+	const char *name = mmc_hostname(host->mmc);
+	void *desc = host->adma_table;
+
+	sdhci_dumpregs(host);
+
+	while (true) {
+		struct sdhci_adma2_64_desc *dma_desc = desc;
+
+		if (host->flags & SDHCI_USE_64_BIT_DMA)
+			DBG("%s: %p: DMA 0x%08x%08x, LEN 0x%04x, Attr=0x%02x\n",
+			    name, desc, le32_to_cpu(dma_desc->addr_hi),
+			    le32_to_cpu(dma_desc->addr_lo),
+			    le16_to_cpu(dma_desc->len),
+			    le16_to_cpu(dma_desc->cmd));
+		else
+			DBG("%s: %p: DMA 0x%08x, LEN 0x%04x, Attr=0x%02x\n",
+			    name, desc, le32_to_cpu(dma_desc->addr_lo),
+			    le16_to_cpu(dma_desc->len),
+			    le16_to_cpu(dma_desc->cmd));
+
+		desc += host->desc_sz;
+
+		if (dma_desc->cmd & cpu_to_le16(ADMA2_END))
+			break;
+	}
+}
+#else
+static void sdhci_adma_show_error(struct sdhci_host *host) { }
+#endif
+
+static void sdhci_data_irq(struct sdhci_host *host, u32 intmask, u32 dmamask)
+{
+	u32 command;
+	BUG_ON((intmask == 0) && (dmamask == 0));
+	//printk(KERN_INFO "data_irq\n");
+	/* CMD19 generates _only_ Buffer Read Ready interrupt */
+	
+	if (intmask & SDHCI_INT_DATA_AVAIL) {
+		command = SDHCI_GET_CMD(sdhci_readl(host, SDHCI_COMMAND));
+		
+		if (command == MMC_SEND_TUNING_BLOCK ||
+		    command == MMC_SEND_TUNING_BLOCK_HS200) {
+
+			u32 ctrl = host->sdhci_host_control2;
+			ctrl &= ~SDHCI_CTRL_EXEC_TUNING;
+			host->sdhci_host_control2 = ctrl;
+			
+			host->tuning_done = 1;
+			wake_up(&host->buf_ready_int);
+			return;
+		}
+	}
+
+	if (!host->data) {
+		/*
+		 * The "data complete" interrupt is also used to
+		 * indicate that a busy state has ended. See comment
+		 * above in sdhci_cmd_irq().
+		 */
+		
+		if (host->cmd && (host->cmd->flags & MMC_RSP_BUSY)) {
+			if (intmask & SDHCI_INT_DATA_TIMEOUT) {
+				host->cmd->error = -ETIMEDOUT;
+				tasklet_schedule(&host->finish_tasklet);
+				
+				return;
+			}
+			if (intmask & SDHCI_INT_DATA_END) {
+				/*
+				 * Some cards handle busy-end interrupt
+				 * before the command completed, so make
+				 * sure we do things in the proper order.
+				 */
+				
+				if (host->busy_handle)
+					sdhci_finish_command(host);
+				else
+					host->busy_handle = 1;
+				return;
+			}
+		}
+		
+		pr_err("%s: Got data interrupt 0x%08x even "
+			"though no data operation was in progress.\n",
+			mmc_hostname(host->mmc), (unsigned)intmask);
+		sdhci_dumpregs(host);
+
+		return;
+	}
+
+	if (intmask & SDHCI_INT_DATA_TIMEOUT) {
+		host->data->error = -ETIMEDOUT;
+		printk("data timeout, ");
+
+//	else if (intmask & SDHCI_INT_DATA_END_BIT)
+//		host->data->error = -EILSEQ;
+	} else if ((intmask & SDHCI_INT_DATA_CRC) &&
+		SDHCI_GET_CMD(sdhci_readl(host, SDHCI_COMMAND))
+			!= MMC_BUS_TEST_R) {
+		host->data->error = -EILSEQ;
+		printk("data crc error, ");
+	} else if (intmask & SDHCI_INT_DATA_END)
+		host->resp_flag |= MMC_DATA_DONE_FLAG;
+
+	if ((dmamask & SDHCI_INT_DMA_END) ||
+	    (dmamask & SDHCI_INT_ADMA_END))
+		host->resp_flag |= MMC_DMA_DONE_FLAG;
+	else if (dmamask & SDHCI_INT_ADMA_ERROR) {
+		pr_err("%s: ADMA error\n", mmc_hostname(host->mmc));
+		sdhci_adma_show_error(host);
+		host->data->error = -EIO;
+		sdhci_w3k_adma_workaround(host, intmask);
+	}
+	
+	if (host->data->error) {
+		printk("command (%d)\n", SDHCI_GET_CMD(sdhci_readl(host, SDHCI_COMMAND)));
+		sdhci_dumpregs(host);
+		sdhci_finish_data(host);
+	} else {
+#if 0
+		if (intmask & (SDHCI_INT_DATA_AVAIL | SDHCI_INT_SPACE_AVAIL))
+			sdhci_transfer_pio(host);
+
+		/*
+		 * We currently don't do anything fancy with DMA
+		 * boundaries, but as we can't disable the feature
+		 * we need to at least restart the transfer.
+		 *
+		 * According to the spec sdhci_readl(host, SDHCI_DMA_ADDRESS)
+		 * should return a valid address to continue from, but as
+		 * some controllers are faulty, don't trust them.
+		 */
+		if (intmask & SDHCI_INT_DMA_END) {
+			u32 dmastart, dmanow;
+			dmastart = sg_dma_address(host->data->sg);
+			dmanow = dmastart + host->data->bytes_xfered;
+			/*
+			 * Force update to the next DMA block boundary.
+			 */
+			dmanow = (dmanow &
+				~(SDHCI_DEFAULT_BOUNDARY_SIZE - 1)) +
+				SDHCI_DEFAULT_BOUNDARY_SIZE;
+			host->data->bytes_xfered = dmanow - dmastart;
+			DBG("%s: DMA base 0x%08x, transferred 0x%06x bytes,"
+				" next 0x%08x\n",
+				mmc_hostname(host->mmc), dmastart,
+				host->data->bytes_xfered, dmanow);
+			sdhci_writel(host, dmanow, SDHCI_DMA_ADDRESS);
+		}
+#endif
+
+//		if (intmask & SDHCI_INT_DATA_END) {
+		if ((host->resp_flag & MMC_DATA_DONE_FLAG) &&
+		    (host->resp_flag & MMC_DMA_DONE_FLAG)) {
+			if (host->cmd) {
+				/*
+				 * Data managed to finish before the
+				 * command completed. Make sure we do
+				 * things in the proper order.
+				 */
+				host->data_early = 1;
+				
+			} else {
+				
+				sdhci_finish_data(host);
+				
+			}
+		}
+	}
+}
+
+static irqreturn_t sdhci_irq(int irq, void *dev_id)
+{
+	irqreturn_t result = IRQ_NONE;
+	struct sdhci_host *host = dev_id;
+	u32 intmask, dmamask, mask, unexpected = 0;
+	int max_loops = 16;
+	//printk(KERN_INFO "sdhci_irq\n");
+	spin_lock(&host->lock);
+
+	if (host->runtime_suspended && !sdhci_sdio_irq_enabled(host)) {
+		spin_unlock(&host->lock);
+		return IRQ_NONE;
+	}
+
+	intmask = sdhci_readl(host, SDHCI_INT_STATUS);
+	dmamask = sdhci_readl(host, SDHCI_DMA_STA_REG);
+	//printk(KERN_INFO "intmask %x dmamask %x\n", intmask, dmamask);
+	if ((!intmask || intmask == 0xffffffff) &&
+	    (!dmamask)) {
+		result = IRQ_NONE;
+		goto out;
+	}
+
+	do {
+		/* Clear selected interrupts. */
+		mask = intmask & (SDHCI_INT_CMD_MASK | SDHCI_INT_DATA_MASK /*|
+				  SDHCI_INT_BUS_POWER*/);
+		sdhci_writel(host, mask, SDHCI_INT_STATUS);
+		sdhci_writel(host, dmamask, SDHCI_DMA_STA_REG);
+
+		//printk(KERN_INFO "*** %s got interrupt: 0x%08x 0x%08x\n",
+		//	mmc_hostname(host->mmc), intmask, dmamask);
+
+		if (intmask & (SDHCI_INT_CARD_INSERT | SDHCI_INT_CARD_REMOVE)) {
+			u32 present = sdhci_readl(host, SDHCI_PRESENT_STATE) &
+				      SDHCI_CARD_PRESENT;
+
+			host->card_present = !!present;
+
+			printk("%s : card insert/remove interrupt (0x%08x)\n",
+					mmc_hostname(host->mmc),
+					sdhci_readl(host, SDHCI_PRESENT_STATE));
+
+			/*
+			 * There is a observation on i.mx esdhc.  INSERT
+			 * bit will be immediately set again when it gets
+			 * cleared, if a card is inserted.  We have to mask
+			 * the irq to prevent interrupt storm which will
+			 * freeze the system.  And the REMOVE gets the
+			 * same situation.
+			 *
+			 * More testing are needed here to ensure it works
+			 * for other platforms though.
+			 */
+//			host->ier &= ~(SDHCI_INT_CARD_INSERT |
+//				       SDHCI_INT_CARD_REMOVE);
+//			host->ier |= present ? SDHCI_INT_CARD_REMOVE :
+//					       SDHCI_INT_CARD_INSERT;
+//			sdhci_writel(host, host->ier, SDHCI_INT_ENABLE);
+//			sdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);
+
+			sdhci_writel(host, intmask & (SDHCI_INT_CARD_INSERT |
+				     SDHCI_INT_CARD_REMOVE), SDHCI_INT_STATUS);
+
+			host->thread_isr |= intmask & (SDHCI_INT_CARD_INSERT |
+						       SDHCI_INT_CARD_REMOVE);
+			result = IRQ_WAKE_THREAD;
+		}
+
+		if (intmask & SDHCI_INT_CMD_MASK){
+			sdhci_cmd_irq(host, intmask & SDHCI_INT_CMD_MASK,
+				      &intmask);
+		}
+		if ((intmask & SDHCI_INT_DATA_MASK) ||
+		    (dmamask & SDHCI_INT_DMA_MASK)){
+			sdhci_data_irq(host, (intmask & SDHCI_INT_DATA_MASK),
+					     (dmamask & SDHCI_INT_DMA_MASK));
+		}
+#if 0
+		if (intmask & SDHCI_INT_BUS_POWER)
+			pr_err("%s: Card is consuming too much power!\n",
+				mmc_hostname(host->mmc));
+
+		if (intmask & SDHCI_INT_CARD_INT) {
+			sdhci_enable_sdio_irq_nolock(host, false);
+			host->thread_isr |= SDHCI_INT_CARD_INT;
+			result = IRQ_WAKE_THREAD;
+		}
+#endif
+
+		intmask &= ~(SDHCI_INT_CARD_INSERT | SDHCI_INT_CARD_REMOVE |
+			     SDHCI_INT_CMD_MASK | SDHCI_INT_DATA_MASK /*|
+			     SDHCI_INT_ERROR | SDHCI_INT_BUS_POWER |
+			     SDHCI_INT_CARD_INT*/);
+
+		if (intmask) {
+			unexpected |= intmask;
+			sdhci_writel(host, intmask, SDHCI_INT_STATUS);
+		}
+
+		if (result == IRQ_NONE)
+			result = IRQ_HANDLED;
+
+		intmask = sdhci_readl(host, SDHCI_INT_STATUS);
+		dmamask = sdhci_readl(host, SDHCI_DMA_STA_REG);
+	} while (intmask && --max_loops);
+out:
+	spin_unlock(&host->lock);
+
+#if 0
+	if (unexpected) {
+		pr_err("%s: Unexpected interrupt 0x%08x.\n",
+			   mmc_hostname(host->mmc), unexpected);
+		sdhci_dumpregs(host);
+	}
+#endif
+
+	return result;
+}
+
+static irqreturn_t sdhci_thread_irq(int irq, void *dev_id)
+{
+	struct sdhci_host *host = dev_id;
+	unsigned long flags;
+	u32 isr;
+
+	spin_lock_irqsave(&host->lock, flags);
+	isr = host->thread_isr;
+	host->thread_isr = 0;
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	if (isr & (SDHCI_INT_CARD_INSERT | SDHCI_INT_CARD_REMOVE)) {
+		sdhci_card_event(host->mmc);
+		mmc_detect_change(host->mmc, msecs_to_jiffies(200));
+	}
+
+#if 0	/* Unsupported */
+	if (isr & SDHCI_INT_CARD_INT) {
+		sdio_run_irqs(host->mmc);
+
+		spin_lock_irqsave(&host->lock, flags);
+		if (host->flags & SDHCI_SDIO_IRQ_ENABLED)
+			sdhci_enable_sdio_irq_nolock(host, true);
+		spin_unlock_irqrestore(&host->lock, flags);
+	}
+#endif
+
+	return isr ? IRQ_HANDLED : IRQ_NONE;
+}
+
+/*****************************************************************************\
+ *                                                                           *
+ * Suspend/resume                                                            *
+ *                                                                           *
+\*****************************************************************************/
+
+#ifdef CONFIG_PM
+void sdhci_enable_irq_wakeups(struct sdhci_host *host)
+{
+#if 0
+	u8 val;
+	u8 mask = SDHCI_WAKE_ON_INSERT | SDHCI_WAKE_ON_REMOVE
+			| SDHCI_WAKE_ON_INT;
+
+	val = sdhci_readb(host, SDHCI_WAKE_UP_CONTROL);
+	val |= mask ;
+	/* Avoid fake wake up */
+	if (host->quirks & SDHCI_QUIRK_BROKEN_CARD_DETECTION)
+		val &= ~(SDHCI_WAKE_ON_INSERT | SDHCI_WAKE_ON_REMOVE);
+	sdhci_writeb(host, val, SDHCI_WAKE_UP_CONTROL);
+#else
+	pr_err("%s: Unsupport function %s()\n", mmc_hostname(host->mmc), __func__);
+#endif
+}
+EXPORT_SYMBOL_GPL(sdhci_enable_irq_wakeups);
+
+static void sdhci_disable_irq_wakeups(struct sdhci_host *host)
+{
+#if 0
+	u8 val;
+	u8 mask = SDHCI_WAKE_ON_INSERT | SDHCI_WAKE_ON_REMOVE
+			| SDHCI_WAKE_ON_INT;
+
+	val = sdhci_readb(host, SDHCI_WAKE_UP_CONTROL);
+	val &= ~mask;
+	sdhci_writeb(host, val, SDHCI_WAKE_UP_CONTROL);
+#else
+	pr_err("%s: Unsupport function %s()\n", mmc_hostname(host->mmc), __func__);
+#endif
+}
+
+int sdhci_suspend_host(struct sdhci_host *host)
+{
+	//printk("%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	sdhci_disable_card_detection(host);
+
+	/* Disable tuning since we are suspending */
+	if (host->flags & SDHCI_USING_RETUNING_TIMER) {
+		del_timer_sync(&host->tuning_timer);
+		host->flags &= ~SDHCI_NEEDS_RETUNING;
+	}
+
+	if (!device_may_wakeup(mmc_dev(host->mmc))) {
+		host->ier = 0;
+		sdhci_writel(host, 0, SDHCI_IEN_REG);
+//		sdhci_writel(host, 0, SDHCI_SIGNAL_ENABLE);
+		free_irq(host->irq, host);
+	} else {
+		sdhci_enable_irq_wakeups(host);
+		enable_irq_wake(host->irq);
+	}
+	return 0;
+}
+
+EXPORT_SYMBOL_GPL(sdhci_suspend_host);
+
+int sdhci_resume_host(struct sdhci_host *host)
+{
+	int ret = 0;
+
+	//printk("%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	if (host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {
+		sdhci_w3k_enable_dma(host);
+	}
+
+	if (!device_may_wakeup(mmc_dev(host->mmc))) {
+		ret = request_threaded_irq(host->irq, sdhci_irq,
+					   sdhci_thread_irq, IRQF_SHARED,
+					   mmc_hostname(host->mmc), host);
+		if (ret)
+			return ret;
+	} else {
+		sdhci_disable_irq_wakeups(host);
+		disable_irq_wake(host->irq);
+	}
+
+	if ((host->mmc->pm_flags & MMC_PM_KEEP_POWER) &&
+	    (host->quirks2 & SDHCI_QUIRK2_HOST_OFF_CARD_ON)) {
+		/* Card keeps power but host controller does not */
+		sdhci_init(host, 0);
+		host->pwr = 0;
+		host->clock = 0;
+		sdhci_do_set_ios(host, &host->mmc->ios);
+	} else {
+		sdhci_init(host, (host->mmc->pm_flags & MMC_PM_KEEP_POWER));
+		mb();
+	}
+
+	sdhci_enable_card_detection(host);
+
+	/* Set the re-tuning expiration flag */
+	if (host->flags & SDHCI_USING_RETUNING_TIMER)
+		host->flags |= SDHCI_NEEDS_RETUNING;
+
+	return ret;
+}
+
+EXPORT_SYMBOL_GPL(sdhci_resume_host);
+
+static int sdhci_runtime_pm_get(struct sdhci_host *host)
+{
+	return pm_runtime_get_sync(host->mmc->parent);
+}
+
+static int sdhci_runtime_pm_put(struct sdhci_host *host)
+{
+	pm_runtime_mark_last_busy(host->mmc->parent);
+	return pm_runtime_put_autosuspend(host->mmc->parent);
+}
+
+static void sdhci_runtime_pm_bus_on(struct sdhci_host *host)
+{
+	if (host->runtime_suspended || host->bus_on)
+		return;
+	host->bus_on = true;
+	pm_runtime_get_noresume(host->mmc->parent);
+}
+
+static void sdhci_runtime_pm_bus_off(struct sdhci_host *host)
+{
+	if (host->runtime_suspended || !host->bus_on)
+		return;
+	host->bus_on = false;
+	pm_runtime_put_noidle(host->mmc->parent);
+}
+
+int sdhci_runtime_suspend_host(struct sdhci_host *host)
+{
+	unsigned long flags;
+
+	//printk("%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	/* Disable tuning since we are suspending */
+	if (host->flags & SDHCI_USING_RETUNING_TIMER) {
+		del_timer_sync(&host->tuning_timer);
+		host->flags &= ~SDHCI_NEEDS_RETUNING;
+	}
+
+#if 0	/* Unsupported */
+	spin_lock_irqsave(&host->lock, flags);
+	host->ier &= SDHCI_INT_CARD_INT;
+	sdhci_writel(host, host->ier, SDHCI_INT_ENABLE);
+	sdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);
+	spin_unlock_irqrestore(&host->lock, flags);
+#endif
+
+	synchronize_irq(host->irq);
+
+	spin_lock_irqsave(&host->lock, flags);
+	host->runtime_suspended = true;
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(sdhci_runtime_suspend_host);
+
+int sdhci_runtime_resume_host(struct sdhci_host *host)
+{
+	unsigned long flags;
+	int host_flags = host->flags;
+
+	//printk("%s : %s()\n", mmc_hostname(host->mmc), __func__);
+
+	if (host_flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {
+		sdhci_w3k_enable_dma(host);
+	}
+
+	sdhci_init(host, 0);
+
+	/* Force clock and power re-program */
+	host->pwr = 0;
+	host->clock = 0;
+	sdhci_do_start_signal_voltage_switch(host, &host->mmc->ios);
+	sdhci_do_set_ios(host, &host->mmc->ios);
+
+	if ((host_flags & SDHCI_PV_ENABLED) &&
+		!(host->quirks2 & SDHCI_QUIRK2_PRESET_VALUE_BROKEN)) {
+		spin_lock_irqsave(&host->lock, flags);
+		sdhci_enable_preset_value(host, true);
+		spin_unlock_irqrestore(&host->lock, flags);
+	}
+
+	/* Set the re-tuning expiration flag */
+	if (host->flags & SDHCI_USING_RETUNING_TIMER)
+		host->flags |= SDHCI_NEEDS_RETUNING;
+
+	spin_lock_irqsave(&host->lock, flags);
+
+	host->runtime_suspended = false;
+
+	/* Enable SDIO IRQ */
+	if (host->flags & SDHCI_SDIO_IRQ_ENABLED)
+		sdhci_enable_sdio_irq_nolock(host, true);
+
+	/* Enable Card Detection */
+	sdhci_enable_card_detection(host);
+
+	spin_unlock_irqrestore(&host->lock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(sdhci_runtime_resume_host);
+
+#endif /* CONFIG_PM */
+
+/*****************************************************************************\
+ *                                                                           *
+ * Device allocation/registration                                            *
+ *                                                                           *
+\*****************************************************************************/
+
+struct sdhci_host *sdhci_alloc_host(struct device *dev,
+	size_t priv_size)
+{
+	struct mmc_host *mmc;
+	struct sdhci_host *host;
+
+	WARN_ON(dev == NULL);
+
+	mmc = mmc_alloc_host(sizeof(struct sdhci_host) + priv_size, dev);
+	if (!mmc)
+		return ERR_PTR(-ENOMEM);
+
+	host = mmc_priv(mmc);
+	host->mmc = mmc;
+
+	return host;
+}
+
+EXPORT_SYMBOL_GPL(sdhci_alloc_host);
+
+int sdhci_add_host(struct sdhci_host *host)
+{
+	struct mmc_host *mmc;
+	u32 caps[2] = {0, 0};
+//	u32 max_current_caps;
+	unsigned int ocr_avail;
+	unsigned int override_timeout_clk;
+	int ret;
+	
+	////printk(KERN_INFO "host caps %x\n", host->caps);
+	WARN_ON(host == NULL);
+	if (host == NULL)
+		return -EINVAL;
+
+	host->card_detect = false;
+
+	mmc = host->mmc;
+
+	if (debug_quirks)
+		host->quirks = debug_quirks;
+	if (debug_quirks2)
+		host->quirks2 = debug_quirks2;
+
+	override_timeout_clk = host->timeout_clk;
+
+	sdhci_do_reset(host, SDHCI_RESET_ALL);
+
+//	host->version = sdhci_readw(host, SDHCI_HOST_VERSION);
+//	host->version = (host->version & SDHCI_SPEC_VER_MASK)
+//				>> SDHCI_SPEC_VER_SHIFT;
+	host->version = SDHCI_SPEC_200;
+	if (host->version > SDHCI_SPEC_300) {
+		pr_err("%s: Unknown controller version (%d). "
+			"You may experience problems.\n", mmc_hostname(mmc),
+			host->version);
+	}
+
+//	caps[0] = (host->quirks & SDHCI_QUIRK_MISSING_CAPS) ? host->caps :
+//		sdhci_readl(host, SDHCI_CAPABILITIES);
+
+//	if (host->version >= SDHCI_SPEC_300)
+//		caps[1] = (host->quirks & SDHCI_QUIRK_MISSING_CAPS) ?
+//			host->caps1 :
+//			sdhci_readl(host, SDHCI_CAPABILITIES_1);
+#ifdef USE_ADMA
+    host->caps = SDHCI_CAN_VDD_330 | SDHCI_CAN_VDD_300 | SDHCI_CAN_DO_HISPD | SDHCI_CAN_DO_SDMA | SDHCI_CAN_DO_ADMA2;
+#else
+	host->caps = SDHCI_CAN_VDD_330 | SDHCI_CAN_VDD_300 | SDHCI_CAN_DO_HISPD | SDHCI_CAN_DO_SDMA;
+#endif
+	host->quirks |= SDHCI_QUIRK_BROKEN_CARD_DETECTION;
+	//host->quirks2 |= SDHCI_QUIRK2_HOST_NO_CMD23;
+
+
+	caps[0] = host->caps;
+	caps[1] = host->caps1;
+
+	if (host->quirks & SDHCI_QUIRK_FORCE_DMA)
+		host->flags |= SDHCI_USE_SDMA;
+	else if (!(caps[0] & SDHCI_CAN_DO_SDMA))
+		DBG("Controller doesn't have SDMA capability\n");
+	else
+		host->flags |= SDHCI_USE_SDMA;
+
+	if ((host->quirks & SDHCI_QUIRK_BROKEN_DMA) &&
+		(host->flags & SDHCI_USE_SDMA)) {
+		DBG("Disabling DMA as it is marked broken\n");
+		host->flags &= ~SDHCI_USE_SDMA;
+	}
+#ifdef USE_ADMA
+	if ((host->version >= SDHCI_SPEC_200) &&
+		(caps[0]))
+		host->flags |= SDHCI_USE_ADMA;
+#endif
+	if ((host->quirks & SDHCI_QUIRK_BROKEN_ADMA) &&
+		(host->flags & SDHCI_USE_ADMA)) {
+		DBG("Disabling ADMA as it is marked broken\n");
+		host->flags &= ~SDHCI_USE_ADMA;
+	}
+
+	/*
+	 * It is assumed that a 64-bit capable device has set a 64-bit DMA mask
+	 * and *must* do 64-bit DMA.  A driver has the opportunity to change
+	 * that during the first call to ->enable_dma().  Similarly
+	 * SDHCI_QUIRK2_BROKEN_64_BIT_DMA must be left to the drivers to
+	 * implement.
+	 */
+//	if (sdhci_readl(host, SDHCI_CAPABILITIES) & SDHCI_CAN_64BIT)
+//		host->flags |= SDHCI_USE_64_BIT_DMA;
+
+	if (host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {
+		if (sdhci_w3k_enable_dma(host)) {
+			pr_warn("%s: No suitable DMA available - falling back to PIO\n",
+				mmc_hostname(mmc));
+			host->flags &=
+				~(SDHCI_USE_SDMA | SDHCI_USE_ADMA);
+		}
+	}
+
+	/* SDMA does not support 64-bit DMA */
+	if (host->flags & SDHCI_USE_64_BIT_DMA)
+		host->flags &= ~SDHCI_USE_SDMA;
+
+	if (host->flags & SDHCI_USE_ADMA) {
+		/*
+		 * The DMA descriptor table size is calculated as the maximum
+		 * number of segments times 2, to allow for an alignment
+		 * descriptor for each segment, plus 1 for a nop end descriptor,
+		 * all multipled by the descriptor size.
+		 */
+		if (host->flags & SDHCI_USE_64_BIT_DMA) {
+			host->adma_table_sz = (SDHCI_MAX_SEGS * 2 + 1) *
+					      SDHCI_ADMA2_64_DESC_SZ;
+			host->align_buffer_sz = SDHCI_MAX_SEGS *
+						SDHCI_ADMA2_64_ALIGN;
+			host->desc_sz = SDHCI_ADMA2_64_DESC_SZ;
+			host->align_sz = SDHCI_ADMA2_64_ALIGN;
+			host->align_mask = SDHCI_ADMA2_64_ALIGN - 1;
+		} else {
+			host->adma_table_sz = (SDHCI_MAX_SEGS * 2 + 1) *
+					      SDHCI_ADMA2_32_DESC_SZ;
+			host->align_buffer_sz = SDHCI_MAX_SEGS *
+						SDHCI_ADMA2_32_ALIGN;
+			host->desc_sz = SDHCI_ADMA2_32_DESC_SZ;
+			host->align_sz = SDHCI_ADMA2_32_ALIGN;
+			host->align_mask = SDHCI_ADMA2_32_ALIGN - 1;
+		}
+		host->adma_table = dma_alloc_coherent(mmc_dev(mmc),
+						      host->adma_table_sz,
+						      &host->adma_addr,
+						      GFP_KERNEL);
+		host->align_buffer = kmalloc(host->align_buffer_sz, GFP_KERNEL);
+		if (!host->adma_table || !host->align_buffer) {
+			dma_free_coherent(mmc_dev(mmc), host->adma_table_sz,
+					  host->adma_table, host->adma_addr);
+			kfree(host->align_buffer);
+			pr_warn("%s: Unable to allocate ADMA buffers - falling back to standard DMA\n",
+				mmc_hostname(mmc));
+			host->flags &= ~SDHCI_USE_ADMA;
+			host->adma_table = NULL;
+			host->align_buffer = NULL;
+		} else if (host->adma_addr & host->align_mask) {
+			pr_warn("%s: unable to allocate aligned ADMA descriptor\n",
+				mmc_hostname(mmc));
+			host->flags &= ~SDHCI_USE_ADMA;
+			dma_free_coherent(mmc_dev(mmc), host->adma_table_sz,
+					  host->adma_table, host->adma_addr);
+			kfree(host->align_buffer);
+			host->adma_table = NULL;
+			host->align_buffer = NULL;
+		}
+	}
+
+	/*
+	 * If we use DMA, then it's up to the caller to set the DMA
+	 * mask, but PIO does not need the hw shim so we set a new
+	 * mask here in that case.
+	 */
+	if (!(host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA))) {
+		host->dma_mask = DMA_BIT_MASK(64);
+		mmc_dev(mmc)->dma_mask = &host->dma_mask;
+	}
+
+	if (host->version >= SDHCI_SPEC_300)
+		host->max_clk = (caps[0] & SDHCI_CLOCK_V3_BASE_MASK)
+			>> SDHCI_CLOCK_BASE_SHIFT;
+	else
+		host->max_clk = (caps[0] & SDHCI_CLOCK_BASE_MASK)
+			>> SDHCI_CLOCK_BASE_SHIFT;
+
+	host->max_clk *= 1000000;
+	if (host->max_clk == 0 || host->quirks &
+			SDHCI_QUIRK_CAP_CLOCK_BASE_BROKEN) {
+		host->max_clk = sdhci_w3k_get_max_clock(host);
+	}
+
+	host->next_data.cookie = 1;
+	/*
+	 * In case of Host Controller v3.00, find out whether clock
+	 * multiplier is supported.
+	 */
+	host->clk_mul = (caps[1] & SDHCI_CLOCK_MUL_MASK) >>
+			SDHCI_CLOCK_MUL_SHIFT;
+
+	/*
+	 * In case the value in Clock Multiplier is 0, then programmable
+	 * clock mode is not supported, otherwise the actual clock
+	 * multiplier is one more than the value of Clock Multiplier
+	 * in the Capabilities Register.
+	 */
+	if (host->clk_mul)
+		host->clk_mul += 1;
+
+	/*
+	 * Set host parameters.
+	 */
+	mmc->ops = &sdhci_ops;
+	mmc->f_max = host->max_clk;
+	if (0)
+		mmc->f_min = sdhci_w3k_get_min_clock(host);
+	else if (host->version >= SDHCI_SPEC_300) {
+		if (host->clk_mul) {
+			mmc->f_min = (host->max_clk * host->clk_mul) / 1024;
+			mmc->f_max = host->max_clk * host->clk_mul;
+		} else
+			mmc->f_min = host->max_clk / SDHCI_MAX_DIV_SPEC_300;
+	} else
+		mmc->f_min = host->max_clk / SDHCI_MAX_DIV_SPEC_200;
+
+	if (!(host->quirks & SDHCI_QUIRK_DATA_TIMEOUT_USES_SDCLK)) {
+		host->timeout_clk = (caps[0] & SDHCI_TIMEOUT_CLK_MASK) >>
+					SDHCI_TIMEOUT_CLK_SHIFT;
+		if (host->timeout_clk == 0) {
+			if (1) {
+				host->timeout_clk =
+					sdhci_w3k_get_timeout_clock(host);
+			} else {
+				pr_err("%s: Hardware doesn't specify timeout clock frequency.\n",
+					mmc_hostname(mmc));
+				return -ENODEV;
+			}
+		}
+
+		if (caps[0] & SDHCI_TIMEOUT_CLK_UNIT)
+			host->timeout_clk *= 1000;
+
+		mmc->max_busy_timeout =
+			sdhci_w3k_get_max_timeout_count(host);
+		mmc->max_busy_timeout /= host->timeout_clk;
+	}
+
+	if (override_timeout_clk)
+		host->timeout_clk = override_timeout_clk;
+
+	mmc->caps |= MMC_CAP_SDIO_IRQ | MMC_CAP_CMD23;
+//	mmc->caps2 |= MMC_CAP2_SDIO_IRQ_NOTHREAD;
+
+	if (host->quirks & SDHCI_QUIRK_MULTIBLOCK_READ_ACMD12)
+		host->flags |= SDHCI_AUTO_CMD12;
+
+	/* Auto-CMD23 stuff only works in ADMA or PIO. */
+	if ((host->version >= SDHCI_SPEC_300) &&
+	    ((host->flags & SDHCI_USE_ADMA) ||
+	     !(host->flags & SDHCI_USE_SDMA)) &&
+	     !(host->quirks2 & SDHCI_QUIRK2_ACMD23_BROKEN)) {
+		host->flags |= SDHCI_AUTO_CMD23;
+		printk(KERN_INFO "%s: Auto-CMD23 available\n", mmc_hostname(mmc));
+	} else {
+		printk(KERN_INFO "%s: Auto-CMD23 unavailable\n", mmc_hostname(mmc));
+	}
+
+	/*
+	 * A controller may support 8-bit width, but the board itself
+	 * might not have the pins brought out.  Boards that support
+	 * 8-bit width must set "mmc->caps |= MMC_CAP_8_BIT_DATA;" in
+	 * their platform code before calling sdhci_add_host(), and we
+	 * won't assume 8-bit width for hosts without that CAP.
+	 */
+	if (!(host->quirks & SDHCI_QUIRK_FORCE_1_BIT_DATA))
+		mmc->caps |= MMC_CAP_4_BIT_DATA;
+
+	if (host->quirks2 & SDHCI_QUIRK2_HOST_NO_CMD23)
+		mmc->caps &= ~MMC_CAP_CMD23;
+
+	if (caps[0] & SDHCI_CAN_DO_HISPD)
+		mmc->caps |= MMC_CAP_SD_HIGHSPEED | MMC_CAP_MMC_HIGHSPEED;
+
+	if ((host->quirks & SDHCI_QUIRK_BROKEN_CARD_DETECTION) &&
+	    !(mmc->caps & MMC_CAP_NONREMOVABLE))
+		mmc->caps |= MMC_CAP_NEEDS_POLL;
+
+	/* If there are external regulators, get them */
+	if (mmc_regulator_get_supply(mmc) == -EPROBE_DEFER)
+		return -EPROBE_DEFER;
+
+	/* If vmmc regulator and no 1.8V signalling, then there's no UHS */
+	if (!IS_ERR(mmc->supply.vmmc)) {
+		ret = regulator_enable(mmc->supply.vmmc);
+		if (!regulator_is_supported_voltage(mmc->supply.vmmc, 1700000,
+						    1950000))
+			caps[1] &= ~(SDHCI_SUPPORT_SDR104 |
+					SDHCI_SUPPORT_SDR50 |
+					SDHCI_SUPPORT_DDR50);
+		if (ret) {
+			pr_warn("%s: Failed to enable vmmc regulator: %d\n",
+				mmc_hostname(mmc), ret);
+			mmc->supply.vmmc = ERR_PTR(-EINVAL);
+		}
+	}
+
+	if (host->quirks2 & SDHCI_QUIRK2_NO_1_8_V)
+		caps[1] &= ~(SDHCI_SUPPORT_SDR104 | SDHCI_SUPPORT_SDR50 |
+		       SDHCI_SUPPORT_DDR50);
+
+	/* Any UHS-I mode in caps implies SDR12 and SDR25 support. */
+	if (caps[1] & (SDHCI_SUPPORT_SDR104 | SDHCI_SUPPORT_SDR50 |
+		       SDHCI_SUPPORT_DDR50))
+		mmc->caps |= MMC_CAP_UHS_SDR12 | MMC_CAP_UHS_SDR25;
+
+	/* SDR104 supports also implies SDR50 support */
+	if (caps[1] & SDHCI_SUPPORT_SDR104) {
+		mmc->caps |= MMC_CAP_UHS_SDR104 | MMC_CAP_UHS_SDR50;
+		/* SD3.0: SDR104 is supported so (for eMMC) the caps2
+		 * field can be promoted to support HS200.
+		 */
+		if (!(host->quirks2 & SDHCI_QUIRK2_BROKEN_HS200))
+			mmc->caps2 |= MMC_CAP2_HS200;
+	} else if (caps[1] & SDHCI_SUPPORT_SDR50)
+		mmc->caps |= MMC_CAP_UHS_SDR50;
+
+	if (host->quirks2 & SDHCI_QUIRK2_CAPS_BIT63_FOR_HS400 &&
+	    (caps[1] & SDHCI_SUPPORT_HS400))
+		mmc->caps2 |= MMC_CAP2_HS400;
+
+	if ((mmc->caps2 & MMC_CAP2_HSX00_1_2V) &&
+	    (IS_ERR(mmc->supply.vmmc) ||
+	     !regulator_is_supported_voltage(mmc->supply.vmmc, 1100000,
+					     1300000)))
+		mmc->caps2 &= ~MMC_CAP2_HSX00_1_2V;
+
+	if ((caps[1] & SDHCI_SUPPORT_DDR50) &&
+		!(host->quirks2 & SDHCI_QUIRK2_BROKEN_DDR50))
+		mmc->caps |= MMC_CAP_UHS_DDR50;
+
+	/* Does the host need tuning for SDR50? */
+	if (caps[1] & SDHCI_USE_SDR50_TUNING)
+		host->flags |= SDHCI_SDR50_NEEDS_TUNING;
+
+	/* Does the host need tuning for SDR104 / HS200? */
+	if (mmc->caps2 & MMC_CAP2_HS200)
+		host->flags |= SDHCI_SDR104_NEEDS_TUNING;
+
+	/* Driver Type(s) (A, C, D) supported by the host */
+	if (caps[1] & SDHCI_DRIVER_TYPE_A)
+		mmc->caps |= MMC_CAP_DRIVER_TYPE_A;
+	if (caps[1] & SDHCI_DRIVER_TYPE_C)
+		mmc->caps |= MMC_CAP_DRIVER_TYPE_C;
+	if (caps[1] & SDHCI_DRIVER_TYPE_D)
+		mmc->caps |= MMC_CAP_DRIVER_TYPE_D;
+
+	/* Initial value for re-tuning timer count */
+	host->tuning_count = (caps[1] & SDHCI_RETUNING_TIMER_COUNT_MASK) >>
+			      SDHCI_RETUNING_TIMER_COUNT_SHIFT;
+
+	/*
+	 * In case Re-tuning Timer is not disabled, the actual value of
+	 * re-tuning timer will be 2 ^ (n - 1).
+	 */
+	if (host->tuning_count)
+		host->tuning_count = 1 << (host->tuning_count - 1);
+
+	/* Re-tuning mode supported by the Host Controller */
+	host->tuning_mode = (caps[1] & SDHCI_RETUNING_MODE_MASK) >>
+			     SDHCI_RETUNING_MODE_SHIFT;
+
+	ocr_avail = 0;
+
+#if 0
+	/*
+	 * According to SD Host Controller spec v3.00, if the Host System
+	 * can afford more than 150mA, Host Driver should set XPC to 1. Also
+	 * the value is meaningful only if Voltage Support in the Capabilities
+	 * register is set. The actual current value is 4 times the register
+	 * value.
+	 */
+	max_current_caps = sdhci_readl(host, SDHCI_MAX_CURRENT);
+	if (!max_current_caps && !IS_ERR(mmc->supply.vmmc)) {
+		int curr = regulator_get_current_limit(mmc->supply.vmmc);
+		if (curr > 0) {
+
+			/* convert to SDHCI_MAX_CURRENT format */
+			curr = curr/1000;  /* convert to mA */
+			curr = curr/SDHCI_MAX_CURRENT_MULTIPLIER;
+
+			curr = min_t(u32, curr, SDHCI_MAX_CURRENT_LIMIT);
+			max_current_caps =
+				(curr << SDHCI_MAX_CURRENT_330_SHIFT) |
+				(curr << SDHCI_MAX_CURRENT_300_SHIFT) |
+				(curr << SDHCI_MAX_CURRENT_180_SHIFT);
+		}
+	}
+#endif
+
+	if (caps[0] & SDHCI_CAN_VDD_330) {
+		ocr_avail |= MMC_VDD_32_33 | MMC_VDD_33_34;
+
+		mmc->max_current_330 = ((/*max_current_caps &*/
+				   SDHCI_MAX_CURRENT_330_MASK) >>
+				   SDHCI_MAX_CURRENT_330_SHIFT) *
+				   SDHCI_MAX_CURRENT_MULTIPLIER;
+	}
+	if (caps[0] & SDHCI_CAN_VDD_300) {
+		ocr_avail |= MMC_VDD_29_30 | MMC_VDD_30_31;
+
+		mmc->max_current_300 = ((/*max_current_caps &*/
+				   SDHCI_MAX_CURRENT_300_MASK) >>
+				   SDHCI_MAX_CURRENT_300_SHIFT) *
+				   SDHCI_MAX_CURRENT_MULTIPLIER;
+	}
+	if (caps[0] & SDHCI_CAN_VDD_180) {
+		ocr_avail |= MMC_VDD_165_195;
+
+		mmc->max_current_180 = ((/*max_current_caps &*/
+				   SDHCI_MAX_CURRENT_180_MASK) >>
+				   SDHCI_MAX_CURRENT_180_SHIFT) *
+				   SDHCI_MAX_CURRENT_MULTIPLIER;
+	}
+
+	/* If OCR set by external regulators, use it instead */
+//	if (mmc->ocr_avail)
+//		ocr_avail = mmc->ocr_avail;
+
+	if (host->ocr_mask)
+//		ocr_avail &= host->ocr_mask;
+		ocr_avail = host->ocr_mask;
+
+	mmc->ocr_avail = ocr_avail;
+	mmc->ocr_avail_sdio = ocr_avail;
+	if (host->ocr_avail_sdio)
+		mmc->ocr_avail_sdio &= host->ocr_avail_sdio;
+	mmc->ocr_avail_sd = ocr_avail;
+	if (host->ocr_avail_sd)
+		mmc->ocr_avail_sd &= host->ocr_avail_sd;
+//	else /* normal SD controllers don't support 1.8V */
+//		mmc->ocr_avail_sd &= ~MMC_VDD_165_195;
+	mmc->ocr_avail_mmc = ocr_avail;
+	if (host->ocr_avail_mmc)
+		mmc->ocr_avail_mmc &= host->ocr_avail_mmc;
+
+	if (mmc->ocr_avail == 0) {
+		pr_err("%s: Hardware doesn't report any "
+			"support voltages.\n", mmc_hostname(mmc));
+		return -ENODEV;
+	}
+
+	spin_lock_init(&host->lock);
+
+	/*
+	 * Maximum number of segments. Depends on if the hardware
+	 * can do scatter/gather or not.
+	 */
+	if (host->flags & SDHCI_USE_ADMA)
+		mmc->max_segs = SDHCI_MAX_SEGS;
+	else if (host->flags & SDHCI_USE_SDMA)
+		mmc->max_segs = 1;
+	else /* PIO */
+		mmc->max_segs = SDHCI_MAX_SEGS;
+
+	/*
+	 * Maximum number of sectors in one transfer. Limited by SDMA boundary
+	 * size (512KiB). Note some tuning modes impose a 4MiB limit, but this
+	 * is less anyway.
+	 */
+	mmc->max_req_size = 524288;
+
+	/*
+	 * Maximum segment size. Could be one segment with the maximum number
+	 * of bytes. When doing hardware scatter/gather, each entry cannot
+	 * be larger than 64 KiB though.
+	 */
+	if (host->flags & SDHCI_USE_ADMA) {
+		if (host->quirks & SDHCI_QUIRK_BROKEN_ADMA_ZEROLEN_DESC)
+			mmc->max_seg_size = 65535;
+		else
+			mmc->max_seg_size = 65536;
+	} else {
+		mmc->max_seg_size = mmc->max_req_size;
+	}
+
+	/*
+	 * Maximum block size. This varies from controller to controller and
+	 * is specified in the capabilities register.
+	 */
+	if (host->quirks & SDHCI_QUIRK_FORCE_BLK_SZ_2048) {
+		mmc->max_blk_size = 2;
+	} else {
+		mmc->max_blk_size = (caps[0] & SDHCI_MAX_BLOCK_MASK) >>
+				SDHCI_MAX_BLOCK_SHIFT;
+		if (mmc->max_blk_size >= 3) {
+			pr_warn("%s: Invalid maximum block size, assuming 512 bytes\n",
+				mmc_hostname(mmc));
+			mmc->max_blk_size = 0;
+		}
+	}
+
+	mmc->max_blk_size = 512 << mmc->max_blk_size;
+
+	/*
+	 * Maximum block count.
+	 */
+	mmc->max_blk_count = (host->quirks & SDHCI_QUIRK_NO_MULTIBLOCK) ? 1 : (SRAM_SIZE/mmc->max_blk_size);
+
+	/*
+	 * Init tasklets.
+	 */
+	tasklet_init(&host->finish_tasklet,
+		sdhci_tasklet_finish, (unsigned long)host);
+
+	timer_setup(&host->timer, sdhci_timeout_timer, 0);
+
+	init_waitqueue_head(&host->buf_ready_int);
+
+	if (host->version >= SDHCI_SPEC_300) {
+		/* Initialize re-tuning timer */
+		//init_timer(&host->tuning_timer);
+		//host->tuning_timer.data = (unsigned long)host;
+		host->tuning_timer.function = sdhci_tuning_timer;
+	}
+
+	sdhci_init(host, 0);
+
+	ret = request_threaded_irq(host->irq, sdhci_irq, sdhci_thread_irq,
+				   IRQF_SHARED,	mmc_hostname(mmc), host);
+	if (ret) {
+		printk(KERN_INFO  "%s: Failed to request IRQ %d: %d\n",
+		       mmc_hostname(mmc), host->irq, ret);
+		goto untasklet;
+	}
+
+#ifdef CONFIG_MMC_DEBUG
+	sdhci_dumpregs(host);
+#endif
+
+	mb();
+
+//	sdhci_enable_card_detection(host);
+
+	mmc_add_host(mmc);
+
+	pr_info("%s: SDHCI controller on %s [%s] using %s\n",
+		mmc_hostname(mmc), host->hw_name, dev_name(mmc_dev(mmc)),
+		(host->flags & SDHCI_USE_ADMA) ?
+		(host->flags & SDHCI_USE_64_BIT_DMA) ? "ADMA 64-bit" : "ADMA" :
+		(host->flags & SDHCI_USE_SDMA) ? "DMA" : "PIO");
+
+	sdhci_enable_card_detection(host);
+
+	if (host->slot_id == SLOT_SDIO_WIFI) {
+		printk("sdio host init ...done .....\n");
+		wifi_sdio_host = host;
+
+		// keep power while host suspend.
+		host->mmc->pm_caps |= MMC_PM_KEEP_POWER;
+		//assume . wifi card not removable.
+		host->mmc->caps |= MMC_CAP_NONREMOVABLE;
+		//assume . wifi will wake up host
+//		host->mmc->pm_flags |= MMC_PM_WAKE_SDIO_IRQ;
+		host->mmc->caps &= ~MMC_CAP_NEEDS_POLL; 
+	}
+#ifdef RTL_SDIO_GPIO_TEST
+	if (host->slot_id == SLOT_SDIO_WIFI)
+		sdio_irq_gpio_set(SDIO_INTERRUPT_GPIO, host);
+#endif
+	//printk(KERN_INFO "add_host done\n");
+
+	return 0;
+
+untasklet:
+	tasklet_kill(&host->finish_tasklet);
+
+	return ret;
+}
+
+EXPORT_SYMBOL_GPL(sdhci_add_host);
+
+void sdhci_remove_host(struct sdhci_host *host, int dead)
+{
+	struct mmc_host *mmc = host->mmc;
+	unsigned long flags;
+
+	if (dead) {
+		spin_lock_irqsave(&host->lock, flags);
+
+		host->flags |= SDHCI_DEVICE_DEAD;
+
+		if (host->mrq) {
+			pr_err("%s: Controller removed during "
+				" transfer!\n", mmc_hostname(mmc));
+
+			host->mrq->cmd->error = -ENOMEDIUM;
+			tasklet_schedule(&host->finish_tasklet);
+		}
+
+		spin_unlock_irqrestore(&host->lock, flags);
+	}
+
+	sdhci_disable_card_detection(host);
+
+	mmc_remove_host(mmc);
+
+	if (!dead)
+		sdhci_do_reset(host, SDHCI_RESET_ALL);
+
+	sdhci_writel(host, 0, SDHCI_IEN_REG);
+//	sdhci_writel(host, 0, SDHCI_SIGNAL_ENABLE);
+	free_irq(host->irq, host);
+
+	del_timer_sync(&host->timer);
+
+	tasklet_kill(&host->finish_tasklet);
+
+	if (!IS_ERR(mmc->supply.vmmc))
+		regulator_disable(mmc->supply.vmmc);
+
+	if (host->adma_table)
+		dma_free_coherent(mmc_dev(mmc), host->adma_table_sz,
+				  host->adma_table, host->adma_addr);
+	kfree(host->align_buffer);
+
+	host->adma_table = NULL;
+	host->align_buffer = NULL;
+}
+
+EXPORT_SYMBOL_GPL(sdhci_remove_host);
+
+void sdhci_free_host(struct sdhci_host *host)
+{
+	mmc_free_host(host->mmc);
+}
+
+EXPORT_SYMBOL_GPL(sdhci_free_host);
+
+/******************************************************************************/
+
+#ifdef CONFIG_OF
+static int sdhci_w3k_parse_dt(struct device *dev,
+		struct sdhci_host *host, struct w3k_sdhci_platdata *pdata)
+{
+	struct device_node *node = dev->of_node;
+	u32 max_width;
+	//printk(KERN_INFO "parse dt\n");
+	/* if the bus-width property is not specified, assume width as 1 */
+	pdata->host_caps |= SDHCI_CAN_VDD_330;
+
+	if (of_property_read_u32(node, "bus-width", &max_width))
+		max_width = 1;
+	pdata->max_width = max_width;
+
+	/* get the card detection method */
+	if (of_get_property(node, "broken-cd", NULL)) {
+		pdata->cd_type = W3K_SDHCI_CD_NONE;
+		return 0;
+	}
+
+	if (of_get_property(node, "non-removable", NULL)) {
+		pdata->cd_type = W3K_SDHCI_CD_PERMANENT;
+		return 0;
+	}
+
+	if (of_get_named_gpio(node, "cd-gpios", 0))
+		return 0;
+
+	/* assuming internal card detect that will be configured by pinctrl */
+	pdata->cd_type = W3K_SDHCI_CD_INTERNAL;
+
+	pdata->host_caps |= SDHCI_CAN_VDD_330;
+	//printk(KERN_INFO "parse caps %x\n", pdata->host_caps);
+	return 0;
+}
+#else
+static int sdhci_w3k_parse_dt(struct device *dev,
+		struct sdhci_host *host, struct w3k_sdhci_platdata *pdata)
+{
+	return -EINVAL;
+}
+#endif
+
+static const struct of_device_id sdhci_w3k_dt_match[];
+
+#if 0
+static inline struct sdhci_w3k_drv_data *sdhci_im98xx_get_driver_data(
+			struct platform_device *pdev)
+{
+#ifdef CONFIG_OF
+	if (pdev->dev.of_node) {
+		const struct of_device_id *match;
+		match = of_match_node(sdhci_w3k_dt_match, pdev->dev.of_node);
+		return (struct sdhci_w3k_drv_data *)match->data;
+	}
+#endif
+	return (struct sdhci_w3k_drv_data *)
+			platform_get_device_id(pdev)->driver_data;
+}
+#endif
+
+static int sdhci_w3k_probe(struct platform_device *pdev)
+{
+	struct w3k_sdhci_platdata *pdata;
+//	struct sdhci_w3k_drv_data *drv_data;
+	struct device *dev = &pdev->dev;
+	struct sdhci_host *host;
+//	struct sdhci_w3k *sc;
+	struct resource *res;
+	int ret, irq/*, ptr, clks*/;
+	//void __iomem *base=NULL;
+#ifdef USE_SRAM
+	void __iomem *sram_addr = NULL;
+#endif
+	//base = ioremap(0xF2208a00, 0x100);
+	//if (base) {
+	//	writel( 0x4 , base+0x24);	
+	//	writel( 0x4 , base+0x0C);	
+	//	iounmap(base);
+	//}
+	
+	//printk(KERN_INFO "w3k_sdhci_probe\n");
+	if (!pdev->dev.platform_data && !pdev->dev.of_node) {
+		dev_err(dev, "no device data specified\n");
+		return -ENOENT;
+	}
+
+	irq = platform_get_irq(pdev, 0);
+	if (irq < 0) {
+		dev_err(dev, "no irq specified\n");
+		return irq;
+	}
+
+	host = sdhci_alloc_host(dev, sizeof(struct sdhci_host));
+	if (IS_ERR(host)) {
+		dev_err(dev, "sdhci_alloc_host() failed\n");
+		return PTR_ERR(host);
+	}
+//	sc = sdhci_priv(host);
+
+	pdata = devm_kzalloc(&pdev->dev, sizeof(*pdata), GFP_KERNEL);
+	if (!pdata) {
+		ret = -ENOMEM;
+		goto err_pdata_io_clk;
+	}
+
+	if (pdev->dev.of_node) {
+		ret = sdhci_w3k_parse_dt(&pdev->dev, host, pdata);
+		if (ret)
+			goto err_pdata_io_clk;
+	} else {
+		memcpy(pdata, pdev->dev.platform_data, sizeof(*pdata));
+//		sc->ext_cd_gpio = -1; /* invalid gpio number */
+	}
+
+//	drv_data = sdhci_w3k_get_driver_data(pdev);
+
+//	sc->host = host;
+//	sc->pdev = pdev;
+//	sc->pdata = pdata;
+//	sc->cur_clk = -1;
+
+	platform_set_drvdata(pdev, host);
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	host->ioaddr = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(host->ioaddr)) {
+		ret = PTR_ERR(host->ioaddr);
+		goto err_req_regs;
+	}
+
+	/* Ensure we have minimal gpio selected CMD/CLK/Detect */
+	if (pdata->cfg_gpio)
+		pdata->cfg_gpio(pdev, pdata->max_width);
+
+	host->hw_name = "siliconwaves-sdhci";
+//	host->ops = &sdhci_w3k_ops;
+	host->quirks = 0;
+	host->quirks2 = 0;
+	host->irq = irq;
+	host->slot_id = pdev->id;
+
+	/* Setup quirks for the controller */
+//	host->quirks |= SDHCI_QUIRK_NO_ENDATTR_IN_NOPDESC;
+//	host->quirks |= SDHCI_QUIRK_NO_HISPD_BIT;
+//	if (drv_data) {
+//		host->quirks |= drv_data->sdhci_quirks;
+//		sc->no_divider = drv_data->no_divider;
+//	}
+
+#ifdef USE_ADMA
+	host->quirks |= SDHCI_QUIRK_BROKEN_DMA;
+#else
+	host->quirks |= SDHCI_QUIRK_FORCE_DMA;
+#endif
+
+	/* It seems we do not get an DATA transfer complete on non-busy
+	 * transfers, not sure if this is a problem with this specific
+	 * SDHCI block, or a missing configuration that needs to be set. */
+	host->quirks |= SDHCI_QUIRK_NO_BUSY_IRQ;
+
+	/* This host supports the Auto CMD12 */
+//	host->quirks |= SDHCI_QUIRK_MULTIBLOCK_READ_ACMD12;
+
+	/* Samsung SoCs need BROKEN_ADMA_ZEROLEN_DESC */
+//	host->quirks |= SDHCI_QUIRK_BROKEN_ADMA_ZEROLEN_DESC;
+
+	if (pdata->cd_type == W3K_SDHCI_CD_NONE ||
+	    pdata->cd_type == W3K_SDHCI_CD_PERMANENT)
+		host->quirks |= SDHCI_QUIRK_BROKEN_CARD_DETECTION;
+
+	if (pdata->cd_type == W3K_SDHCI_CD_PERMANENT)
+		host->mmc->caps = MMC_CAP_NONREMOVABLE;
+
+	switch (pdata->max_width) {
+	case 8:
+		host->mmc->caps |= MMC_CAP_8_BIT_DATA;
+		break;
+	case 4:
+		host->mmc->caps |= MMC_CAP_4_BIT_DATA;
+		break;
+	}
+
+	if (pdata->pm_caps)
+		host->mmc->pm_caps |= pdata->pm_caps;
+
+//	host->quirks |= (SDHCI_QUIRK_32BIT_DMA_ADDR |
+//			 SDHCI_QUIRK_32BIT_DMA_SIZE);
+
+	/* HSMMC on Samsung SoCs uses SDCLK as timeout clock */
+	host->quirks |= SDHCI_QUIRK_DATA_TIMEOUT_USES_SDCLK;
+
+	/* Support tuning */
+	host->quirks2 |= SDHCI_QUIRK2_TUNING_WORK_AROUND;
+	/* Support HS400 */
+	host->quirks2 |= SDHCI_QUIRK2_CAPS_BIT63_FOR_HS400;
+
+	host->quirks2 |= SDHCI_QUIRK2_PRESET_VALUE_BROKEN;
+#if 0
+	/*
+	 * If controller does not have internal clock divider,
+	 * we can use overriding functions instead of default.
+	 */
+	if (sc->no_divider) {
+		sdhci_w3k_ops.set_clock = sdhci_cmu_set_clock;
+		sdhci_w3k_ops.get_min_clock = sdhci_cmu_get_min_clock;
+		sdhci_w3k_ops.get_max_clock = sdhci_cmu_get_max_clock;
+	}
+#endif
+
+	/* It supports additional host capabilities if needed */
+	if (pdata->host_caps) {
+//		host->mmc->caps |= pdata->host_caps;
+		host->caps |= pdata->host_caps;
+	}
+	//printk(KERN_INFO "pdata %x host %x\n", pdata->host_caps, host->caps);
+	if (pdata->host_caps1) {
+//		host->mmc->caps2 |= pdata->host_caps2;
+		host->caps1 |= pdata->host_caps1;
+	}
+
+//	pm_runtime_enable(&pdev->dev);
+//	pm_runtime_set_autosuspend_delay(&pdev->dev, 50);
+//	pm_runtime_use_autosuspend(&pdev->dev);
+//	pm_suspend_ignore_children(&pdev->dev, 1);
+
+	ret = mmc_of_parse(host->mmc);
+	if (ret)
+		goto err_req_regs;
+
+	ret = sdhci_add_host(host);
+	if (ret) {
+		dev_err(dev, "sdhci_add_host() failed\n");
+		goto err_req_regs;
+	}
+#ifdef USE_SRAM
+	host->sram = SRAM_ADDR;
+	sram_addr = ioremap((phys_addr_t)SRAM_ADDR, SRAM_SIZE);
+	if (sram_addr) {
+		char *p = (char*)sram_addr;
+		host->sram_addr = sram_addr;
+		memset(p, 0xff, SRAM_SIZE);
+		//printk("read sram value: %x %x %x %x\n", p[0], 
+		//	p[SRAM_SIZE/4], p[SRAM_SIZE/2], p[SRAM_SIZE-4]);
+	}else
+		printk("ioremap sram error\n");
+#endif
+
+#ifdef CONFIG_PM
+//	if (pdata->cd_type != W3K_SDHCI_CD_INTERNAL)
+//		clk_disable_unprepare(sc->clk_io);
+#endif
+	return 0;
+
+ err_req_regs:
+	pm_runtime_disable(&pdev->dev);
+
+// err_no_busclks:
+//	clk_disable_unprepare(sc->clk_io);
+
+ err_pdata_io_clk:
+	sdhci_free_host(host);
+
+	return ret;
+}
+
+static int sdhci_w3k_remove(struct platform_device *pdev)
+{
+	struct sdhci_host *host = platform_get_drvdata(pdev);
+//	struct sdhci_w3k *sc = sdhci_priv(host);
+
+//	if (sc->ext_cd_irq)
+//		free_irq(sc->ext_cd_irq, sc);
+
+#ifdef CONFIG_PM
+//	if (sc->pdata->cd_type != W3K_SDHCI_CD_INTERNAL)
+//		clk_prepare_enable(sc->clk_io);
+#endif
+	sdhci_remove_host(host, 1);
+
+	pm_runtime_dont_use_autosuspend(&pdev->dev);
+	pm_runtime_disable(&pdev->dev);
+
+//	clk_disable_unprepare(sc->clk_io);
+
+	sdhci_free_host(host);
+
+#ifdef RTL_SDIO_GPIO_TEST
+	if (host->slot_id == SLOT_SDIO_WIFI)
+		sdio_irq_gpio_unset(SDIO_INTERRUPT_GPIO, host);
+#endif
+
+	return 0;
+}
+
+#ifdef CONFIG_PM_SLEEP
+static int sdhci_w3k_suspend(struct device *dev)
+{
+	struct sdhci_host *host = dev_get_drvdata(dev);
+
+	return sdhci_suspend_host(host);
+}
+
+static int sdhci_w3k_resume(struct device *dev)
+{
+	struct sdhci_host *host = dev_get_drvdata(dev);
+
+	return sdhci_resume_host(host);
+}
+#endif
+
+#ifdef CONFIG_PM
+static int sdhci_w3k_runtime_suspend(struct device *dev)
+{
+	struct sdhci_host *host = dev_get_drvdata(dev);
+//	struct sdhci_w3k *ourhost = to_im98xx(host);
+//	struct clk *busclk = ourhost->clk_io;
+	int ret;
+
+	ret = sdhci_runtime_suspend_host(host);
+
+//	if (ourhost->cur_clk >= 0)
+//		clk_disable_unprepare(ourhost->clk_bus[ourhost->cur_clk]);
+//	clk_disable_unprepare(busclk);
+	return ret;
+}
+
+static int sdhci_w3k_runtime_resume(struct device *dev)
+{
+	struct sdhci_host *host = dev_get_drvdata(dev);
+//	struct sdhci_w3k *ourhost = to_im98xx(host);
+//	struct clk *busclk = ourhost->clk_io;
+	int ret;
+
+//	clk_prepare_enable(busclk);
+//	if (ourhost->cur_clk >= 0)
+//		clk_prepare_enable(ourhost->clk_bus[ourhost->cur_clk]);
+	ret = sdhci_runtime_resume_host(host);
+	return ret;
+}
+#endif
+
+#ifdef CONFIG_PM
+static const struct dev_pm_ops sdhci_w3k_pmops = {
+	SET_SYSTEM_SLEEP_PM_OPS(sdhci_w3k_suspend, sdhci_im98xx_resume)
+	SET_RUNTIME_PM_OPS(sdhci_w3k_runtime_suspend, sdhci_im98xx_runtime_resume,
+			   NULL)
+};
+
+#define SDHCI_W3K_PMOPS (&sdhci_w3k_pmops)
+
+#else
+#define SDHCI_W3K_PMOPS NULL
+#endif
+
+#if 0
+static struct sdhci_w3k_drv_data im98xx_sdhci_drv_data = {
+	.no_divider = true,
+};
+#define W3K_SDHCI_DRV_DATA ((kernel_ulong_t)&w3k_sdhci_drv_data)
+#else
+#define W3K_SDHCI_DRV_DATA ((kernel_ulong_t)NULL)
+#endif
+
+static struct platform_device_id sdhci_w3k_driver_ids[] = {
+	{
+		.name		= "w3k-sdhci",
+		.driver_data	= W3K_SDHCI_DRV_DATA,
+	},
+	{ }
+};
+MODULE_DEVICE_TABLE(platform, sdhci_w3k_driver_ids);
+
+#ifdef CONFIG_OF
+static const struct of_device_id sdhci_w3k_dt_match[] = {
+#if 0
+	{ .compatible = "infomax,w3k-sdhci", },
+#endif
+	{ .compatible = "siliconwaves,w3k-sdhci",
+		.data = (void *)W3K_SDHCI_DRV_DATA },
+	{},
+};
+MODULE_DEVICE_TABLE(of, sdhci_w3k_dt_match);
+#endif
+
+static struct platform_driver sdhci_w3k_driver = {
+	.probe		= sdhci_w3k_probe,
+	.remove		= sdhci_w3k_remove,
+	.id_table	= sdhci_w3k_driver_ids,
+	.driver		= {
+		.name	= "w3k-sdhci",
+		.of_match_table = of_match_ptr(sdhci_w3k_dt_match),
+		.pm	= SDHCI_W3K_PMOPS,
+	},
+};
+
+module_platform_driver(sdhci_w3k_driver);
+
+/*****************************************************************************\
+ *                                                                           *
+ * Driver init/exit                                                          *
+ *                                                                           *
+\*****************************************************************************/
+
+static int __init sdhci_drv_init(void)
+{
+	pr_info(DRIVER_NAME
+		": Secure Digital Host Controller Interface driver\n");
+	return 0;
+}
+
+static void __exit sdhci_drv_exit(void)
+{
+}
+
+module_init(sdhci_drv_init);
+module_exit(sdhci_drv_exit);
+
+module_param(debug_quirks, uint, 0444);
+module_param(debug_quirks2, uint, 0444);
+
+MODULE_DESCRIPTION("Secure Digital Host Controller Interface core driver");
+MODULE_LICENSE("GPL");
+
+MODULE_PARM_DESC(debug_quirks, "Force certain quirks.");
+MODULE_PARM_DESC(debug_quirks2, "Force certain other quirks.");
diff --git a/drivers/mmc/host/sdhci_w3k.h b/drivers/mmc/host/sdhci_w3k.h
new file mode 100644
index 000000000..4b9dde7bb
--- /dev/null
+++ b/drivers/mmc/host/sdhci_w3k.h
@@ -0,0 +1,760 @@
+#ifndef __SDHCI_W3K_H
+#define __SDHCI_W3K_H
+
+#include <linux/scatterlist.h>
+#include <linux/compiler.h>
+#include <linux/types.h>
+#include <linux/io.h>
+
+#include <linux/mmc/host.h>
+
+#define USE_SRAM
+
+#ifdef USE_SRAM
+
+#define SRAM_ADDR (0x40020000)
+#define SRAM_SIZE (1024*384) 
+
+#endif
+
+/*
+ * Controller registers
+ */
+
+#define SDHCI_DMA_ADDRESS	0x00
+#define SDHCI_ARGUMENT2		SDHCI_DMA_ADDRESS
+
+#define SDHCI_BLOCK_SIZE	0x04
+#define  SDHCI_MAKE_BLKSZ(dma, blksz) (((dma & 0x7) << 12) | (blksz & 0xFFF))
+
+#define SDHCI_BLOCK_COUNT	0x34
+
+#define SDHCI_ARGUMENT		0x1C
+
+#define SDHCI_TRANSFER_MODE	0x0C
+#define  SDHCI_TRNS_DMA		0x01
+#define  SDHCI_TRNS_BLK_CNT_EN	0x02
+#define  SDHCI_TRNS_AUTO_CMD12	0x04
+#define  SDHCI_TRNS_AUTO_CMD23	0x08
+#define  SDHCI_TRNS_READ	0x10
+#define  SDHCI_TRNS_MULTI	0x20
+
+#define SDHCI_COMMAND		0x18
+#define  SDHCI_CMD_RESP_MASK	0x03
+#define  SDHCI_CMD_CRC		0x08
+#define  SDHCI_CMD_INDEX	0x10
+#define  SDHCI_CMD_DATA		0x20
+#define  SDHCI_CMD_ABORTCMD	0xC0
+
+#define  SDHCI_CMD_RESP_NONE	0x00
+#define  SDHCI_CMD_RESP_LONG	0x01
+#define  SDHCI_CMD_RESP_SHORT	0x02
+#define  SDHCI_CMD_RESP_SHORT_BUSY 0x03
+#if 0
+#define SDHCI_MAKE_CMD(c, f) (((c & 0xff) << 8) | (f & 0xff))
+#define SDHCI_GET_CMD(c) ((c>>8) & 0x3f)
+#endif
+
+#define SDHCI_MAKE_CMD(c, f) ((c & 0x3f) | ((f & 0x7) << 7))
+#define SDHCI_GET_CMD(c) (c & 0x3f)
+
+#define SDHCI_RESPONSE		0x24
+
+#define SDHCI_BUFFER		0x20
+
+#define SDHCI_PRESENT_STATE	0x24
+#define  SDHCI_CMD_INHIBIT	0x00000001
+#define  SDHCI_DATA_INHIBIT	0x00000002
+#define  SDHCI_DOING_WRITE	0x00000100
+#define  SDHCI_DOING_READ	0x00000200
+#define  SDHCI_SPACE_AVAILABLE	0x00000400
+#define  SDHCI_DATA_AVAILABLE	0x00000800
+#define  SDHCI_CARD_PRESENT	0x00010000
+#define  SDHCI_WRITE_PROTECT	0x00080000
+#define  SDHCI_DATA_LVL_MASK	0x00F00000
+#define   SDHCI_DATA_LVL_SHIFT	20
+#define   SDHCI_DATA_0_LVL_MASK	0x00100000
+
+#define SDHCI_HOST_CONTROL	0x14
+#define  SDHCI_CTRL_BITBUS_MASK	0x00030000
+#define  SDHCI_CTRL_LED		0x01
+#define  SDHCI_CTRL_4BITBUS	0x02
+#define  SDHCI_CTRL_HISPD	0x04
+#define  SDHCI_CTRL_DMA_MASK	0x18
+#define   SDHCI_CTRL_SDMA	0x00
+#define   SDHCI_CTRL_ADMA1	0x08
+#define   SDHCI_CTRL_ADMA32	0x10
+#define   SDHCI_CTRL_ADMA64	0x18
+#define   SDHCI_CTRL_8BITBUS	0x20
+
+#define SDHCI_POWER_CONTROL	0x00
+#define  SDHCI_POWER_ON		0x10
+#define  SDHCI_POWER_180	0x0A
+#define  SDHCI_POWER_300	0x0C
+#define  SDHCI_POWER_330	0x0E
+
+#define SDHCI_BLOCK_GAP_CONTROL	0x2A
+
+#define SDHCI_WAKE_UP_CONTROL	0x2B
+#define  SDHCI_WAKE_ON_INT	0x01
+#define  SDHCI_WAKE_ON_INSERT	0x02
+#define  SDHCI_WAKE_ON_REMOVE	0x04
+
+#define SDHCI_CLOCK_CONTROL	0x00
+#define  SDHCI_DIVIDER_SHIFT	8
+#define  SDHCI_DIVIDER_HI_SHIFT	6
+#define  SDHCI_DIV_MASK		0x1FFF
+#define  SDHCI_DIV_MASK_LEN	13
+#define  SDHCI_DIV_HI_MASK	0x300
+#define  SDHCI_PROG_CLOCK_MODE	0x0020
+#define  SDHCI_CLOCK_CARD_EN	0x0004
+#define  SDHCI_CLOCK_INT_STABLE	0x0080
+#define  SDHCI_CLOCK_INT_EN	0x0001
+
+#define SDHCI_TIMEOUT_CONTROL	0x2E
+
+#define SDHCI_SOFTWARE_RESET	0x00
+#define  SDHCI_RESET_ALL	0x04
+#define  SDHCI_RESET_CMD	0x02
+#define  SDHCI_RESET_DATA	0x04
+
+#define SDHCI_INT_STATUS	0x0C
+#define SDHCI_INT_ENABLE	0x10
+#define SDHCI_SIGNAL_ENABLE	0x38
+#ifndef W3K_MMC_HOST//infomax, merge from another version
+#define  SDHCI_INT_RESPONSE	0x00000001
+#define  SDHCI_INT_DATA_END	0x00000002
+#define  SDHCI_INT_BLK_GAP	0x00000004
+#define  SDHCI_INT_DMA_END	0x00000008
+#define  SDHCI_INT_SPACE_AVAIL	0x00000010
+#define  SDHCI_INT_DATA_AVAIL	0x00000020
+#define  SDHCI_INT_CARD_INSERT	0x00000040
+#define  SDHCI_INT_CARD_REMOVE	0x00000080
+#define  SDHCI_INT_CARD_INT	0x00000100
+#define  SDHCI_INT_ERROR	0x00008000
+#define  SDHCI_INT_TIMEOUT	0x00000200
+#define  SDHCI_INT_CRC		0x00000400
+#define  SDHCI_INT_END_BIT	0x00040000
+#define  SDHCI_INT_INDEX	0x00080000
+#define  SDHCI_INT_DATA_TIMEOUT	0x00004000
+#define  SDHCI_INT_DATA_CRC	0x00008000
+#define  SDHCI_INT_DATA_END_BIT	0x00400000
+#define  SDHCI_INT_BUS_POWER	0x00800000
+#define  SDHCI_INT_ACMD12ERR	0x01000000
+#define  SDHCI_INT_ADMA_ERROR	0x02000000
+
+#else //W3K_MMC_HOST
+
+#define  SDHCI_INT_CARD_INSERT	0x00000002
+#define  SDHCI_INT_CARD_REMOVE	0x00000002
+
+#define  SDHCI_INT_ACMD_END	0x00000008
+#define  SDHCI_INT_ACMD_TIMEOUT	0x00000010
+#define  SDHCI_INT_ACMD_CRC	0x00000020
+
+#define  SDHCI_INT_RESPONSE	0x00000100
+#define  SDHCI_INT_TIMEOUT	0x00000200
+#define  SDHCI_INT_CRC		0x00000400
+
+#define  SDHCI_INT_DATA_END	0x00001000
+#define  SDHCI_INT_DATA_TIMEOUT	0x00004000
+#define  SDHCI_INT_DATA_CRC	0x00008000
+
+#define  SDHCI_INT_DATA_AVAIL	0x00010000
+
+#define  SDHCI_INT_DMA_START	0x00000001
+#define  SDHCI_INT_DMA_END	0x00000002
+#define  SDHCI_INT_ADMA_ERROR	0x00000004
+#define  SDHCI_INT_ADMA_END	0x00000008
+#endif
+
+#define  SDHCI_INT_NORMAL_MASK	0x00007FFF
+#define  SDHCI_INT_ERROR_MASK	0xFFFF8000
+
+#ifndef W3K_MMC_HOST//infomax, merge from another version
+#define  SDHCI_INT_CMD_MASK	(SDHCI_INT_RESPONSE | SDHCI_INT_TIMEOUT | \
+		SDHCI_INT_CRC | SDHCI_INT_END_BIT | SDHCI_INT_INDEX)
+#define  SDHCI_INT_DATA_MASK	(SDHCI_INT_DATA_END | SDHCI_INT_DMA_END | \
+		SDHCI_INT_DATA_AVAIL | SDHCI_INT_SPACE_AVAIL | \
+		SDHCI_INT_DATA_TIMEOUT | SDHCI_INT_DATA_CRC | \
+		SDHCI_INT_DATA_END_BIT | SDHCI_INT_ADMA_ERROR | \
+		SDHCI_INT_BLK_GAP)
+#else //W3K_MMC_HOST
+#define  SDHCI_INT_CMD_MASK	0x00000700
+#define  SDHCI_INT_DATA_MASK	0x0000D000
+#define  SDHCI_INT_DMA_MASK	(SDHCI_INT_DMA_END | SDHCI_INT_ADMA_ERROR | \
+				 SDHCI_INT_ADMA_END)
+#endif
+#define SDHCI_INT_ALL_MASK	((unsigned int)-1)
+
+#define SDHCI_ACMD12_ERR	0x3C
+
+#define SDHCI_HOST_CONTROL2		0x3E
+#define  SDHCI_CTRL_UHS_MASK		0x0007
+#define   SDHCI_CTRL_UHS_SDR12		0x0000
+#define   SDHCI_CTRL_UHS_SDR25		0x0001
+#define   SDHCI_CTRL_UHS_SDR50		0x0002
+#define   SDHCI_CTRL_UHS_SDR104		0x0003
+#define   SDHCI_CTRL_UHS_DDR50		0x0004
+#define   SDHCI_CTRL_HS400		0x0005 /* Non-standard */
+#define  SDHCI_CTRL_VDD_180		0x0008
+#define  SDHCI_CTRL_DRV_TYPE_MASK	0x0030
+#define   SDHCI_CTRL_DRV_TYPE_B		0x0000
+#define   SDHCI_CTRL_DRV_TYPE_A		0x0010
+#define   SDHCI_CTRL_DRV_TYPE_C		0x0020
+#define   SDHCI_CTRL_DRV_TYPE_D		0x0030
+#define  SDHCI_CTRL_EXEC_TUNING		0x0040
+#define  SDHCI_CTRL_TUNED_CLK		0x0080
+#define  SDHCI_CTRL_PRESET_VAL_ENABLE	0x8000
+
+#define SDHCI_CAPABILITIES	0x40
+#define  SDHCI_TIMEOUT_CLK_MASK	0x0000003F
+#define  SDHCI_TIMEOUT_CLK_SHIFT 0
+#define  SDHCI_TIMEOUT_CLK_UNIT	0x00000080
+#define  SDHCI_CLOCK_BASE_MASK	0x00003F00
+#define  SDHCI_CLOCK_V3_BASE_MASK	0x0000FF00
+#define  SDHCI_CLOCK_BASE_SHIFT	8
+#define  SDHCI_MAX_BLOCK_MASK	0x00030000
+#define  SDHCI_MAX_BLOCK_SHIFT  16
+#define  SDHCI_CAN_DO_8BIT	0x00040000
+#define  SDHCI_CAN_DO_ADMA2	0x00080000
+#define  SDHCI_CAN_DO_ADMA1	0x00100000
+#define  SDHCI_CAN_DO_HISPD	0x00200000
+#define  SDHCI_CAN_DO_SDMA	0x00400000
+#define  SDHCI_CAN_VDD_330	0x01000000
+#define  SDHCI_CAN_VDD_300	0x02000000
+#define  SDHCI_CAN_VDD_180	0x04000000
+#define  SDHCI_CAN_64BIT	0x10000000
+
+#define  SDHCI_SUPPORT_SDR50	0x00000001
+#define  SDHCI_SUPPORT_SDR104	0x00000002
+#define  SDHCI_SUPPORT_DDR50	0x00000004
+#define  SDHCI_DRIVER_TYPE_A	0x00000010
+#define  SDHCI_DRIVER_TYPE_C	0x00000020
+#define  SDHCI_DRIVER_TYPE_D	0x00000040
+#define  SDHCI_RETUNING_TIMER_COUNT_MASK	0x00000F00
+#define  SDHCI_RETUNING_TIMER_COUNT_SHIFT	8
+#define  SDHCI_USE_SDR50_TUNING			0x00002000
+#define  SDHCI_RETUNING_MODE_MASK		0x0000C000
+#define  SDHCI_RETUNING_MODE_SHIFT		14
+#define  SDHCI_CLOCK_MUL_MASK	0x00FF0000
+#define  SDHCI_CLOCK_MUL_SHIFT	16
+#define  SDHCI_SUPPORT_HS400	0x80000000 /* Non-standard */
+
+#define SDHCI_CAPABILITIES_1	0x44
+
+#define SDHCI_MAX_CURRENT		0x48
+#define  SDHCI_MAX_CURRENT_LIMIT	0xFF
+#define  SDHCI_MAX_CURRENT_330_MASK	0x0000FF
+#define  SDHCI_MAX_CURRENT_330_SHIFT	0
+#define  SDHCI_MAX_CURRENT_300_MASK	0x00FF00
+#define  SDHCI_MAX_CURRENT_300_SHIFT	8
+#define  SDHCI_MAX_CURRENT_180_MASK	0xFF0000
+#define  SDHCI_MAX_CURRENT_180_SHIFT	16
+#define   SDHCI_MAX_CURRENT_MULTIPLIER	4
+
+/* 4C-4F reserved for more max current */
+
+#define SDHCI_SET_ACMD12_ERROR	0x50
+#define SDHCI_SET_INT_ERROR	0x52
+
+#define SDHCI_ADMA_ERROR	0x54
+
+/* 55-57 reserved */
+
+#define SDHCI_ADMA_ADDRESS	0x10C
+#define SDHCI_ADMA_ADDRESS_HI	0x5C
+
+/* 60-FB reserved */
+
+#define SDHCI_PRESET_FOR_SDR12 0x66
+#define SDHCI_PRESET_FOR_SDR25 0x68
+#define SDHCI_PRESET_FOR_SDR50 0x6A
+#define SDHCI_PRESET_FOR_SDR104        0x6C
+#define SDHCI_PRESET_FOR_DDR50 0x6E
+#define SDHCI_PRESET_FOR_HS400 0x74 /* Non-standard */
+#define SDHCI_PRESET_DRV_MASK  0xC000
+#define SDHCI_PRESET_DRV_SHIFT  14
+#define SDHCI_PRESET_CLKGEN_SEL_MASK   0x400
+#define SDHCI_PRESET_CLKGEN_SEL_SHIFT	10
+#define SDHCI_PRESET_SDCLK_FREQ_MASK   0x3FF
+#define SDHCI_PRESET_SDCLK_FREQ_SHIFT	0
+
+#define SDHCI_SLOT_INT_STATUS	0xFC
+
+#define SDHCI_HOST_VERSION	0xFE
+#define  SDHCI_VENDOR_VER_MASK	0xFF00
+#define  SDHCI_VENDOR_VER_SHIFT	8
+#define  SDHCI_SPEC_VER_MASK	0x00FF
+#define  SDHCI_SPEC_VER_SHIFT	0
+#define   SDHCI_SPEC_100	0
+#define   SDHCI_SPEC_200	1
+#define   SDHCI_SPEC_300	2
+
+/*
+ * End of controller registers.
+ */
+
+#define SDHCI_MAX_DIV_SPEC_200	256
+#define SDHCI_MAX_DIV_SPEC_300	2046
+
+/*
+ * Host SDMA buffer boundary. Valid values from 4K to 512K in powers of 2.
+ */
+#define SDHCI_DEFAULT_BOUNDARY_SIZE  (512 * 1024)
+#define SDHCI_DEFAULT_BOUNDARY_ARG   (ilog2(SDHCI_DEFAULT_BOUNDARY_SIZE) - 12)
+
+/* ADMA2 32-bit DMA descriptor size */
+#define SDHCI_ADMA2_32_DESC_SZ	8
+
+#ifdef W3K_MMC_HOST //infomax, merge from another version
+/* ADMA2 32-bit DMA alignment */
+#define SDHCI_ADMA2_32_ALIGN	4
+#endif
+/* ADMA2 32-bit descriptor */
+struct sdhci_adma2_32_desc {
+	__le16	cmd;
+	__le16	len;
+	__le32	addr;
+}  __packed __aligned(4);
+
+/* ADMA2 data alignment */
+#define SDHCI_ADMA2_ALIGN	4
+#define SDHCI_ADMA2_MASK	(SDHCI_ADMA2_ALIGN - 1)
+
+/*
+ * ADMA2 descriptor alignment.  Some controllers (e.g. Intel) require 8 byte
+ * alignment for the descriptor table even in 32-bit DMA mode.  Memory
+ * allocation is at least 8 byte aligned anyway, so just stipulate 8 always.
+ */
+#define SDHCI_ADMA2_DESC_ALIGN	8
+
+/* ADMA2 64-bit DMA descriptor size */
+#define SDHCI_ADMA2_64_DESC_SZ	12
+
+#ifdef W3K_MMC_HOST //infomax, merge from another version
+/* ADMA2 64-bit DMA alignment */
+#define SDHCI_ADMA2_64_ALIGN	8
+#endif
+/*
+ * ADMA2 64-bit descriptor. Note 12-byte descriptor can't always be 8-byte
+ * aligned.
+ */
+struct sdhci_adma2_64_desc {
+	__le16	cmd;
+	__le16	len;
+	__le32	addr_lo;
+	__le32	addr_hi;
+}  __packed __aligned(4);
+
+#define ADMA2_TRAN_VALID	0x21
+#define ADMA2_NOP_END_VALID	0x3
+#define ADMA2_END		0x2
+
+/*
+ * Maximum segments assuming a 512KiB maximum requisition size and a minimum
+ * 4KiB page size.
+ */
+#define SDHCI_MAX_SEGS		128
+
+enum sdhci_cookie {
+	COOKIE_UNMAPPED,
+	COOKIE_MAPPED,
+	COOKIE_GIVEN,
+};
+
+#ifdef W3K_MMC_HOST
+struct sdhci_host_next {
+	 unsigned int	sg_count;
+	 s32		cookie;
+};
+#endif
+
+struct sdhci_host {
+	/* Data set by hardware interface driver */
+	const char *hw_name;	/* Hardware bus name */
+
+	unsigned int quirks;	/* Deviations from spec. */
+
+/* Controller doesn't honor resets unless we touch the clock register */
+#define SDHCI_QUIRK_CLOCK_BEFORE_RESET			(1<<0)
+/* Controller has bad caps bits, but really supports DMA */
+#define SDHCI_QUIRK_FORCE_DMA				(1<<1)
+/* Controller doesn't like to be reset when there is no card inserted. */
+#define SDHCI_QUIRK_NO_CARD_NO_RESET			(1<<2)
+/* Controller doesn't like clearing the power reg before a change */
+#define SDHCI_QUIRK_SINGLE_POWER_WRITE			(1<<3)
+/* Controller has flaky internal state so reset it on each ios change */
+#define SDHCI_QUIRK_RESET_CMD_DATA_ON_IOS		(1<<4)
+/* Controller has an unusable DMA engine */
+#define SDHCI_QUIRK_BROKEN_DMA				(1<<5)
+/* Controller has an unusable ADMA engine */
+#define SDHCI_QUIRK_BROKEN_ADMA				(1<<6)
+/* Controller can only DMA from 32-bit aligned addresses */
+#define SDHCI_QUIRK_32BIT_DMA_ADDR			(1<<7)
+/* Controller can only DMA chunk sizes that are a multiple of 32 bits */
+#define SDHCI_QUIRK_32BIT_DMA_SIZE			(1<<8)
+/* Controller can only ADMA chunks that are a multiple of 32 bits */
+#define SDHCI_QUIRK_32BIT_ADMA_SIZE			(1<<9)
+/* Controller needs to be reset after each request to stay stable */
+#define SDHCI_QUIRK_RESET_AFTER_REQUEST			(1<<10)
+/* Controller needs voltage and power writes to happen separately */
+#define SDHCI_QUIRK_NO_SIMULT_VDD_AND_POWER		(1<<11)
+/* Controller provides an incorrect timeout value for transfers */
+#define SDHCI_QUIRK_BROKEN_TIMEOUT_VAL			(1<<12)
+/* Controller has an issue with buffer bits for small transfers */
+#define SDHCI_QUIRK_BROKEN_SMALL_PIO			(1<<13)
+/* Controller does not provide transfer-complete interrupt when not busy */
+#define SDHCI_QUIRK_NO_BUSY_IRQ				(1<<14)
+/* Controller has unreliable card detection */
+#define SDHCI_QUIRK_BROKEN_CARD_DETECTION		(1<<15)
+/* Controller reports inverted write-protect state */
+#define SDHCI_QUIRK_INVERTED_WRITE_PROTECT		(1<<16)
+/* Controller does not like fast PIO transfers */
+#define SDHCI_QUIRK_PIO_NEEDS_DELAY			(1<<18)
+/* Controller has to be forced to use block size of 2048 bytes */
+#define SDHCI_QUIRK_FORCE_BLK_SZ_2048			(1<<20)
+/* Controller cannot do multi-block transfers */
+#define SDHCI_QUIRK_NO_MULTIBLOCK			(1<<21)
+/* Controller can only handle 1-bit data transfers */
+#define SDHCI_QUIRK_FORCE_1_BIT_DATA			(1<<22)
+/* Controller needs 10ms delay between applying power and clock */
+#define SDHCI_QUIRK_DELAY_AFTER_POWER			(1<<23)
+/* Controller uses SDCLK instead of TMCLK for data timeouts */
+#define SDHCI_QUIRK_DATA_TIMEOUT_USES_SDCLK		(1<<24)
+/* Controller reports wrong base clock capability */
+#define SDHCI_QUIRK_CAP_CLOCK_BASE_BROKEN		(1<<25)
+/* Controller cannot support End Attribute in NOP ADMA descriptor */
+#define SDHCI_QUIRK_NO_ENDATTR_IN_NOPDESC		(1<<26)
+/* Controller is missing device caps. Use caps provided by host */
+#define SDHCI_QUIRK_MISSING_CAPS			(1<<27)
+/* Controller uses Auto CMD12 command to stop the transfer */
+#define SDHCI_QUIRK_MULTIBLOCK_READ_ACMD12		(1<<28)
+/* Controller doesn't have HISPD bit field in HI-SPEED SD card */
+#define SDHCI_QUIRK_NO_HISPD_BIT			(1<<29)
+/* Controller treats ADMA descriptors with length 0000h incorrectly */
+#define SDHCI_QUIRK_BROKEN_ADMA_ZEROLEN_DESC		(1<<30)
+/* The read-only detection via SDHCI_PRESENT_STATE register is unstable */
+#define SDHCI_QUIRK_UNSTABLE_RO_DETECT			(1<<31)
+
+	unsigned int quirks2;	/* More deviations from spec. */
+
+#define SDHCI_QUIRK2_HOST_OFF_CARD_ON			(1<<0)
+#define SDHCI_QUIRK2_HOST_NO_CMD23			(1<<1)
+/* The system physically doesn't support 1.8v, even if the host does */
+#define SDHCI_QUIRK2_NO_1_8_V				(1<<2)
+#define SDHCI_QUIRK2_PRESET_VALUE_BROKEN		(1<<3)
+#define SDHCI_QUIRK2_CARD_ON_NEEDS_BUS_ON		(1<<4)
+/* Controller has a non-standard host control register */
+#define SDHCI_QUIRK2_BROKEN_HOST_CONTROL		(1<<5)
+/* Controller does not support HS200 */
+#define SDHCI_QUIRK2_BROKEN_HS200			(1<<6)
+/* Controller does not support DDR50 */
+#define SDHCI_QUIRK2_BROKEN_DDR50			(1<<7)
+/* Stop command (CMD12) can set Transfer Complete when not using MMC_RSP_BUSY */
+#define SDHCI_QUIRK2_STOP_WITH_TC			(1<<8)
+/* Controller does not support 64-bit DMA */
+#define SDHCI_QUIRK2_BROKEN_64_BIT_DMA			(1<<9)
+/* need clear transfer mode register before send cmd */
+#define SDHCI_QUIRK2_CLEAR_TRANSFERMODE_REG_BEFORE_CMD	(1<<10)
+/* Capability register bit-63 indicates HS400 support */
+#define SDHCI_QUIRK2_CAPS_BIT63_FOR_HS400		(1<<11)
+/* forced tuned clock */
+#define SDHCI_QUIRK2_TUNING_WORK_AROUND			(1<<12)
+/* disable the block count for single block transactions */
+#define SDHCI_QUIRK2_SUPPORT_SINGLE			(1<<13)
+/* Controller broken with using ACMD23 */
+#define SDHCI_QUIRK2_ACMD23_BROKEN			(1<<14)
+/* Broken Clock divider zero in controller */
+#define SDHCI_QUIRK2_CLOCK_DIV_ZERO_BROKEN		(1<<15)
+/*
+ * When internal clock is disabled, a delay is needed before modifying the
+ * SD clock frequency or enabling back the internal clock.
+ */
+#define SDHCI_QUIRK2_NEED_DELAY_AFTER_INT_CLK_RST	(1<<16)
+
+	int irq;		/* Device IRQ */
+	void __iomem *ioaddr;	/* Mapped address */
+	void __iomem *gpioaddr;	/* Mapped address */
+
+	const struct sdhci_ops *ops;	/* Low level hw interface */
+
+	/* Internal data */
+	struct mmc_host *mmc;	/* MMC structure */
+	struct mmc_host_ops mmc_host_ops;	/* MMC host ops */
+	u64 dma_mask;		/* custom DMA mask */
+#if 0
+#if defined(CONFIG_LEDS_CLASS) || defined(CONFIG_LEDS_CLASS_MODULE)
+	struct led_classdev led;	/* LED control */
+	char led_name[32];
+#endif
+#endif
+	spinlock_t lock;	/* Mutex */
+
+	int flags;		/* Host attributes */
+#define SDHCI_USE_SDMA		(1<<0)	/* Host is SDMA capable */
+#define SDHCI_USE_ADMA		(1<<1)	/* Host is ADMA capable */
+#define SDHCI_REQ_USE_DMA	(1<<2)	/* Use DMA for this req. */
+#define SDHCI_DEVICE_DEAD	(1<<3)	/* Device unresponsive */
+#define SDHCI_SDR50_NEEDS_TUNING (1<<4)	/* SDR50 needs tuning */
+#ifdef W3K_MMC_HOST //infomax, merge from another version
+#define SDHCI_NEEDS_RETUNING	(1<<5)	/* Host needs retuning */
+#endif
+#define SDHCI_AUTO_CMD12	(1<<6)	/* Auto CMD12 support */
+#define SDHCI_AUTO_CMD23	(1<<7)	/* Auto CMD23 support */
+#define SDHCI_PV_ENABLED	(1<<8)	/* Preset value enabled */
+#define SDHCI_SDIO_IRQ_ENABLED	(1<<9)	/* SDIO irq enabled */
+#define SDHCI_SDR104_NEEDS_TUNING (1<<10)	/* SDR104/HS200 needs tuning */
+#ifdef W3K_MMC_HOST //infomax, merge from another version
+#define SDHCI_USING_RETUNING_TIMER (1<<11)	/* Host is using a retuning timer for the card */
+#endif
+#define SDHCI_USE_64_BIT_DMA	(1<<12)	/* Use 64-bit DMA */
+#define SDHCI_HS400_TUNING	(1<<13)	/* Tuning for HS400 */
+
+	unsigned int version;	/* SDHCI spec. version */
+
+	unsigned int max_clk;	/* Max possible freq (MHz) */
+	unsigned int timeout_clk;	/* Timeout freq (KHz) */
+	unsigned int clk_mul;	/* Clock Muliplier value */
+
+	unsigned int clock;	/* Current clock (MHz) */
+	u8 pwr;			/* Current voltage */
+
+	bool runtime_suspended;	/* Host is runtime suspended */
+	bool bus_on;		/* Bus power prevents runtime suspend */
+	bool preset_enabled;	/* Preset is enabled */
+
+	struct mmc_request *mrq;	/* Current request */
+	struct mmc_command *cmd;	/* Current command */
+	struct mmc_data *data;	/* Current data request */
+	unsigned int data_early:1;	/* Data finished before cmd */
+	unsigned int busy_handle:1;	/* Handling the order of Busy-end */
+
+	struct sg_mapping_iter sg_miter;	/* SG state for PIO */
+	unsigned int blocks;	/* remaining PIO blocks */
+
+	int sg_count;		/* Mapped sg entries */
+
+	void *adma_table;	/* ADMA descriptor table */
+	void *align_buffer;	/* Bounce buffer */
+
+	size_t adma_table_sz;	/* ADMA descriptor table size */
+	size_t align_buffer_sz;	/* Bounce buffer size */
+
+	dma_addr_t adma_addr;	/* Mapped ADMA descr. table */
+	dma_addr_t align_addr;	/* Mapped bounce buffer */
+
+	unsigned int desc_sz;	/* ADMA descriptor size */
+#ifdef W3K_MMC_HOST //infomax, merge from another version	
+	unsigned int align_sz;	/* ADMA alignment */
+	unsigned int align_mask;	/* ADMA alignment mask */	
+#endif
+
+	struct tasklet_struct finish_tasklet;	/* Tasklet structures */
+
+	struct timer_list timer;	/* Timer for timeouts */
+
+	u32 caps;		/* Alternative CAPABILITY_0 */
+	u32 caps1;		/* Alternative CAPABILITY_1 */
+
+	unsigned int            ocr_avail_sdio;	/* OCR bit masks */
+	unsigned int            ocr_avail_sd;
+	unsigned int            ocr_avail_mmc;
+	u32 ocr_mask;		/* available voltages */
+
+	unsigned		timing;		/* Current timing */
+
+	u32			thread_isr;
+
+	/* cached registers */
+	u32			ier;
+
+	wait_queue_head_t	buf_ready_int;	/* Waitqueue for Buffer Read Ready interrupt */
+	unsigned int		tuning_done;	/* Condition flag set when CMD19 succeeds */
+
+	unsigned int		tuning_count;	/* Timer count for re-tuning */
+	unsigned int		tuning_mode;	/* Re-tuning mode supported by host */
+#define SDHCI_TUNING_MODE_1	0
+
+	/* im98xx */
+#ifdef W3K_MMC_HOST
+	struct timer_list	tuning_timer;	/* Timer for tuning */
+
+	struct sdhci_host_next	next_data;
+	bool			card_present;
+	bool			card_detect;
+	u8			sdhci_host_control;
+	u16			sdhci_host_control2;
+
+	int			resp_flag;
+
+#define MMC_CMD_DONE_FLAG	0x00000001
+#define MMC_DATA_DONE_FLAG	0x00000002
+#define MMC_DMA_DONE_FLAG	0x00000004
+
+	u32 slot_id;	
+#endif
+#ifdef USE_SRAM
+	unsigned int sram;
+	void __iomem *sram_addr;
+#endif
+	unsigned long private[0] ____cacheline_aligned;
+};
+
+struct sdhci_ops {
+#ifdef CONFIG_MMC_SDHCI_IO_ACCESSORS
+	u32		(*read_l)(struct sdhci_host *host, int reg);
+	u16		(*read_w)(struct sdhci_host *host, int reg);
+	u8		(*read_b)(struct sdhci_host *host, int reg);
+	void		(*write_l)(struct sdhci_host *host, u32 val, int reg);
+	void		(*write_w)(struct sdhci_host *host, u16 val, int reg);
+	void		(*write_b)(struct sdhci_host *host, u8 val, int reg);
+#endif
+
+	void	(*set_clock)(struct sdhci_host *host, unsigned int clock);
+
+	int		(*enable_dma)(struct sdhci_host *host);
+	unsigned int	(*get_max_clock)(struct sdhci_host *host);
+	unsigned int	(*get_min_clock)(struct sdhci_host *host);
+	unsigned int	(*get_timeout_clock)(struct sdhci_host *host);
+	unsigned int	(*get_max_timeout_count)(struct sdhci_host *host);
+	void		(*set_timeout)(struct sdhci_host *host,
+				       struct mmc_command *cmd);
+	void		(*set_bus_width)(struct sdhci_host *host, int width);
+	void (*platform_send_init_74_clocks)(struct sdhci_host *host,
+					     u8 power_mode);
+	unsigned int    (*get_ro)(struct sdhci_host *host);
+	void		(*reset)(struct sdhci_host *host, u8 mask);
+	int	(*platform_execute_tuning)(struct sdhci_host *host, u32 opcode);
+	void	(*set_uhs_signaling)(struct sdhci_host *host, unsigned int uhs);
+	void	(*hw_reset)(struct sdhci_host *host);
+	void    (*adma_workaround)(struct sdhci_host *host, u32 intmask);
+	void	(*platform_init)(struct sdhci_host *host);
+	void    (*card_event)(struct sdhci_host *host);
+	void	(*voltage_switch)(struct sdhci_host *host);
+	int	(*select_drive_strength)(struct sdhci_host *host,
+					 struct mmc_card *card,
+					 unsigned int max_dtr, int host_drv,
+					 int card_drv, int *drv_type);
+};
+
+#ifdef CONFIG_MMC_SDHCI_IO_ACCESSORS
+
+static inline void sdhci_writel(struct sdhci_host *host, u32 val, int reg)
+{
+	//printk(KERN_INFO "writel %x val %x\n", reg, val);
+	if (unlikely(host->ops->write_l))
+		host->ops->write_l(host, val, reg);
+	else
+		writel(val, host->ioaddr + reg);
+}
+
+static inline void sdhci_writew(struct sdhci_host *host, u16 val, int reg)
+{
+	if (unlikely(host->ops->write_w))
+		host->ops->write_w(host, val, reg);
+	else
+		writew(val, host->ioaddr + reg);
+}
+
+static inline void sdhci_writeb(struct sdhci_host *host, u8 val, int reg)
+{
+	if (unlikely(host->ops->write_b))
+		host->ops->write_b(host, val, reg);
+	else
+		writeb(val, host->ioaddr + reg);
+}
+
+static inline u32 sdhci_readl(struct sdhci_host *host, int reg)
+{
+	if (unlikely(host->ops->read_l))
+		return host->ops->read_l(host, reg);
+	else
+		return readl(host->ioaddr + reg);
+}
+
+static inline u16 sdhci_readw(struct sdhci_host *host, int reg)
+{
+	if (unlikely(host->ops->read_w))
+		return host->ops->read_w(host, reg);
+	else
+		return readw(host->ioaddr + reg);
+}
+
+static inline u8 sdhci_readb(struct sdhci_host *host, int reg)
+{
+	if (unlikely(host->ops->read_b))
+		return host->ops->read_b(host, reg);
+	else
+		return readb(host->ioaddr + reg);
+}
+
+#else
+
+static inline void sdhci_writel(struct sdhci_host *host, u32 val, int reg)
+{
+	//printk(KERN_INFO "writel %x val %x\n", reg, val);
+	writel(val, host->ioaddr + reg);
+}
+
+static inline void sdhci_writew(struct sdhci_host *host, u16 val, int reg)
+{
+	writew(val, host->ioaddr + reg);
+}
+
+static inline void sdhci_writeb(struct sdhci_host *host, u8 val, int reg)
+{
+	writeb(val, host->ioaddr + reg);
+}
+
+static inline u32 sdhci_readl(struct sdhci_host *host, int reg)
+{
+	return readl(host->ioaddr + reg);
+}
+
+static inline u16 sdhci_readw(struct sdhci_host *host, int reg)
+{
+	return readw(host->ioaddr + reg);
+}
+
+static inline u8 sdhci_readb(struct sdhci_host *host, int reg)
+{
+	return readb(host->ioaddr + reg);
+}
+
+#endif /* CONFIG_MMC_SDHCI_IO_ACCESSORS */
+
+extern struct sdhci_host *sdhci_alloc_host(struct device *dev,
+	size_t priv_size);
+extern void sdhci_free_host(struct sdhci_host *host);
+
+static inline void *sdhci_priv(struct sdhci_host *host)
+{
+	return (void *)host->private;
+}
+
+extern void sdhci_card_detect(struct sdhci_host *host);
+extern int sdhci_add_host(struct sdhci_host *host);
+extern void sdhci_remove_host(struct sdhci_host *host, int dead);
+extern void sdhci_send_command(struct sdhci_host *host,
+				struct mmc_command *cmd);
+
+static inline bool sdhci_sdio_irq_enabled(struct sdhci_host *host)
+{
+	return !!(host->flags & SDHCI_SDIO_IRQ_ENABLED);
+}
+
+void sdhci_set_clock(struct sdhci_host *host, unsigned int clock);
+void sdhci_set_bus_width(struct sdhci_host *host, int width);
+void sdhci_reset(struct sdhci_host *host, u8 mask);
+void sdhci_set_uhs_signaling(struct sdhci_host *host, unsigned timing);
+
+#ifdef CONFIG_PM
+extern int sdhci_suspend_host(struct sdhci_host *host);
+extern int sdhci_resume_host(struct sdhci_host *host);
+extern void sdhci_enable_irq_wakeups(struct sdhci_host *host);
+extern int sdhci_runtime_suspend_host(struct sdhci_host *host);
+extern int sdhci_runtime_resume_host(struct sdhci_host *host);
+#endif
+
+#endif /* __SDHCI_W3K_H */
diff --git a/include/linux/platform_data/mmc-sdhci-w3k.h b/include/linux/platform_data/mmc-sdhci-w3k.h
new file mode 100644
index 000000000..1dd507b17
--- /dev/null
+++ b/include/linux/platform_data/mmc-sdhci-w3k.h
@@ -0,0 +1,32 @@
+#ifndef __PLATFORM_DATA_SDHCI_W3K_H
+#define __PLATFORM_DATA_SDHCI_W3K_H
+
+struct platform_device;
+
+enum cd_types {
+	W3K_SDHCI_CD_INTERNAL,	/* use mmc internal CD line */
+	W3K_SDHCI_CD_EXTERNAL,	/* use external callback */
+	W3K_SDHCI_CD_GPIO,	/* use external gpio pin for CD line */
+	W3K_SDHCI_CD_NONE,	/* no CD line, use polling to detect card */
+	W3K_SDHCI_CD_PERMANENT,	/* no CD line, card permanently wired to host */
+};
+
+struct w3k_sdhci_platdata {
+	unsigned int	max_width;
+	unsigned int	host_caps;
+	unsigned int	host_caps1;
+	unsigned int	host_caps2;
+	unsigned int	pm_caps;
+	enum cd_types	cd_type;
+
+	int		ext_cd_gpio;
+	bool		ext_cd_gpio_invert;
+	int	(*ext_cd_init)(void (*notify_func)(struct platform_device *,
+						   int state));
+	int	(*ext_cd_cleanup)(void (*notify_func)(struct platform_device *,
+						      int state));
+
+	void	(*cfg_gpio)(struct platform_device *dev, int width);
+};
+
+#endif /* __PLATFORM_DATA_SDHCI_W3K_H */
-- 
2.34.1

